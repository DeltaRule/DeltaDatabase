{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DeltaDatabase \u00b6 A lightweight, encrypted-at-rest JSON database written in Go \u2014 built for production-grade workloads that need per-entity encryption, JSON Schema validation, and a simple REST API. What is DeltaDatabase? \u00b6 DeltaDatabase stores arbitrary JSON documents \u2014 called entities \u2014 inside named databases . Every entity is: Validated against a JSON Schema template before being persisted. Encrypted at rest using AES-256-GCM before touching disk. Cached in memory using a smart LRU policy for high-speed reads. Accessed through a plain HTTP REST API or gRPC from any language. A built-in single-page web UI is served at / so you can browse and manage databases without any external tooling. Quick Navigation \u00b6 Tip New here? Start with the Quick Start guide to have DeltaDatabase running in under 5 minutes. I want to\u2026 Go to\u2026 Get DeltaDatabase running quickly Quick Start Understand the system architecture Architecture See the full REST API API Reference Deploy with Docker or Kubernetes Deployment See real-world usage examples Examples Understand the security model Security Use the web management UI Management UI Build from source Building Run tests Testing Key Features \u00b6 \ud83d\udd10 Encrypted at Rest \u00b6 All entities are encrypted with AES-256-GCM before being written to disk. The encryption key is managed exclusively by the Main Worker and never written to disk. \ud83d\udccb Schema Validation \u00b6 Define the shape of your data using JSON Schema (draft-07). Every write is validated before encryption \u2014 bad data is rejected before it reaches storage. \u26a1 Smart Caching \u00b6 An in-memory LRU cache means frequently-accessed entities are served without disk I/O. The cache is coherent across multiple Processing Workers. \ud83d\udd0c Dual API \u00b6 Access DeltaDatabase via REST (HTTP/JSON) or gRPC. The same data is accessible through either interface. \ud83c\udf10 Built-in Web UI \u00b6 A single-page management UI is embedded in the main-worker binary \u2014 no additional installation required. \ud83d\udce6 Flexible Storage \u00b6 Choose between a shared POSIX filesystem (NFS, local) or any S3-compatible object store (MinIO, AWS S3, RustFS, SeaweedFS). \ud83d\ude80 Horizontally Scalable \u00b6 Add more Processing Workers behind the same Main Worker to increase throughput linearly. Architecture Overview \u00b6 Client (app, browser, curl) \u2502 REST (HTTP/JSON) or gRPC \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Main Worker (:8080 REST | :50051 gRPC) \u2502 \u2502 \u2022 Auth & token issuance \u2502 \u2502 \u2022 Key distribution to workers \u2502 \u2502 \u2022 Routes requests to workers \u2502 \u2502 \u2022 Serves the web management UI \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 gRPC (internal) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u25bc \u25bc \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Proc \u2502 \u2502 Proc \u2502 \u2502 Proc \u2502 \u2502 Worker 1 \u2502 \u2502 Worker 2 \u2502 \u2502 Worker 3 \u2502 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Shared FS or S3 See the full Architecture page for details. Get Started in One Command \u00b6 docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up The REST API is available at http://localhost:8080 and the web UI at http://localhost:8080/ . \u2192 Full Quick Start guide Changelog \u00b6 See CHANGELOG for a full history of releases and changes.","title":"Home"},{"location":"#deltadatabase","text":"A lightweight, encrypted-at-rest JSON database written in Go \u2014 built for production-grade workloads that need per-entity encryption, JSON Schema validation, and a simple REST API.","title":"DeltaDatabase"},{"location":"#what-is-deltadatabase","text":"DeltaDatabase stores arbitrary JSON documents \u2014 called entities \u2014 inside named databases . Every entity is: Validated against a JSON Schema template before being persisted. Encrypted at rest using AES-256-GCM before touching disk. Cached in memory using a smart LRU policy for high-speed reads. Accessed through a plain HTTP REST API or gRPC from any language. A built-in single-page web UI is served at / so you can browse and manage databases without any external tooling.","title":"What is DeltaDatabase?"},{"location":"#quick-navigation","text":"Tip New here? Start with the Quick Start guide to have DeltaDatabase running in under 5 minutes. I want to\u2026 Go to\u2026 Get DeltaDatabase running quickly Quick Start Understand the system architecture Architecture See the full REST API API Reference Deploy with Docker or Kubernetes Deployment See real-world usage examples Examples Understand the security model Security Use the web management UI Management UI Build from source Building Run tests Testing","title":"Quick Navigation"},{"location":"#key-features","text":"","title":"Key Features"},{"location":"#encrypted-at-rest","text":"All entities are encrypted with AES-256-GCM before being written to disk. The encryption key is managed exclusively by the Main Worker and never written to disk.","title":"\ud83d\udd10 Encrypted at Rest"},{"location":"#schema-validation","text":"Define the shape of your data using JSON Schema (draft-07). Every write is validated before encryption \u2014 bad data is rejected before it reaches storage.","title":"\ud83d\udccb Schema Validation"},{"location":"#smart-caching","text":"An in-memory LRU cache means frequently-accessed entities are served without disk I/O. The cache is coherent across multiple Processing Workers.","title":"\u26a1 Smart Caching"},{"location":"#dual-api","text":"Access DeltaDatabase via REST (HTTP/JSON) or gRPC. The same data is accessible through either interface.","title":"\ud83d\udd0c Dual API"},{"location":"#built-in-web-ui","text":"A single-page management UI is embedded in the main-worker binary \u2014 no additional installation required.","title":"\ud83c\udf10 Built-in Web UI"},{"location":"#flexible-storage","text":"Choose between a shared POSIX filesystem (NFS, local) or any S3-compatible object store (MinIO, AWS S3, RustFS, SeaweedFS).","title":"\ud83d\udce6 Flexible Storage"},{"location":"#horizontally-scalable","text":"Add more Processing Workers behind the same Main Worker to increase throughput linearly.","title":"\ud83d\ude80 Horizontally Scalable"},{"location":"#architecture-overview","text":"Client (app, browser, curl) \u2502 REST (HTTP/JSON) or gRPC \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Main Worker (:8080 REST | :50051 gRPC) \u2502 \u2502 \u2022 Auth & token issuance \u2502 \u2502 \u2022 Key distribution to workers \u2502 \u2502 \u2022 Routes requests to workers \u2502 \u2502 \u2022 Serves the web management UI \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 gRPC (internal) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u25bc \u25bc \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Proc \u2502 \u2502 Proc \u2502 \u2502 Proc \u2502 \u2502 Worker 1 \u2502 \u2502 Worker 2 \u2502 \u2502 Worker 3 \u2502 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Shared FS or S3 See the full Architecture page for details.","title":"Architecture Overview"},{"location":"#get-started-in-one-command","text":"docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up The REST API is available at http://localhost:8080 and the web UI at http://localhost:8080/ . \u2192 Full Quick Start guide","title":"Get Started in One Command"},{"location":"#changelog","text":"See CHANGELOG for a full history of releases and changes.","title":"Changelog"},{"location":"changelog/","text":"Changelog \u00b6 All notable changes to DeltaDatabase are documented here. The format follows Keep a Changelog . DeltaDatabase uses Semantic Versioning . [Unreleased] \u00b6 0.1.0-alpha.1 \u2014 2026-02-25 \u00b6 \u26a0\ufe0f Pre-release / Alpha \u2014 APIs and storage formats may change without notice. Added \u00b6 Admin key authentication \u2014 start the Main Worker with -admin-key (or $ADMIN_KEY env var) for a single master credential that bypasses all RBAC checks, analogous to a PostgreSQL superuser password or MinIO root access key. Persistent RBAC API keys ( dk_\u2026 prefix) \u2014 managed via POST /api/keys , GET /api/keys , and DELETE /api/keys/{id} . Keys are persisted to <shared-fs>/_auth/keys.json and survive restarts. Each key carries configurable read , write , and/or admin permissions with optional expiry. Three-tier authentication priority \u2014 every Bearer token is now evaluated as: admin key \u2192 API key \u2192 session token (from POST /api/login ). All three types are usable directly without a login step. Session token permissions now correctly inherited \u2014 session tokens issued by POST /api/login carry the exact permissions of the admin key or API key used to authenticate. Previously, session tokens were always restricted to read+write even when the login credential had admin permissions. Management UI \u2014 API Keys tab \u2014 create, list, and delete RBAC API keys from the browser. Management UI \u2014 Schema Export \u2014 generate typed Pydantic (Python) or TypeScript interfaces from any JSON Schema loaded in the editor. Management UI login \u2014 the login screen now accepts an admin key or API key instead of a plain client_id . The client_id field is retained for backwards-compatible dev-mode only. Chat example application ( examples/chat/ ) \u2014 a full-stack Flask chat app backed exclusively by DeltaDatabase, featuring: Session-based authentication with login, registration, and logout Per-user encrypted chat histories stored in DeltaDatabase Per-user OpenAI API configuration (key, base URL, default model) Admin panel for managing users and assigning allowed models per user Support for custom OpenAI-compatible API endpoints Mock mode ( MOCK_OPENAI=true ) for running without a real API key Playwright end-to-end test suite covering auth, chat, settings, and admin Docker Compose setup for one-command local deployment ReadTheDocs documentation link added to README.md ( https://deltadatabase.readthedocs.io/en/latest/ ) Changelog ( CHANGELOG.md ) referenced from the documentation Management UI Guide ( docs/usage/frontend.md ) \u2014 documentation page with screenshots of every UI tab and detailed usage instructions. Fixed \u00b6 GET /api/keys empty-state \u2014 when no API keys exist the endpoint now returns 200 [] instead of 401 / 403 , so the Management UI shows \"No API keys found.\" rather than \"Failed to load keys\" on a fresh install or after all keys are deleted. docker-compose.one-main-multiple-workers.yml \u2014 the ADMIN_KEY environment variable was missing from the main-worker service. It is now passed through correctly so that the admin key set in .env or the host environment is honoured in multi-worker deployments. Session token permissions \u2014 extractBearerToken now reads the roles stored on the session token rather than hard-coding read+write . This fixes the Management UI's Workers and API Keys tabs returning HTTP 403 when the user logged in with an admin key. Changed \u00b6 POST /api/login request body \u2014 the key field (admin key or API key) is now the primary authentication credential. The client_id field is still accepted for backwards compatibility when no admin key is configured (dev mode). POST /api/login response \u2014 the response now includes a permissions array so callers know which operations the issued token permits. Removed \u00b6 GitHub Actions workflow for deploying docs to GitHub Pages (documentation is now hosted on ReadTheDocs)","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to DeltaDatabase are documented here. The format follows Keep a Changelog . DeltaDatabase uses Semantic Versioning .","title":"Changelog"},{"location":"changelog/#unreleased","text":"","title":"[Unreleased]"},{"location":"changelog/#010-alpha1-2026-02-25","text":"\u26a0\ufe0f Pre-release / Alpha \u2014 APIs and storage formats may change without notice.","title":"0.1.0-alpha.1 \u2014 2026-02-25"},{"location":"changelog/#added","text":"Admin key authentication \u2014 start the Main Worker with -admin-key (or $ADMIN_KEY env var) for a single master credential that bypasses all RBAC checks, analogous to a PostgreSQL superuser password or MinIO root access key. Persistent RBAC API keys ( dk_\u2026 prefix) \u2014 managed via POST /api/keys , GET /api/keys , and DELETE /api/keys/{id} . Keys are persisted to <shared-fs>/_auth/keys.json and survive restarts. Each key carries configurable read , write , and/or admin permissions with optional expiry. Three-tier authentication priority \u2014 every Bearer token is now evaluated as: admin key \u2192 API key \u2192 session token (from POST /api/login ). All three types are usable directly without a login step. Session token permissions now correctly inherited \u2014 session tokens issued by POST /api/login carry the exact permissions of the admin key or API key used to authenticate. Previously, session tokens were always restricted to read+write even when the login credential had admin permissions. Management UI \u2014 API Keys tab \u2014 create, list, and delete RBAC API keys from the browser. Management UI \u2014 Schema Export \u2014 generate typed Pydantic (Python) or TypeScript interfaces from any JSON Schema loaded in the editor. Management UI login \u2014 the login screen now accepts an admin key or API key instead of a plain client_id . The client_id field is retained for backwards-compatible dev-mode only. Chat example application ( examples/chat/ ) \u2014 a full-stack Flask chat app backed exclusively by DeltaDatabase, featuring: Session-based authentication with login, registration, and logout Per-user encrypted chat histories stored in DeltaDatabase Per-user OpenAI API configuration (key, base URL, default model) Admin panel for managing users and assigning allowed models per user Support for custom OpenAI-compatible API endpoints Mock mode ( MOCK_OPENAI=true ) for running without a real API key Playwright end-to-end test suite covering auth, chat, settings, and admin Docker Compose setup for one-command local deployment ReadTheDocs documentation link added to README.md ( https://deltadatabase.readthedocs.io/en/latest/ ) Changelog ( CHANGELOG.md ) referenced from the documentation Management UI Guide ( docs/usage/frontend.md ) \u2014 documentation page with screenshots of every UI tab and detailed usage instructions.","title":"Added"},{"location":"changelog/#fixed","text":"GET /api/keys empty-state \u2014 when no API keys exist the endpoint now returns 200 [] instead of 401 / 403 , so the Management UI shows \"No API keys found.\" rather than \"Failed to load keys\" on a fresh install or after all keys are deleted. docker-compose.one-main-multiple-workers.yml \u2014 the ADMIN_KEY environment variable was missing from the main-worker service. It is now passed through correctly so that the admin key set in .env or the host environment is honoured in multi-worker deployments. Session token permissions \u2014 extractBearerToken now reads the roles stored on the session token rather than hard-coding read+write . This fixes the Management UI's Workers and API Keys tabs returning HTTP 403 when the user logged in with an admin key.","title":"Fixed"},{"location":"changelog/#changed","text":"POST /api/login request body \u2014 the key field (admin key or API key) is now the primary authentication credential. The client_id field is still accepted for backwards compatibility when no admin key is configured (dev mode). POST /api/login response \u2014 the response now includes a permissions array so callers know which operations the issued token permits.","title":"Changed"},{"location":"changelog/#removed","text":"GitHub Actions workflow for deploying docs to GitHub Pages (documentation is now hosted on ReadTheDocs)","title":"Removed"},{"location":"development/","text":"Development \u00b6 This section covers everything you need to know to develop, extend, or contribute to DeltaDatabase. In This Section \u00b6 Page Description Architecture System design, component overview, data flows Project Structure Directory layout and what lives where Building from Source Prerequisites, build steps, and binary output Testing Unit tests, integration tests, and Python end-to-end tests Development Philosophy \u00b6 DeltaDatabase follows a strict separation of concerns: Main Worker = authentication, authorization, routing, key management Processing Worker = encryption, decryption, caching, file I/O Shared storage = the single source of truth (filesystem or S3) All communication between workers uses gRPC . All client communication uses REST (HTTP/JSON) or gRPC . Preferred Libraries \u00b6 Category Library Purpose Communication google.golang.org/grpc Worker-to-worker RPC REST API github.com/gin-gonic/gin Lightweight web framework JSON Schema github.com/xeipuuv/gojsonschema Draft-07 validation Caching github.com/hashicorp/golang-lru LRU cache Encryption crypto/aes , crypto/cipher AES-GCM (standard library) Concurrency golang.org/x/sync/errgroup Worker goroutine management Testing github.com/stretchr/testify Assertions and mocks Security Principles \u00b6 No Plaintext Keys on Disk \u2014 Encryption keys are stored in volatile memory only and cleared on shutdown. Log Redaction \u2014 Logs never contain decrypted entity data or key material. Fail Closed \u2014 If encryption, decryption, or schema validation fails, the operation is rejected and a security event is logged. Schema Enforced on Every Write \u2014 Bad data is rejected before reaching storage.","title":"Overview"},{"location":"development/#development","text":"This section covers everything you need to know to develop, extend, or contribute to DeltaDatabase.","title":"Development"},{"location":"development/#in-this-section","text":"Page Description Architecture System design, component overview, data flows Project Structure Directory layout and what lives where Building from Source Prerequisites, build steps, and binary output Testing Unit tests, integration tests, and Python end-to-end tests","title":"In This Section"},{"location":"development/#development-philosophy","text":"DeltaDatabase follows a strict separation of concerns: Main Worker = authentication, authorization, routing, key management Processing Worker = encryption, decryption, caching, file I/O Shared storage = the single source of truth (filesystem or S3) All communication between workers uses gRPC . All client communication uses REST (HTTP/JSON) or gRPC .","title":"Development Philosophy"},{"location":"development/#preferred-libraries","text":"Category Library Purpose Communication google.golang.org/grpc Worker-to-worker RPC REST API github.com/gin-gonic/gin Lightweight web framework JSON Schema github.com/xeipuuv/gojsonschema Draft-07 validation Caching github.com/hashicorp/golang-lru LRU cache Encryption crypto/aes , crypto/cipher AES-GCM (standard library) Concurrency golang.org/x/sync/errgroup Worker goroutine management Testing github.com/stretchr/testify Assertions and mocks","title":"Preferred Libraries"},{"location":"development/#security-principles","text":"No Plaintext Keys on Disk \u2014 Encryption keys are stored in volatile memory only and cleared on shutdown. Log Redaction \u2014 Logs never contain decrypted entity data or key material. Fail Closed \u2014 If encryption, decryption, or schema validation fails, the operation is rejected and a security event is logged. Schema Enforced on Every Write \u2014 Bad data is rejected before reaching storage.","title":"Security Principles"},{"location":"development/architecture/","text":"Architecture \u00b6 DeltaDatabase is built around a two-worker model : a single Main Worker handles authentication and routing, while one or more Processing Workers handle the actual data operations (encryption, decryption, caching, storage). High-Level Diagram \u00b6 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Client (your application, browser, curl \u2026) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 REST (HTTP/JSON) or gRPC \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Main Worker (:8080 REST | :50051 gRPC) \u2502 \u2502 \u2022 Issues client Bearer tokens (POST /api/login) \u2502 \u2502 \u2022 Authenticates every request \u2502 \u2502 \u2022 Distributes master encryption key to Processing Workers \u2502 \u2502 \u2022 Routes entity requests to an available Processing Worker \u2502 \u2502 \u2022 Exposes the web management UI at / \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 gRPC (internal) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u25bc \u25bc \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Proc Worker\u2502 \u2502 Proc Worker\u2502 \u2502 Proc Worker\u2502 \u2502 :50052 \u2502 \u2502 :50053 \u2502 \u2502 :50054 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Shared FS \u2502 \u2500\u2500 or \u2500\u2500 \u2502 S3-compatible \u2502 \u2502 /shared/db/ \u2502 \u2502 (MinIO, AWS S3,\u2502 \u2502 \u251c\u2500\u2500 files/ \u2502 \u2502 RustFS, \u2026) \u2502 \u2502 \u2514\u2500\u2500 templates/ \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Main Worker \u00b6 The Main Worker is the single entry point for all external clients. It never touches the data directly \u2014 it authenticates requests and delegates to Processing Workers. Responsibilities \u00b6 Responsibility Details Client authentication Issues Bearer tokens via POST /api/login Worker authentication Validates Processing Workers during the subscribe handshake (mTLS-ready) Key distribution Wraps the AES master key with each worker's RSA public key and vends it during subscription Request routing Forwards GET /entity/\u2026 and PUT /entity/\u2026 to an available Processing Worker Worker registry Maintains the list of active workers; removes workers that stop heartbeating Web UI Serves the embedded single-page management application at / Schema storage Stores JSON Schema templates in shared storage so all workers can access them Routing Strategy \u00b6 The Main Worker routes entity requests using a cache-aware + least-loaded algorithm: Try to send to the worker that most recently served the same entity (to maximize LRU cache hits). Fall back to the worker with the fewest active requests when no preferred worker is available. Processing Worker \u00b6 Processing Workers are the data plane . They subscribe to the Main Worker at startup to receive the encryption key, then handle all read and write operations. Responsibilities \u00b6 Responsibility Details Subscribe Connect to Main Worker, provide RSA public key, receive wrapped AES key Schema validation Validate incoming JSON against the registered JSON Schema before writing Encryption Encrypt entities with AES-256-GCM before writing to storage Decryption Decrypt entities after reading from storage Caching Maintain an LRU in-memory cache of decrypted entities File locking Acquire advisory locks ( flock ) on shared-FS writes to prevent concurrent corruption S3 locking Use in-process mutexes for S3 writes (no shared-FS lock needed) Worker Lifecycle \u00b6 Startup \u2502 \u251c\u2500 Generate RSA key pair (ephemeral) \u2502 \u251c\u2500 Connect to Main Worker (gRPC) \u2502 \u251c\u2500 Send Subscribe(worker_id, rsa_public_key) \u2502 \u251c\u2500 Receive SubscribeResponse(token, wrapped_aes_key, key_id) \u2502 \u251c\u2500 Unwrap AES key with RSA private key \u2192 store in volatile memory \u2502 \u251c\u2500 Register as \"Available\" \u2502 \u2514\u2500 Start serving Process RPCs (GET / PUT) \u2502 \u251c\u2500 GET: check cache \u2192 decrypt from storage if miss \u2192 return \u2502 \u2514\u2500 PUT: validate schema \u2192 encrypt \u2192 write atomically \u2192 update cache Storage Backends \u00b6 Shared Filesystem (default) \u00b6 Any POSIX-compatible directory: local disk, NFS, CIFS/Samba, or a cloud-mounted volume. File layout: /shared/db/ \u251c\u2500\u2500 files/ \u2502 \u251c\u2500\u2500 <entityID>.json.enc # AES-256-GCM encrypted blob \u2502 \u2514\u2500\u2500 <entityID>.meta.json # metadata (key_id, iv, tag, schema_id, version) \u2514\u2500\u2500 templates/ \u2514\u2500\u2500 <schemaID>.json # JSON Schema template Write durability: fdatasync before atomic rename \u2014 no data loss on crash. Locking: POSIX advisory flock per file prevents concurrent writers from corrupting entities. S3-Compatible (optional) \u00b6 Any service implementing the S3 API: MinIO, RustFS, SeaweedFS, AWS S3, Ceph RadosGW. Object layout: deltadatabase/ \u251c\u2500\u2500 files/<entityID>.json.enc \u251c\u2500\u2500 files/<entityID>.meta.json \u2514\u2500\u2500 templates/<schemaID>.json Locking: In-process mutexes; S3's strong read-after-write consistency prevents races. Advantage: No shared PVC needed in Kubernetes. Key Management \u00b6 Main Worker \u2502 \u251c\u2500 Generates (or restores from -master-key flag) a 32-byte AES master key \u2502 at startup \u2014 NEVER writes it to disk \u2502 \u2514\u2500 On each worker Subscribe: \u2502 \u251c\u2500 Validates worker credentials \u2502 \u251c\u2500 Encrypts master key with worker's RSA public key (RSA-OAEP) \u2502 \u2514\u2500 Sends wrapped key \u2192 worker unwraps \u2192 stores in RAM only Key rotation is supported: generate a new key, restart the Main Worker with -master-key=<new> , and Processing Workers will receive the new key on their next subscription. Active files will be re-encrypted lazily on next write. Authentication Flow (Clients) \u00b6 Client Main Worker \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500 POST /api/login \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 \u2502 {\"client_id\": \"myapp\"} \u2502 \u2502 \u251c\u2500 Generates Bearer token (JWT-style, signed) \u2502\u25c4\u2500\u2500\u2500 {\"token\": \"\u2026\"} \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500 GET /entity/db?key=foo \u2500\u2500\u2500\u25ba\u2502 \u2502 Authorization: Bearer \u2026 \u2502 \u2502 \u251c\u2500 Validates token \u2502 \u251c\u2500 Routes to Processing Worker \u2502\u25c4\u2500\u2500\u2500 {\"field\": \"value\"} \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 Caching Architecture \u00b6 Each Processing Worker maintains its own LRU cache of decrypted entities: Proc essing Worker ( in - memory ) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 LRU Cache ( configurable size ) \u2502 \u2502 \u2502 \u2502 key: \" chatdb / session_001 \" \u2502 \u2502 value: {\" messages \" : [ ... ] } \u2502 \u2502 version: 3 \u2502 \u2502 \u2502 \u2502 key: \" userdb / user_42 \" \u2502 \u2502 value: {\" name \": \" Alice \" , ... } \u2502 \u2502 version: 1 \u2502 \u2502 \u2502 \u2502 \u2026 ( up to - cache - size entries ) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Cache coherence: When reading from disk, the worker checks meta.version against the cached version. If they differ, the disk copy wins and the cache is refreshed. See the Caching Model page for the full read/write path description.","title":"Architecture"},{"location":"development/architecture/#architecture","text":"DeltaDatabase is built around a two-worker model : a single Main Worker handles authentication and routing, while one or more Processing Workers handle the actual data operations (encryption, decryption, caching, storage).","title":"Architecture"},{"location":"development/architecture/#high-level-diagram","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Client (your application, browser, curl \u2026) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 REST (HTTP/JSON) or gRPC \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Main Worker (:8080 REST | :50051 gRPC) \u2502 \u2502 \u2022 Issues client Bearer tokens (POST /api/login) \u2502 \u2502 \u2022 Authenticates every request \u2502 \u2502 \u2022 Distributes master encryption key to Processing Workers \u2502 \u2502 \u2022 Routes entity requests to an available Processing Worker \u2502 \u2502 \u2022 Exposes the web management UI at / \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 gRPC (internal) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u25bc \u25bc \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Proc Worker\u2502 \u2502 Proc Worker\u2502 \u2502 Proc Worker\u2502 \u2502 :50052 \u2502 \u2502 :50053 \u2502 \u2502 :50054 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Shared FS \u2502 \u2500\u2500 or \u2500\u2500 \u2502 S3-compatible \u2502 \u2502 /shared/db/ \u2502 \u2502 (MinIO, AWS S3,\u2502 \u2502 \u251c\u2500\u2500 files/ \u2502 \u2502 RustFS, \u2026) \u2502 \u2502 \u2514\u2500\u2500 templates/ \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"High-Level Diagram"},{"location":"development/architecture/#main-worker","text":"The Main Worker is the single entry point for all external clients. It never touches the data directly \u2014 it authenticates requests and delegates to Processing Workers.","title":"Main Worker"},{"location":"development/architecture/#responsibilities","text":"Responsibility Details Client authentication Issues Bearer tokens via POST /api/login Worker authentication Validates Processing Workers during the subscribe handshake (mTLS-ready) Key distribution Wraps the AES master key with each worker's RSA public key and vends it during subscription Request routing Forwards GET /entity/\u2026 and PUT /entity/\u2026 to an available Processing Worker Worker registry Maintains the list of active workers; removes workers that stop heartbeating Web UI Serves the embedded single-page management application at / Schema storage Stores JSON Schema templates in shared storage so all workers can access them","title":"Responsibilities"},{"location":"development/architecture/#routing-strategy","text":"The Main Worker routes entity requests using a cache-aware + least-loaded algorithm: Try to send to the worker that most recently served the same entity (to maximize LRU cache hits). Fall back to the worker with the fewest active requests when no preferred worker is available.","title":"Routing Strategy"},{"location":"development/architecture/#processing-worker","text":"Processing Workers are the data plane . They subscribe to the Main Worker at startup to receive the encryption key, then handle all read and write operations.","title":"Processing Worker"},{"location":"development/architecture/#responsibilities_1","text":"Responsibility Details Subscribe Connect to Main Worker, provide RSA public key, receive wrapped AES key Schema validation Validate incoming JSON against the registered JSON Schema before writing Encryption Encrypt entities with AES-256-GCM before writing to storage Decryption Decrypt entities after reading from storage Caching Maintain an LRU in-memory cache of decrypted entities File locking Acquire advisory locks ( flock ) on shared-FS writes to prevent concurrent corruption S3 locking Use in-process mutexes for S3 writes (no shared-FS lock needed)","title":"Responsibilities"},{"location":"development/architecture/#worker-lifecycle","text":"Startup \u2502 \u251c\u2500 Generate RSA key pair (ephemeral) \u2502 \u251c\u2500 Connect to Main Worker (gRPC) \u2502 \u251c\u2500 Send Subscribe(worker_id, rsa_public_key) \u2502 \u251c\u2500 Receive SubscribeResponse(token, wrapped_aes_key, key_id) \u2502 \u251c\u2500 Unwrap AES key with RSA private key \u2192 store in volatile memory \u2502 \u251c\u2500 Register as \"Available\" \u2502 \u2514\u2500 Start serving Process RPCs (GET / PUT) \u2502 \u251c\u2500 GET: check cache \u2192 decrypt from storage if miss \u2192 return \u2502 \u2514\u2500 PUT: validate schema \u2192 encrypt \u2192 write atomically \u2192 update cache","title":"Worker Lifecycle"},{"location":"development/architecture/#storage-backends","text":"","title":"Storage Backends"},{"location":"development/architecture/#shared-filesystem-default","text":"Any POSIX-compatible directory: local disk, NFS, CIFS/Samba, or a cloud-mounted volume. File layout: /shared/db/ \u251c\u2500\u2500 files/ \u2502 \u251c\u2500\u2500 <entityID>.json.enc # AES-256-GCM encrypted blob \u2502 \u2514\u2500\u2500 <entityID>.meta.json # metadata (key_id, iv, tag, schema_id, version) \u2514\u2500\u2500 templates/ \u2514\u2500\u2500 <schemaID>.json # JSON Schema template Write durability: fdatasync before atomic rename \u2014 no data loss on crash. Locking: POSIX advisory flock per file prevents concurrent writers from corrupting entities.","title":"Shared Filesystem (default)"},{"location":"development/architecture/#s3-compatible-optional","text":"Any service implementing the S3 API: MinIO, RustFS, SeaweedFS, AWS S3, Ceph RadosGW. Object layout: deltadatabase/ \u251c\u2500\u2500 files/<entityID>.json.enc \u251c\u2500\u2500 files/<entityID>.meta.json \u2514\u2500\u2500 templates/<schemaID>.json Locking: In-process mutexes; S3's strong read-after-write consistency prevents races. Advantage: No shared PVC needed in Kubernetes.","title":"S3-Compatible (optional)"},{"location":"development/architecture/#key-management","text":"Main Worker \u2502 \u251c\u2500 Generates (or restores from -master-key flag) a 32-byte AES master key \u2502 at startup \u2014 NEVER writes it to disk \u2502 \u2514\u2500 On each worker Subscribe: \u2502 \u251c\u2500 Validates worker credentials \u2502 \u251c\u2500 Encrypts master key with worker's RSA public key (RSA-OAEP) \u2502 \u2514\u2500 Sends wrapped key \u2192 worker unwraps \u2192 stores in RAM only Key rotation is supported: generate a new key, restart the Main Worker with -master-key=<new> , and Processing Workers will receive the new key on their next subscription. Active files will be re-encrypted lazily on next write.","title":"Key Management"},{"location":"development/architecture/#authentication-flow-clients","text":"Client Main Worker \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500 POST /api/login \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 \u2502 {\"client_id\": \"myapp\"} \u2502 \u2502 \u251c\u2500 Generates Bearer token (JWT-style, signed) \u2502\u25c4\u2500\u2500\u2500 {\"token\": \"\u2026\"} \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500 GET /entity/db?key=foo \u2500\u2500\u2500\u25ba\u2502 \u2502 Authorization: Bearer \u2026 \u2502 \u2502 \u251c\u2500 Validates token \u2502 \u251c\u2500 Routes to Processing Worker \u2502\u25c4\u2500\u2500\u2500 {\"field\": \"value\"} \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524","title":"Authentication Flow (Clients)"},{"location":"development/architecture/#caching-architecture","text":"Each Processing Worker maintains its own LRU cache of decrypted entities: Proc essing Worker ( in - memory ) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 LRU Cache ( configurable size ) \u2502 \u2502 \u2502 \u2502 key: \" chatdb / session_001 \" \u2502 \u2502 value: {\" messages \" : [ ... ] } \u2502 \u2502 version: 3 \u2502 \u2502 \u2502 \u2502 key: \" userdb / user_42 \" \u2502 \u2502 value: {\" name \": \" Alice \" , ... } \u2502 \u2502 version: 1 \u2502 \u2502 \u2502 \u2502 \u2026 ( up to - cache - size entries ) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Cache coherence: When reading from disk, the worker checks meta.version against the cached version. If they differ, the disk copy wins and the cache is refreshed. See the Caching Model page for the full read/write path description.","title":"Caching Architecture"},{"location":"development/building/","text":"Building from Source \u00b6 Note For most use-cases, the Docker / Kubernetes deployment is the recommended way to run DeltaDatabase. Build from source only when you need to develop, modify, or test the code locally. Prerequisites \u00b6 Tool Minimum version Notes Go 1.25 Required for both workers Git any Python 3.9+ Integration tests only No external databases, message brokers, or container runtimes are required for local development. Clone and Build \u00b6 git clone https://github.com/DeltaRule/DeltaDatabase.git cd DeltaDatabase # Build the Main Worker go build -o bin/main-worker ./cmd/main-worker/ # Build the Processing Worker go build -o bin/proc-worker ./cmd/proc-worker/ # Verify both binaries ./bin/main-worker --help ./bin/proc-worker --help Both binaries are self-contained \u2014 no dynamic libraries or external dependencies are needed at runtime. Running Locally \u00b6 1. Create the shared filesystem directory \u00b6 mkdir -p ./shared/db/files ./shared/db/templates 2. Start the Main Worker \u00b6 ./bin/main-worker \\ -grpc-addr = 127 .0.0.1:50051 \\ -rest-addr = 127 .0.0.1:8080 \\ -shared-fs = ./shared/db The first line of output shows the generated master key \u2014 copy it for subsequent restarts: 2026 / 02 / 24 12 : 00 : 00 Generated new master encryption key 2026 / 02 / 24 12 : 00 : 00 Key ( hex ): a1b2c3d4 ... \u2190 save this ! Tip Pass -master-key=<hex> on subsequent starts to reuse the same key and keep previously stored data readable. 3. Start the Processing Worker \u00b6 Open a second terminal: ./bin/proc-worker \\ -main-addr = 127 .0.0.1:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 127 .0.0.1:50052 \\ -shared-fs = ./shared/db 4. Verify with a health check \u00b6 curl http://127.0.0.1:8080/health # {\"status\":\"ok\"} Development Workflow \u00b6 API First \u2014 Define gRPC services in api/proto/ and regenerate Go code. Core Layers \u2014 Implement pkg/ modules with unit tests. Integration \u2014 Wire the layers in cmd/main-worker/ and cmd/proc-worker/ . Test \u2014 Run unit tests and Python integration tests (see Testing ). Regenerating Protobuf Code \u00b6 If you modify .proto files in api/proto/ , regenerate the Go code with: # Install protoc and the Go plugin (once) go install google.golang.org/protobuf/cmd/protoc-gen-go@latest go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest # Regenerate protoc \\ --go_out = . \\ --go-grpc_out = . \\ api/proto/*.proto Common Build Flags \u00b6 Flag Purpose go build -race Enable the race detector (recommended during development) go build -ldflags=\"-s -w\" Strip debug info for smaller production binaries CGO_ENABLED=0 Produce a fully static binary (needed for distroless Docker images) Example optimized build: CGO_ENABLED = 0 go build \\ -ldflags = \"-s -w\" \\ -o bin/main-worker \\ ./cmd/main-worker/","title":"Building from Source"},{"location":"development/building/#building-from-source","text":"Note For most use-cases, the Docker / Kubernetes deployment is the recommended way to run DeltaDatabase. Build from source only when you need to develop, modify, or test the code locally.","title":"Building from Source"},{"location":"development/building/#prerequisites","text":"Tool Minimum version Notes Go 1.25 Required for both workers Git any Python 3.9+ Integration tests only No external databases, message brokers, or container runtimes are required for local development.","title":"Prerequisites"},{"location":"development/building/#clone-and-build","text":"git clone https://github.com/DeltaRule/DeltaDatabase.git cd DeltaDatabase # Build the Main Worker go build -o bin/main-worker ./cmd/main-worker/ # Build the Processing Worker go build -o bin/proc-worker ./cmd/proc-worker/ # Verify both binaries ./bin/main-worker --help ./bin/proc-worker --help Both binaries are self-contained \u2014 no dynamic libraries or external dependencies are needed at runtime.","title":"Clone and Build"},{"location":"development/building/#running-locally","text":"","title":"Running Locally"},{"location":"development/building/#1-create-the-shared-filesystem-directory","text":"mkdir -p ./shared/db/files ./shared/db/templates","title":"1. Create the shared filesystem directory"},{"location":"development/building/#2-start-the-main-worker","text":"./bin/main-worker \\ -grpc-addr = 127 .0.0.1:50051 \\ -rest-addr = 127 .0.0.1:8080 \\ -shared-fs = ./shared/db The first line of output shows the generated master key \u2014 copy it for subsequent restarts: 2026 / 02 / 24 12 : 00 : 00 Generated new master encryption key 2026 / 02 / 24 12 : 00 : 00 Key ( hex ): a1b2c3d4 ... \u2190 save this ! Tip Pass -master-key=<hex> on subsequent starts to reuse the same key and keep previously stored data readable.","title":"2. Start the Main Worker"},{"location":"development/building/#3-start-the-processing-worker","text":"Open a second terminal: ./bin/proc-worker \\ -main-addr = 127 .0.0.1:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 127 .0.0.1:50052 \\ -shared-fs = ./shared/db","title":"3. Start the Processing Worker"},{"location":"development/building/#4-verify-with-a-health-check","text":"curl http://127.0.0.1:8080/health # {\"status\":\"ok\"}","title":"4. Verify with a health check"},{"location":"development/building/#development-workflow","text":"API First \u2014 Define gRPC services in api/proto/ and regenerate Go code. Core Layers \u2014 Implement pkg/ modules with unit tests. Integration \u2014 Wire the layers in cmd/main-worker/ and cmd/proc-worker/ . Test \u2014 Run unit tests and Python integration tests (see Testing ).","title":"Development Workflow"},{"location":"development/building/#regenerating-protobuf-code","text":"If you modify .proto files in api/proto/ , regenerate the Go code with: # Install protoc and the Go plugin (once) go install google.golang.org/protobuf/cmd/protoc-gen-go@latest go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest # Regenerate protoc \\ --go_out = . \\ --go-grpc_out = . \\ api/proto/*.proto","title":"Regenerating Protobuf Code"},{"location":"development/building/#common-build-flags","text":"Flag Purpose go build -race Enable the race detector (recommended during development) go build -ldflags=\"-s -w\" Strip debug info for smaller production binaries CGO_ENABLED=0 Produce a fully static binary (needed for distroless Docker images) Example optimized build: CGO_ENABLED = 0 go build \\ -ldflags = \"-s -w\" \\ -o bin/main-worker \\ ./cmd/main-worker/","title":"Common Build Flags"},{"location":"development/project-structure/","text":"Project Structure \u00b6 DeltaDatabase follows the standard Go project layout. . \u251c\u2500\u2500 cmd / \u2502 \u251c\u2500\u2500 main - worker / # Main Worker entry point & server \u2502 \u2502 \u251c\u2500\u2500 main . go # Flag parsing and startup \u2502 \u2502 \u251c\u2500\u2500 server . go # gRPC + REST handler \u2502 \u2502 \u251c\u2500\u2500 frontend . go # Embedded web UI handler \u2502 \u2502 \u2514\u2500\u2500 static / \u2502 \u2502 \u2514\u2500\u2500 index . html # Single - page management app ( embedded ) \u2502 \u2514\u2500\u2500 proc - worker / # Processing Worker entry point \u2502 \u251c\u2500\u2500 main . go # Flag parsing and startup \u2502 \u251c\u2500\u2500 worker . go # Subscription & key management \u2502 \u2514\u2500\u2500 server . go # gRPC Process handler ( GET / PUT ) \u251c\u2500\u2500 pkg / \u2502 \u251c\u2500\u2500 crypto / # AES - GCM encryption + RSA key wrapping \u2502 \u251c\u2500\u2500 cache / # LRU in - memory cache \u2502 \u251c\u2500\u2500 fs / # Shared filesystem storage + file locking \u2502 \u251c\u2500\u2500 metrics / # Operational metrics \u2502 \u2514\u2500\u2500 schema / # JSON Schema draft - 07 validation \u251c\u2500\u2500 internal / \u2502 \u251c\u2500\u2500 auth / # Token manager + worker authenticator \u2502 \u2514\u2500\u2500 routing / # Worker registry + routing logic \u251c\u2500\u2500 api / \u2502 \u2514\u2500\u2500 proto / # Protobuf definitions + generated Go code \u251c\u2500\u2500 shared / \u2502 \u2514\u2500\u2500 db / \u2502 \u251c\u2500\u2500 files / # Encrypted entity blobs ( runtime data ) \u2502 \u2514\u2500\u2500 templates / # JSON Schema templates \u251c\u2500\u2500 tests / # Python integration & end - to - end tests \u2502 \u251c\u2500\u2500 requirements . txt \u2502 \u251c\u2500\u2500 test_authentication . py \u2502 \u251c\u2500\u2500 test_encryption . py \u2502 \u251c\u2500\u2500 test_e2e_security . py \u2502 \u251c\u2500\u2500 test_benchmarks . py \u2502 \u2514\u2500\u2500 test_whole . py \u251c\u2500\u2500 deploy / \u2502 \u251c\u2500\u2500 docker / # Dockerfiles \u2502 \u2502 \u251c\u2500\u2500 Dockerfile . main - worker \u2502 \u2502 \u251c\u2500\u2500 Dockerfile . proc - worker \u2502 \u2502 \u251c\u2500\u2500 Dockerfile . all - in - one \u2502 \u2502 \u2514\u2500\u2500 entrypoint - all - in - one . sh \u2502 \u251c\u2500\u2500 docker - compose / # Docker Compose configurations \u2502 \u2502 \u251c\u2500\u2500 docker - compose . all - in - one . yml \u2502 \u2502 \u251c\u2500\u2500 docker - compose . one - main - one - worker . yml \u2502 \u2502 \u251c\u2500\u2500 docker - compose . one - main - multiple - workers . yml \u2502 \u2502 \u2514\u2500\u2500 docker - compose . with - s3 . yml \u2502 \u2514\u2500\u2500 kubernetes / # Kubernetes manifests \u2502 \u251c\u2500\u2500 shared - pvc . yaml \u2502 \u251c\u2500\u2500 main - worker . yaml \u2502 \u251c\u2500\u2500 proc - worker . yaml \u2502 \u251c\u2500\u2500 proc - worker - hpa . yaml \u2502 \u2514\u2500\u2500 s3 - config . yaml \u251c\u2500\u2500 examples / # Deployment guides ( Markdown ) \u2502 \u251c\u2500\u2500 01 - all - in - one . md \u2502 \u251c\u2500\u2500 02 - one - main - multiple - workers . md \u2502 \u251c\u2500\u2500 03 - one - main - one - worker . md \u2502 \u251c\u2500\u2500 04 - kubernetes - autoscaling . md \u2502 \u2514\u2500\u2500 05 - s3 - compatible - storage . md \u251c\u2500\u2500 Agents . md # Core system design document \u251c\u2500\u2500 BUILDING . md # Build from source & testing \u251c\u2500\u2500 Guideline . md # Coding standards \u251c\u2500\u2500 LICENSE \u2514\u2500\u2500 README . md Package Responsibilities \u00b6 pkg/crypto \u00b6 Provides all cryptographic primitives: AES-256-GCM encryption and decryption of entity blobs. RSA-OAEP key wrapping \u2014 used by the Main Worker to vend the master key to Processing Workers. Nonce generation (random 12-byte IV per entity write). pkg/cache \u00b6 In-memory LRU cache with optional TTL support: Backed by github.com/hashicorp/golang-lru . Keyed by \"<database>/<entity_key>\" . Stores the decrypted JSON and the entity version number (for coherence checks). Thread-safe. pkg/fs \u00b6 Shared filesystem abstraction: Implements the storage interface for both POSIX filesystem and S3-compatible backends. File-level advisory locks ( flock ) prevent concurrent writes on shared-FS. Atomic write path: encrypt \u2192 write temp file \u2192 fdatasync \u2192 rename. S3 backend uses github.com/minio/minio-go for object operations. pkg/schema \u00b6 JSON Schema validation: Validates JSON documents against draft-07 schemas using github.com/xeipuuv/gojsonschema . Loads schemas from the configured templates directory on demand and caches them in memory. pkg/metrics \u00b6 Operational observability: Cache hit/miss counters. Encryption/decryption error rates. Subscription and key rotation event counters. internal/auth \u00b6 Token management: Issues and validates Bearer tokens for external clients. Issues and validates short-lived tokens for Processing Workers. Token expiry is configurable via -client-ttl and -worker-ttl . internal/routing \u00b6 Worker registry: Maintains the set of active Processing Workers. Implements cache-aware + least-loaded routing. Removes workers that fail health checks. api/proto \u00b6 Protocol Buffer definitions: Subscribe RPC \u2014 used by Processing Workers to register with the Main Worker. Process RPC \u2014 used by the Main Worker to forward GET/PUT operations to workers. Generated Go code is committed alongside the .proto files. Adding a New Package \u00b6 Follow these steps when adding a new pkg/ module: Create pkg/<name>/ with a doc.go comment explaining the package purpose. Add a README.md in the directory explaining purpose, usage, and dependencies. Write unit tests with 100% coverage using github.com/stretchr/testify . Update Agents.md if the new module changes the system architecture.","title":"Project Structure"},{"location":"development/project-structure/#project-structure","text":"DeltaDatabase follows the standard Go project layout. . \u251c\u2500\u2500 cmd / \u2502 \u251c\u2500\u2500 main - worker / # Main Worker entry point & server \u2502 \u2502 \u251c\u2500\u2500 main . go # Flag parsing and startup \u2502 \u2502 \u251c\u2500\u2500 server . go # gRPC + REST handler \u2502 \u2502 \u251c\u2500\u2500 frontend . go # Embedded web UI handler \u2502 \u2502 \u2514\u2500\u2500 static / \u2502 \u2502 \u2514\u2500\u2500 index . html # Single - page management app ( embedded ) \u2502 \u2514\u2500\u2500 proc - worker / # Processing Worker entry point \u2502 \u251c\u2500\u2500 main . go # Flag parsing and startup \u2502 \u251c\u2500\u2500 worker . go # Subscription & key management \u2502 \u2514\u2500\u2500 server . go # gRPC Process handler ( GET / PUT ) \u251c\u2500\u2500 pkg / \u2502 \u251c\u2500\u2500 crypto / # AES - GCM encryption + RSA key wrapping \u2502 \u251c\u2500\u2500 cache / # LRU in - memory cache \u2502 \u251c\u2500\u2500 fs / # Shared filesystem storage + file locking \u2502 \u251c\u2500\u2500 metrics / # Operational metrics \u2502 \u2514\u2500\u2500 schema / # JSON Schema draft - 07 validation \u251c\u2500\u2500 internal / \u2502 \u251c\u2500\u2500 auth / # Token manager + worker authenticator \u2502 \u2514\u2500\u2500 routing / # Worker registry + routing logic \u251c\u2500\u2500 api / \u2502 \u2514\u2500\u2500 proto / # Protobuf definitions + generated Go code \u251c\u2500\u2500 shared / \u2502 \u2514\u2500\u2500 db / \u2502 \u251c\u2500\u2500 files / # Encrypted entity blobs ( runtime data ) \u2502 \u2514\u2500\u2500 templates / # JSON Schema templates \u251c\u2500\u2500 tests / # Python integration & end - to - end tests \u2502 \u251c\u2500\u2500 requirements . txt \u2502 \u251c\u2500\u2500 test_authentication . py \u2502 \u251c\u2500\u2500 test_encryption . py \u2502 \u251c\u2500\u2500 test_e2e_security . py \u2502 \u251c\u2500\u2500 test_benchmarks . py \u2502 \u2514\u2500\u2500 test_whole . py \u251c\u2500\u2500 deploy / \u2502 \u251c\u2500\u2500 docker / # Dockerfiles \u2502 \u2502 \u251c\u2500\u2500 Dockerfile . main - worker \u2502 \u2502 \u251c\u2500\u2500 Dockerfile . proc - worker \u2502 \u2502 \u251c\u2500\u2500 Dockerfile . all - in - one \u2502 \u2502 \u2514\u2500\u2500 entrypoint - all - in - one . sh \u2502 \u251c\u2500\u2500 docker - compose / # Docker Compose configurations \u2502 \u2502 \u251c\u2500\u2500 docker - compose . all - in - one . yml \u2502 \u2502 \u251c\u2500\u2500 docker - compose . one - main - one - worker . yml \u2502 \u2502 \u251c\u2500\u2500 docker - compose . one - main - multiple - workers . yml \u2502 \u2502 \u2514\u2500\u2500 docker - compose . with - s3 . yml \u2502 \u2514\u2500\u2500 kubernetes / # Kubernetes manifests \u2502 \u251c\u2500\u2500 shared - pvc . yaml \u2502 \u251c\u2500\u2500 main - worker . yaml \u2502 \u251c\u2500\u2500 proc - worker . yaml \u2502 \u251c\u2500\u2500 proc - worker - hpa . yaml \u2502 \u2514\u2500\u2500 s3 - config . yaml \u251c\u2500\u2500 examples / # Deployment guides ( Markdown ) \u2502 \u251c\u2500\u2500 01 - all - in - one . md \u2502 \u251c\u2500\u2500 02 - one - main - multiple - workers . md \u2502 \u251c\u2500\u2500 03 - one - main - one - worker . md \u2502 \u251c\u2500\u2500 04 - kubernetes - autoscaling . md \u2502 \u2514\u2500\u2500 05 - s3 - compatible - storage . md \u251c\u2500\u2500 Agents . md # Core system design document \u251c\u2500\u2500 BUILDING . md # Build from source & testing \u251c\u2500\u2500 Guideline . md # Coding standards \u251c\u2500\u2500 LICENSE \u2514\u2500\u2500 README . md","title":"Project Structure"},{"location":"development/project-structure/#package-responsibilities","text":"","title":"Package Responsibilities"},{"location":"development/project-structure/#pkgcrypto","text":"Provides all cryptographic primitives: AES-256-GCM encryption and decryption of entity blobs. RSA-OAEP key wrapping \u2014 used by the Main Worker to vend the master key to Processing Workers. Nonce generation (random 12-byte IV per entity write).","title":"pkg/crypto"},{"location":"development/project-structure/#pkgcache","text":"In-memory LRU cache with optional TTL support: Backed by github.com/hashicorp/golang-lru . Keyed by \"<database>/<entity_key>\" . Stores the decrypted JSON and the entity version number (for coherence checks). Thread-safe.","title":"pkg/cache"},{"location":"development/project-structure/#pkgfs","text":"Shared filesystem abstraction: Implements the storage interface for both POSIX filesystem and S3-compatible backends. File-level advisory locks ( flock ) prevent concurrent writes on shared-FS. Atomic write path: encrypt \u2192 write temp file \u2192 fdatasync \u2192 rename. S3 backend uses github.com/minio/minio-go for object operations.","title":"pkg/fs"},{"location":"development/project-structure/#pkgschema","text":"JSON Schema validation: Validates JSON documents against draft-07 schemas using github.com/xeipuuv/gojsonschema . Loads schemas from the configured templates directory on demand and caches them in memory.","title":"pkg/schema"},{"location":"development/project-structure/#pkgmetrics","text":"Operational observability: Cache hit/miss counters. Encryption/decryption error rates. Subscription and key rotation event counters.","title":"pkg/metrics"},{"location":"development/project-structure/#internalauth","text":"Token management: Issues and validates Bearer tokens for external clients. Issues and validates short-lived tokens for Processing Workers. Token expiry is configurable via -client-ttl and -worker-ttl .","title":"internal/auth"},{"location":"development/project-structure/#internalrouting","text":"Worker registry: Maintains the set of active Processing Workers. Implements cache-aware + least-loaded routing. Removes workers that fail health checks.","title":"internal/routing"},{"location":"development/project-structure/#apiproto","text":"Protocol Buffer definitions: Subscribe RPC \u2014 used by Processing Workers to register with the Main Worker. Process RPC \u2014 used by the Main Worker to forward GET/PUT operations to workers. Generated Go code is committed alongside the .proto files.","title":"api/proto"},{"location":"development/project-structure/#adding-a-new-package","text":"Follow these steps when adding a new pkg/ module: Create pkg/<name>/ with a doc.go comment explaining the package purpose. Add a README.md in the directory explaining purpose, usage, and dependencies. Write unit tests with 100% coverage using github.com/stretchr/testify . Update Agents.md if the new module changes the system architecture.","title":"Adding a New Package"},{"location":"development/testing/","text":"Testing \u00b6 DeltaDatabase has two complementary test suites: Go unit tests \u2014 fast, isolated tests for each pkg/ module. Python integration tests \u2014 end-to-end tests that run both workers and verify behaviour through the REST API. Go Unit Tests \u00b6 Run all Go unit tests from the repository root: go test ./... With the race detector enabled (recommended during development): go test -race ./... With coverage report: go test -coverprofile = coverage.out ./... go tool cover -html = coverage.out Test Coverage Requirements \u00b6 Every pkg/ module must maintain 100% unit test coverage . Tests use github.com/stretchr/testify for assertions and testify/mock for interface mocks. Python Integration Tests \u00b6 Setup (once) \u00b6 cd tests pip install -r requirements.txt Individual Test Suites \u00b6 Suite Command What it tests Authentication pytest tests/test_authentication.py -v Login, token expiry, invalid tokens Encryption pytest tests/test_encryption.py -v AES-GCM round-trips, tamper detection Security pytest tests/test_e2e_security.py -v Injection, path traversal, unauthorized access Benchmarks pytest tests/test_benchmarks.py -v --benchmark-sort=mean Throughput and latency measurements Full E2E pytest tests/test_whole.py -v Complete product behaviour Running the Full Suite \u00b6 The full end-to-end suite requires both workers to be running before you start pytest: # Terminal 1 \u2014 start the Main Worker ./bin/main-worker -grpc-addr = 127 .0.0.1:50051 -rest-addr = 127 .0.0.1:8080 -shared-fs = ./shared/db # Terminal 2 \u2014 start a Processing Worker ./bin/proc-worker -main-addr = 127 .0.0.1:50051 -worker-id = proc-1 -grpc-addr = 127 .0.0.1:50052 -shared-fs = ./shared/db # Terminal 3 \u2014 run the tests pytest tests/test_whole.py -v Benchmark Results \u00b6 See the Benchmark Results page for measured numbers. Test File Overview \u00b6 File Description tests/test_authentication.py Verifies login, token lifecycle, invalid credentials tests/test_encryption.py Confirms data is encrypted on disk and correctly decrypted on read tests/test_e2e_security.py Attacks: path traversal in keys, oversized payloads, token replay tests/test_benchmarks.py Measures PUT/GET throughput and latency under sequential and concurrent load tests/test_whole.py Full product test: auth \u2192 schema \u2192 write \u2192 read \u2192 cache hit \u2192 concurrency Continuous Integration \u00b6 All tests run automatically on every pull request via GitHub Actions. The pipeline: Builds both workers with go build . Runs go test -race ./... . Starts both workers, runs pytest tests/test_whole.py -v . Reports coverage.","title":"Testing"},{"location":"development/testing/#testing","text":"DeltaDatabase has two complementary test suites: Go unit tests \u2014 fast, isolated tests for each pkg/ module. Python integration tests \u2014 end-to-end tests that run both workers and verify behaviour through the REST API.","title":"Testing"},{"location":"development/testing/#go-unit-tests","text":"Run all Go unit tests from the repository root: go test ./... With the race detector enabled (recommended during development): go test -race ./... With coverage report: go test -coverprofile = coverage.out ./... go tool cover -html = coverage.out","title":"Go Unit Tests"},{"location":"development/testing/#test-coverage-requirements","text":"Every pkg/ module must maintain 100% unit test coverage . Tests use github.com/stretchr/testify for assertions and testify/mock for interface mocks.","title":"Test Coverage Requirements"},{"location":"development/testing/#python-integration-tests","text":"","title":"Python Integration Tests"},{"location":"development/testing/#setup-once","text":"cd tests pip install -r requirements.txt","title":"Setup (once)"},{"location":"development/testing/#individual-test-suites","text":"Suite Command What it tests Authentication pytest tests/test_authentication.py -v Login, token expiry, invalid tokens Encryption pytest tests/test_encryption.py -v AES-GCM round-trips, tamper detection Security pytest tests/test_e2e_security.py -v Injection, path traversal, unauthorized access Benchmarks pytest tests/test_benchmarks.py -v --benchmark-sort=mean Throughput and latency measurements Full E2E pytest tests/test_whole.py -v Complete product behaviour","title":"Individual Test Suites"},{"location":"development/testing/#running-the-full-suite","text":"The full end-to-end suite requires both workers to be running before you start pytest: # Terminal 1 \u2014 start the Main Worker ./bin/main-worker -grpc-addr = 127 .0.0.1:50051 -rest-addr = 127 .0.0.1:8080 -shared-fs = ./shared/db # Terminal 2 \u2014 start a Processing Worker ./bin/proc-worker -main-addr = 127 .0.0.1:50051 -worker-id = proc-1 -grpc-addr = 127 .0.0.1:50052 -shared-fs = ./shared/db # Terminal 3 \u2014 run the tests pytest tests/test_whole.py -v","title":"Running the Full Suite"},{"location":"development/testing/#benchmark-results","text":"See the Benchmark Results page for measured numbers.","title":"Benchmark Results"},{"location":"development/testing/#test-file-overview","text":"File Description tests/test_authentication.py Verifies login, token lifecycle, invalid credentials tests/test_encryption.py Confirms data is encrypted on disk and correctly decrypted on read tests/test_e2e_security.py Attacks: path traversal in keys, oversized payloads, token replay tests/test_benchmarks.py Measures PUT/GET throughput and latency under sequential and concurrent load tests/test_whole.py Full product test: auth \u2192 schema \u2192 write \u2192 read \u2192 cache hit \u2192 concurrency","title":"Test File Overview"},{"location":"development/testing/#continuous-integration","text":"All tests run automatically on every pull request via GitHub Actions. The pipeline: Builds both workers with go build . Runs go test -race ./... . Starts both workers, runs pytest tests/test_whole.py -v . Reports coverage.","title":"Continuous Integration"},{"location":"usage/","text":"Usage \u00b6 This section covers everything you need to use DeltaDatabase in your applications and infrastructure. In This Section \u00b6 Page Description Quick Start Get DeltaDatabase running in under 5 minutes Configuration All flags and environment variables API Reference Complete REST API documentation Authentication Tokens, login, and token expiry JSON Schema Templates Defining and validating entity shapes Deployment Docker, Docker Compose, Kubernetes, S3 Security Model Encryption, key management, hardening Management UI Browser-based UI for managing databases, schemas, and API keys Caching Model How the LRU cache works Benchmark Results Measured performance numbers Examples Real-world usage examples Concepts \u00b6 Databases and Entities \u00b6 DeltaDatabase organizes data into databases and entities : A database is a named collection (e.g., chatdb , userdb ). An entity is a named JSON document within a database (e.g., session_001 ). Think of it as: database = table, entity key = primary key, entity value = JSON row. chatdb/ \u251c\u2500\u2500 session_001 \u2192 {\"messages\": [...]} \u251c\u2500\u2500 session_002 \u2192 {\"messages\": [...]} \u2514\u2500\u2500 session_003 \u2192 {\"messages\": [...]} The REST API \u00b6 All entity operations use two endpoints: PUT /entity/{database} \u2014 create or update one or more entities GET /entity/{database}?key=... \u2014 retrieve a single entity Both require an Authorization: Bearer <token> header. JSON Schema Validation \u00b6 Before any entity is stored, it is validated against the JSON Schema registered for that database. Invalid data is rejected with an HTTP 400 response. Schemas are stored in {shared-fs}/templates/ or can be managed via the REST API or the web UI.","title":"Overview"},{"location":"usage/#usage","text":"This section covers everything you need to use DeltaDatabase in your applications and infrastructure.","title":"Usage"},{"location":"usage/#in-this-section","text":"Page Description Quick Start Get DeltaDatabase running in under 5 minutes Configuration All flags and environment variables API Reference Complete REST API documentation Authentication Tokens, login, and token expiry JSON Schema Templates Defining and validating entity shapes Deployment Docker, Docker Compose, Kubernetes, S3 Security Model Encryption, key management, hardening Management UI Browser-based UI for managing databases, schemas, and API keys Caching Model How the LRU cache works Benchmark Results Measured performance numbers Examples Real-world usage examples","title":"In This Section"},{"location":"usage/#concepts","text":"","title":"Concepts"},{"location":"usage/#databases-and-entities","text":"DeltaDatabase organizes data into databases and entities : A database is a named collection (e.g., chatdb , userdb ). An entity is a named JSON document within a database (e.g., session_001 ). Think of it as: database = table, entity key = primary key, entity value = JSON row. chatdb/ \u251c\u2500\u2500 session_001 \u2192 {\"messages\": [...]} \u251c\u2500\u2500 session_002 \u2192 {\"messages\": [...]} \u2514\u2500\u2500 session_003 \u2192 {\"messages\": [...]}","title":"Databases and Entities"},{"location":"usage/#the-rest-api","text":"All entity operations use two endpoints: PUT /entity/{database} \u2014 create or update one or more entities GET /entity/{database}?key=... \u2014 retrieve a single entity Both require an Authorization: Bearer <token> header.","title":"The REST API"},{"location":"usage/#json-schema-validation","text":"Before any entity is stored, it is validated against the JSON Schema registered for that database. Invalid data is rejected with an HTTP 400 response. Schemas are stored in {shared-fs}/templates/ or can be managed via the REST API or the web UI.","title":"JSON Schema Validation"},{"location":"usage/api-reference/","text":"REST API Reference \u00b6 All endpoints are served by the Main Worker at the configured -rest-addr (default 127.0.0.1:8080 ). Entity endpoints require an Authorization: Bearer <token> header. See Authentication for how to obtain credentials. Authentication \u00b6 POST /api/login \u00b6 Exchange an admin key or API key for a short-lived session token. The session token inherits the permissions of the key used. Request: POST /api/login Content-Type: application/json {\"key\": \"YOUR_ADMIN_OR_API_KEY\"} Response 200 OK : { \"token\" : \"bWDQOfIs\u2026\" , \"client_id\" : \"admin\" , \"expires_at\" : \"2026-02-26T09:00:00Z\" , \"permissions\" : [ \"read\" , \"write\" , \"admin\" ] } Dev-mode only (when no -admin-key is configured): POST /api/login Content-Type: application/json {\"client_id\": \"myapp\"} Example: TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"key\":\"YOUR_ADMIN_KEY\"}' | jq -r .token ) Health \u00b6 GET /health \u00b6 Returns system health. No authentication required. Response 200 OK : { \"status\" : \"ok\" } Entities \u00b6 PUT /entity/{database} \u00b6 Create or update one or more entities in a database. Requires write permission. Path parameter: database \u2014 name of the database (e.g., chatdb ). Request: PUT /entity/chatdb Authorization: Bearer <token> Content-Type: application/json { \"session_001\": {\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]}, \"session_002\": {\"messages\": [{\"role\": \"user\", \"content\": \"Hi there!\"}]} } The request body is a JSON object where each key is an entity key and each value is the entity's JSON document. Multiple entities can be written in a single request. Response 200 OK : { \"status\" : \"ok\" } Error responses: Code Meaning 400 Invalid JSON, schema validation failure, or body exceeds 1 MiB 401 Missing or invalid Bearer token 403 Token lacks write permission Example: curl -s -X PUT http://127.0.0.1:8080/entity/chatdb \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{\"session_001\": {\"messages\": [{\"role\":\"user\",\"content\":\"Hello!\"}]}}' GET /entity/{database}?key={entityKey} \u00b6 Retrieve a single entity by key. Requires read permission. Path parameter: database \u2014 name of the database. Query parameter: key \u2014 entity key. Request: GET /entity/chatdb?key=session_001 Authorization: Bearer <token> Response 200 OK \u2014 the entity's JSON document: { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"Hello!\" }]} Error responses: Code Meaning 400 Missing key query parameter 401 Missing or invalid Bearer token 403 Token lacks read permission 404 Entity not found Example: curl -s \"http://127.0.0.1:8080/entity/chatdb?key=session_001\" \\ -H \"Authorization: Bearer $TOKEN \" Schemas \u00b6 GET /admin/schemas \u00b6 List all registered schema IDs. No authentication required. Response 200 OK : [ \"chat.v1\" , \"user_credentials.v1\" , \"user_chats.v1\" ] GET /schema/{schemaID} \u00b6 Retrieve a JSON Schema document. No authentication required. Path parameter: schemaID \u2014 the schema identifier (e.g., chat.v1 ). Response 200 OK : { \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"chat.v1\" , \"type\" : \"object\" , \"properties\" : { \"messages\" : { \"type\" : \"array\" } }, \"required\" : [ \"messages\" ] } Error responses: Code Meaning 404 Schema not found PUT /schema/{schemaID} \u00b6 Create or replace a JSON Schema. Requires write permission. Path parameter: schemaID \u2014 the schema identifier. Request: PUT /schema/product.v1 Authorization: Bearer <token> Content-Type: application/json { \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"product.v1\", \"type\": \"object\", \"properties\": { \"name\": {\"type\": \"string\"}, \"price\": {\"type\": \"number\", \"minimum\": 0} }, \"required\": [\"name\", \"price\"] } Response 200 OK : { \"status\" : \"ok\" } Error responses: Code Meaning 400 Invalid JSON or invalid JSON Schema 401 Missing or invalid Bearer token 403 Token lacks write permission API Keys \u00b6 POST /api/keys \u00b6 Create a new named API key with RBAC permissions. Requires admin permission. Request: POST /api/keys Authorization: Bearer <admin-key-or-token> Content-Type: application/json { \"name\": \"ci-deploy\", \"permissions\": [\"read\", \"write\"], \"expires_in\": \"7d\" } expires_in is optional (e.g. \"24h\" , \"7d\" , \"30d\" ). Omit for a non-expiring key. Response 201 Created (secret shown once only ): { \"id\" : \"a1b2c3d4e5f6a7b8\" , \"name\" : \"ci-deploy\" , \"secret\" : \"dk_abc123\u2026\" , \"permissions\" : [ \"read\" , \"write\" ], \"expires_at\" : \"2026-03-04T09:00:00Z\" , \"created_at\" : \"2026-02-25T09:00:00Z\" } Error responses: Code Meaning 400 Missing name or permissions 401 Missing or invalid Bearer token 403 Token lacks admin permission GET /api/keys \u00b6 List all API keys (secrets not returned). Requires admin permission. Response 200 OK : [ { \"id\" : \"a1b2c3d4e5f6a7b8\" , \"name\" : \"ci-deploy\" , \"key_hash\" : \"\u2026\" , \"permissions\" : [ \"read\" , \"write\" ], \"created_at\" : \"2026-02-25T09:00:00Z\" , \"enabled\" : true } ] DELETE /api/keys/{id} \u00b6 Permanently delete an API key by ID. Requires admin permission. Path parameter: id \u2014 the key's ID (from GET /api/keys ). Response 200 OK : { \"status\" : \"ok\" } Error responses: Code Meaning 401 Missing or invalid Bearer token 403 Token lacks admin permission 404 Key ID not found Admin \u00b6 GET /admin/workers \u00b6 Returns all registered Processing Workers and their status. Requires admin permission. Response 200 OK : [ { \"worker_id\" : \"proc-1\" , \"status\" : \"Available\" , \"key_id\" : \"main-key-v1\" , \"last_seen\" : \"2026-02-24T12:01:30Z\" , \"tags\" : { \"grpc_addr\" : \"127.0.0.1:50052\" } }, { \"worker_id\" : \"proc-2\" , \"status\" : \"Available\" , \"key_id\" : \"main-key-v1\" , \"last_seen\" : \"2026-02-24T12:01:28Z\" , \"tags\" : { \"grpc_addr\" : \"127.0.0.1:50053\" } } ] Error Format \u00b6 All error responses return a JSON body with an error field: { \"error\" : \"entity not found\" } HTTP Code Meaning 200 Success 201 Created (new API key) 400 Bad request (invalid JSON, schema violation, missing parameter) 401 Unauthorized (missing or expired token) 403 Forbidden (valid token but insufficient permissions) 404 Not found (entity, schema, or API key does not exist) 413 Request body too large (exceeds 1 MiB limit) 500 Internal server error Request Limits \u00b6 Limit Value Maximum body size (PUT entity, PUT schema) 1 MiB Entity key characters No / , \\ , or .. sequences Database name characters No / , \\ , or .. sequences Schema ID characters No / , \\ , or .. sequences","title":"API Reference"},{"location":"usage/api-reference/#rest-api-reference","text":"All endpoints are served by the Main Worker at the configured -rest-addr (default 127.0.0.1:8080 ). Entity endpoints require an Authorization: Bearer <token> header. See Authentication for how to obtain credentials.","title":"REST API Reference"},{"location":"usage/api-reference/#authentication","text":"","title":"Authentication"},{"location":"usage/api-reference/#post-apilogin","text":"Exchange an admin key or API key for a short-lived session token. The session token inherits the permissions of the key used. Request: POST /api/login Content-Type: application/json {\"key\": \"YOUR_ADMIN_OR_API_KEY\"} Response 200 OK : { \"token\" : \"bWDQOfIs\u2026\" , \"client_id\" : \"admin\" , \"expires_at\" : \"2026-02-26T09:00:00Z\" , \"permissions\" : [ \"read\" , \"write\" , \"admin\" ] } Dev-mode only (when no -admin-key is configured): POST /api/login Content-Type: application/json {\"client_id\": \"myapp\"} Example: TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"key\":\"YOUR_ADMIN_KEY\"}' | jq -r .token )","title":"POST /api/login"},{"location":"usage/api-reference/#health","text":"","title":"Health"},{"location":"usage/api-reference/#get-health","text":"Returns system health. No authentication required. Response 200 OK : { \"status\" : \"ok\" }","title":"GET /health"},{"location":"usage/api-reference/#entities","text":"","title":"Entities"},{"location":"usage/api-reference/#put-entitydatabase","text":"Create or update one or more entities in a database. Requires write permission. Path parameter: database \u2014 name of the database (e.g., chatdb ). Request: PUT /entity/chatdb Authorization: Bearer <token> Content-Type: application/json { \"session_001\": {\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]}, \"session_002\": {\"messages\": [{\"role\": \"user\", \"content\": \"Hi there!\"}]} } The request body is a JSON object where each key is an entity key and each value is the entity's JSON document. Multiple entities can be written in a single request. Response 200 OK : { \"status\" : \"ok\" } Error responses: Code Meaning 400 Invalid JSON, schema validation failure, or body exceeds 1 MiB 401 Missing or invalid Bearer token 403 Token lacks write permission Example: curl -s -X PUT http://127.0.0.1:8080/entity/chatdb \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{\"session_001\": {\"messages\": [{\"role\":\"user\",\"content\":\"Hello!\"}]}}'","title":"PUT /entity/{database}"},{"location":"usage/api-reference/#get-entitydatabasekeyentitykey","text":"Retrieve a single entity by key. Requires read permission. Path parameter: database \u2014 name of the database. Query parameter: key \u2014 entity key. Request: GET /entity/chatdb?key=session_001 Authorization: Bearer <token> Response 200 OK \u2014 the entity's JSON document: { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"Hello!\" }]} Error responses: Code Meaning 400 Missing key query parameter 401 Missing or invalid Bearer token 403 Token lacks read permission 404 Entity not found Example: curl -s \"http://127.0.0.1:8080/entity/chatdb?key=session_001\" \\ -H \"Authorization: Bearer $TOKEN \"","title":"GET /entity/{database}?key={entityKey}"},{"location":"usage/api-reference/#schemas","text":"","title":"Schemas"},{"location":"usage/api-reference/#get-adminschemas","text":"List all registered schema IDs. No authentication required. Response 200 OK : [ \"chat.v1\" , \"user_credentials.v1\" , \"user_chats.v1\" ]","title":"GET /admin/schemas"},{"location":"usage/api-reference/#get-schemaschemaid","text":"Retrieve a JSON Schema document. No authentication required. Path parameter: schemaID \u2014 the schema identifier (e.g., chat.v1 ). Response 200 OK : { \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"chat.v1\" , \"type\" : \"object\" , \"properties\" : { \"messages\" : { \"type\" : \"array\" } }, \"required\" : [ \"messages\" ] } Error responses: Code Meaning 404 Schema not found","title":"GET /schema/{schemaID}"},{"location":"usage/api-reference/#put-schemaschemaid","text":"Create or replace a JSON Schema. Requires write permission. Path parameter: schemaID \u2014 the schema identifier. Request: PUT /schema/product.v1 Authorization: Bearer <token> Content-Type: application/json { \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"product.v1\", \"type\": \"object\", \"properties\": { \"name\": {\"type\": \"string\"}, \"price\": {\"type\": \"number\", \"minimum\": 0} }, \"required\": [\"name\", \"price\"] } Response 200 OK : { \"status\" : \"ok\" } Error responses: Code Meaning 400 Invalid JSON or invalid JSON Schema 401 Missing or invalid Bearer token 403 Token lacks write permission","title":"PUT /schema/{schemaID}"},{"location":"usage/api-reference/#api-keys","text":"","title":"API Keys"},{"location":"usage/api-reference/#post-apikeys","text":"Create a new named API key with RBAC permissions. Requires admin permission. Request: POST /api/keys Authorization: Bearer <admin-key-or-token> Content-Type: application/json { \"name\": \"ci-deploy\", \"permissions\": [\"read\", \"write\"], \"expires_in\": \"7d\" } expires_in is optional (e.g. \"24h\" , \"7d\" , \"30d\" ). Omit for a non-expiring key. Response 201 Created (secret shown once only ): { \"id\" : \"a1b2c3d4e5f6a7b8\" , \"name\" : \"ci-deploy\" , \"secret\" : \"dk_abc123\u2026\" , \"permissions\" : [ \"read\" , \"write\" ], \"expires_at\" : \"2026-03-04T09:00:00Z\" , \"created_at\" : \"2026-02-25T09:00:00Z\" } Error responses: Code Meaning 400 Missing name or permissions 401 Missing or invalid Bearer token 403 Token lacks admin permission","title":"POST /api/keys"},{"location":"usage/api-reference/#get-apikeys","text":"List all API keys (secrets not returned). Requires admin permission. Response 200 OK : [ { \"id\" : \"a1b2c3d4e5f6a7b8\" , \"name\" : \"ci-deploy\" , \"key_hash\" : \"\u2026\" , \"permissions\" : [ \"read\" , \"write\" ], \"created_at\" : \"2026-02-25T09:00:00Z\" , \"enabled\" : true } ]","title":"GET /api/keys"},{"location":"usage/api-reference/#delete-apikeysid","text":"Permanently delete an API key by ID. Requires admin permission. Path parameter: id \u2014 the key's ID (from GET /api/keys ). Response 200 OK : { \"status\" : \"ok\" } Error responses: Code Meaning 401 Missing or invalid Bearer token 403 Token lacks admin permission 404 Key ID not found","title":"DELETE /api/keys/{id}"},{"location":"usage/api-reference/#admin","text":"","title":"Admin"},{"location":"usage/api-reference/#get-adminworkers","text":"Returns all registered Processing Workers and their status. Requires admin permission. Response 200 OK : [ { \"worker_id\" : \"proc-1\" , \"status\" : \"Available\" , \"key_id\" : \"main-key-v1\" , \"last_seen\" : \"2026-02-24T12:01:30Z\" , \"tags\" : { \"grpc_addr\" : \"127.0.0.1:50052\" } }, { \"worker_id\" : \"proc-2\" , \"status\" : \"Available\" , \"key_id\" : \"main-key-v1\" , \"last_seen\" : \"2026-02-24T12:01:28Z\" , \"tags\" : { \"grpc_addr\" : \"127.0.0.1:50053\" } } ]","title":"GET /admin/workers"},{"location":"usage/api-reference/#error-format","text":"All error responses return a JSON body with an error field: { \"error\" : \"entity not found\" } HTTP Code Meaning 200 Success 201 Created (new API key) 400 Bad request (invalid JSON, schema violation, missing parameter) 401 Unauthorized (missing or expired token) 403 Forbidden (valid token but insufficient permissions) 404 Not found (entity, schema, or API key does not exist) 413 Request body too large (exceeds 1 MiB limit) 500 Internal server error","title":"Error Format"},{"location":"usage/api-reference/#request-limits","text":"Limit Value Maximum body size (PUT entity, PUT schema) 1 MiB Entity key characters No / , \\ , or .. sequences Database name characters No / , \\ , or .. sequences Schema ID characters No / , \\ , or .. sequences","title":"Request Limits"},{"location":"usage/authentication/","text":"Authentication \u00b6 DeltaDatabase uses a three-tier Bearer token model for external clients and a separate RSA + token handshake for Processing Workers. Three-Tier Authentication Priority \u00b6 Every Authorization: Bearer <value> header is evaluated in this order: Priority Type How to obtain Permissions 1 Admin key Set -admin-key flag or $ADMIN_KEY env var at startup Full access \u2014 bypasses all RBAC 2 API key POST /api/keys (requires admin) Configurable: read , write , and/or admin 3 Session token POST /api/login with your admin key or API key Inherits the permissions of the key used to log in Tip: For scripts and CI pipelines, use an API key ( dk_\u2026 ) directly as the Bearer token \u2014 no login step is required. Client Authentication \u00b6 Option A \u2014 Admin Key (direct Bearer) \u00b6 Supply the admin key directly in every request header (no login required): curl -s http://127.0.0.1:8080/admin/workers \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \" Option B \u2014 API Key (direct Bearer) \u00b6 Create a named API key via the Management UI or REST API, then use its secret directly: # Create a read+write key (requires admin) curl -s -X POST http://127.0.0.1:8080/api/keys \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \" \\ -H 'Content-Type: application/json' \\ -d '{\"name\":\"ci-deploy\",\"permissions\":[\"read\",\"write\"]}' # Use the returned dk_\u2026 secret directly curl -s http://127.0.0.1:8080/entity/mydb?key = hello \\ -H \"Authorization: Bearer dk_abc123\u2026\" Option C \u2014 Session Token (browser / short-lived) \u00b6 Obtain a short-lived session token by posting your admin key or API key to /api/login . The session token inherits the exact permissions of the key used to authenticate. Step 1 \u2014 Login \u00b6 curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"key\": \"YOUR_ADMIN_OR_API_KEY\"}' Response: { \"token\" : \"bWDQOfIsXsdpo1OZhIwcGrRu\u2026\" , \"client_id\" : \"admin\" , \"expires_at\" : \"2026-02-26T09:00:00Z\" , \"permissions\" : [ \"read\" , \"write\" , \"admin\" ] } The token is valid for the duration configured by -client-ttl on the Main Worker (default: 24 hours ). Step 2 \u2014 Use the Token \u00b6 curl -s \"http://127.0.0.1:8080/entity/chatdb?key=session_001\" \\ -H \"Authorization: Bearer bWDQOfIsXsdpo1OZhIwcGrRu\u2026\" Step 3 \u2014 Refresh \u00b6 Tokens cannot be refreshed. Obtain a new token by calling POST /api/login again. Dev Mode (no admin key configured) \u00b6 When the server is started without -admin-key (local development only), the old client_id login is accepted for backwards compatibility: curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\": \"myapp\"}' This issues a session token with read + write permissions. Do not use dev mode in production. Token Expiry \u00b6 Token type Default TTL Configured by Client session token 24 hours -client-ttl on Main Worker Processing Worker session token 1 hour -worker-ttl on Main Worker API Key Management \u00b6 API keys are persisted to disk ( <shared-fs>/_auth/keys.json ) and survive restarts. Create a key \u00b6 # Key with read+write, expires in 7 days curl -s -X POST http://127.0.0.1:8080/api/keys \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \" \\ -H 'Content-Type: application/json' \\ -d '{\"name\":\"ci-deploy\",\"permissions\":[\"read\",\"write\"],\"expires_in\":\"7d\"}' Response (secret shown once only ): { \"id\" : \"a1b2c3d4e5f6a7b8\" , \"name\" : \"ci-deploy\" , \"secret\" : \"dk_abc123\u2026\" , \"permissions\" : [ \"read\" , \"write\" ], \"expires_at\" : \"2026-03-04T09:00:00Z\" , \"created_at\" : \"2026-02-25T09:00:00Z\" } List keys \u00b6 curl -s http://127.0.0.1:8080/api/keys \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \" Delete a key \u00b6 curl -s -X DELETE http://127.0.0.1:8080/api/keys/<key-id> \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \" Permissions \u00b6 Constant Value Grants read \"read\" GET /entity/\u2026 write \"write\" PUT /entity/\u2026 , PUT /schema/\u2026 admin \"admin\" All of the above + key management + /admin/workers Worker Authentication (Internal) \u00b6 Processing Workers authenticate with the Main Worker during subscription using a public-key + token handshake : Worker generates an ephemeral RSA key pair at startup. Worker sends Subscribe(worker_id, rsa_public_key) to the Main Worker over gRPC. Main Worker wraps the AES master key with the worker's RSA public key (RSA-OAEP) and issues a short-lived session token. Worker unwraps the AES key using its RSA private key and stores it in volatile memory. Worker uses the session token for subsequent gRPC calls to the Main Worker. This ensures that the plaintext AES master key never travels over the wire unencrypted . Public Endpoints \u00b6 The following endpoints do not require authentication: Endpoint Description GET /health Health check GET /admin/schemas List schema IDs GET /schema/{id} Retrieve a schema document Securing the API in Production \u00b6 Warning Configure an admin key before exposing the server to any network. Start the Main Worker with -admin-key or set the ADMIN_KEY environment variable. Put the Main Worker behind a reverse proxy (nginx, Traefik) with TLS termination. Create scoped API keys for each service; do not share the admin key. Set a short -client-ttl (e.g., 1h ) for sensitive applications. The -master-key flag value appears in shell history \u2014 use a wrapper script or secrets manager to supply it.","title":"Authentication"},{"location":"usage/authentication/#authentication","text":"DeltaDatabase uses a three-tier Bearer token model for external clients and a separate RSA + token handshake for Processing Workers.","title":"Authentication"},{"location":"usage/authentication/#three-tier-authentication-priority","text":"Every Authorization: Bearer <value> header is evaluated in this order: Priority Type How to obtain Permissions 1 Admin key Set -admin-key flag or $ADMIN_KEY env var at startup Full access \u2014 bypasses all RBAC 2 API key POST /api/keys (requires admin) Configurable: read , write , and/or admin 3 Session token POST /api/login with your admin key or API key Inherits the permissions of the key used to log in Tip: For scripts and CI pipelines, use an API key ( dk_\u2026 ) directly as the Bearer token \u2014 no login step is required.","title":"Three-Tier Authentication Priority"},{"location":"usage/authentication/#client-authentication","text":"","title":"Client Authentication"},{"location":"usage/authentication/#option-a-admin-key-direct-bearer","text":"Supply the admin key directly in every request header (no login required): curl -s http://127.0.0.1:8080/admin/workers \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \"","title":"Option A \u2014 Admin Key (direct Bearer)"},{"location":"usage/authentication/#option-b-api-key-direct-bearer","text":"Create a named API key via the Management UI or REST API, then use its secret directly: # Create a read+write key (requires admin) curl -s -X POST http://127.0.0.1:8080/api/keys \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \" \\ -H 'Content-Type: application/json' \\ -d '{\"name\":\"ci-deploy\",\"permissions\":[\"read\",\"write\"]}' # Use the returned dk_\u2026 secret directly curl -s http://127.0.0.1:8080/entity/mydb?key = hello \\ -H \"Authorization: Bearer dk_abc123\u2026\"","title":"Option B \u2014 API Key (direct Bearer)"},{"location":"usage/authentication/#option-c-session-token-browser-short-lived","text":"Obtain a short-lived session token by posting your admin key or API key to /api/login . The session token inherits the exact permissions of the key used to authenticate.","title":"Option C \u2014 Session Token (browser / short-lived)"},{"location":"usage/authentication/#step-1-login","text":"curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"key\": \"YOUR_ADMIN_OR_API_KEY\"}' Response: { \"token\" : \"bWDQOfIsXsdpo1OZhIwcGrRu\u2026\" , \"client_id\" : \"admin\" , \"expires_at\" : \"2026-02-26T09:00:00Z\" , \"permissions\" : [ \"read\" , \"write\" , \"admin\" ] } The token is valid for the duration configured by -client-ttl on the Main Worker (default: 24 hours ).","title":"Step 1 \u2014 Login"},{"location":"usage/authentication/#step-2-use-the-token","text":"curl -s \"http://127.0.0.1:8080/entity/chatdb?key=session_001\" \\ -H \"Authorization: Bearer bWDQOfIsXsdpo1OZhIwcGrRu\u2026\"","title":"Step 2 \u2014 Use the Token"},{"location":"usage/authentication/#step-3-refresh","text":"Tokens cannot be refreshed. Obtain a new token by calling POST /api/login again.","title":"Step 3 \u2014 Refresh"},{"location":"usage/authentication/#dev-mode-no-admin-key-configured","text":"When the server is started without -admin-key (local development only), the old client_id login is accepted for backwards compatibility: curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\": \"myapp\"}' This issues a session token with read + write permissions. Do not use dev mode in production.","title":"Dev Mode (no admin key configured)"},{"location":"usage/authentication/#token-expiry","text":"Token type Default TTL Configured by Client session token 24 hours -client-ttl on Main Worker Processing Worker session token 1 hour -worker-ttl on Main Worker","title":"Token Expiry"},{"location":"usage/authentication/#api-key-management","text":"API keys are persisted to disk ( <shared-fs>/_auth/keys.json ) and survive restarts.","title":"API Key Management"},{"location":"usage/authentication/#create-a-key","text":"# Key with read+write, expires in 7 days curl -s -X POST http://127.0.0.1:8080/api/keys \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \" \\ -H 'Content-Type: application/json' \\ -d '{\"name\":\"ci-deploy\",\"permissions\":[\"read\",\"write\"],\"expires_in\":\"7d\"}' Response (secret shown once only ): { \"id\" : \"a1b2c3d4e5f6a7b8\" , \"name\" : \"ci-deploy\" , \"secret\" : \"dk_abc123\u2026\" , \"permissions\" : [ \"read\" , \"write\" ], \"expires_at\" : \"2026-03-04T09:00:00Z\" , \"created_at\" : \"2026-02-25T09:00:00Z\" }","title":"Create a key"},{"location":"usage/authentication/#list-keys","text":"curl -s http://127.0.0.1:8080/api/keys \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \"","title":"List keys"},{"location":"usage/authentication/#delete-a-key","text":"curl -s -X DELETE http://127.0.0.1:8080/api/keys/<key-id> \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \"","title":"Delete a key"},{"location":"usage/authentication/#permissions","text":"Constant Value Grants read \"read\" GET /entity/\u2026 write \"write\" PUT /entity/\u2026 , PUT /schema/\u2026 admin \"admin\" All of the above + key management + /admin/workers","title":"Permissions"},{"location":"usage/authentication/#worker-authentication-internal","text":"Processing Workers authenticate with the Main Worker during subscription using a public-key + token handshake : Worker generates an ephemeral RSA key pair at startup. Worker sends Subscribe(worker_id, rsa_public_key) to the Main Worker over gRPC. Main Worker wraps the AES master key with the worker's RSA public key (RSA-OAEP) and issues a short-lived session token. Worker unwraps the AES key using its RSA private key and stores it in volatile memory. Worker uses the session token for subsequent gRPC calls to the Main Worker. This ensures that the plaintext AES master key never travels over the wire unencrypted .","title":"Worker Authentication (Internal)"},{"location":"usage/authentication/#public-endpoints","text":"The following endpoints do not require authentication: Endpoint Description GET /health Health check GET /admin/schemas List schema IDs GET /schema/{id} Retrieve a schema document","title":"Public Endpoints"},{"location":"usage/authentication/#securing-the-api-in-production","text":"Warning Configure an admin key before exposing the server to any network. Start the Main Worker with -admin-key or set the ADMIN_KEY environment variable. Put the Main Worker behind a reverse proxy (nginx, Traefik) with TLS termination. Create scoped API keys for each service; do not share the admin key. Set a short -client-ttl (e.g., 1h ) for sensitive applications. The -master-key flag value appears in shell history \u2014 use a wrapper script or secrets manager to supply it.","title":"Securing the API in Production"},{"location":"usage/benchmarks/","text":"Benchmark Results \u00b6 The following numbers were measured on a standard CI Linux runner (2 vCPU, 7 GB RAM) with both workers running in-process ( go run ). Real hardware will be faster. Results \u00b6 Benchmark Mean latency Throughput REST PUT (sequential, warm) ~1 ms ~1,000 ops/s REST GET (warm cache, sequential) ~1 ms ~1,000 ops/s REST PUT\u2192GET round-trip ~2 ms ~520 ops/s gRPC PUT (proc-worker direct) ~0.6 ms ~1,700 ops/s gRPC GET (warm cache, proc-worker) ~0.3 ms ~3,500 ops/s Concurrent PUT (32 threads \u00d7 20 each) \u2014 ~910 ops/s total Concurrent GET (32 threads \u00d7 25 each) \u2014 ~970 ops/s total Bulk write 1,000 entities ~1 s total ~1,000 ops/s Running the Benchmarks \u00b6 # Install Python dependencies (once) cd tests && pip install -r requirements.txt # Run all benchmarks sorted by mean latency pytest tests/test_benchmarks.py -v --benchmark-sort = mean # Compare against a previous run pytest-benchmark compare Key Observations \u00b6 Cache Hit Rate Is Critical \u00b6 Warm cache GET: ~1 ms \u2014 data served directly from LRU cache, no disk I/O. Cold cache GET: ~3\u20135 ms \u2014 disk read + AES-GCM decrypt + cache update. Tuning -cache-size to cover your working set is the single most impactful performance optimisation. gRPC vs REST \u00b6 gRPC is ~40\u201350% faster than REST for the same operation: Protocol GET latency PUT latency REST (HTTP/JSON) ~1 ms ~1 ms gRPC (direct to proc-worker) ~0.3 ms ~0.6 ms For latency-sensitive applications, use the gRPC API directly. Horizontal Scaling \u00b6 Adding more Processing Workers increases concurrent throughput: Workers Concurrent PUT ops/s 1 ~910 2 ~1,700 (estimated) 4 ~3,000 (estimated) Throughput scales linearly until the shared filesystem becomes the bottleneck. Use S3-compatible storage for higher-throughput multi-worker deployments. Tracking Regressions \u00b6 Run benchmarks on your branch and compare against main : # Run and save baseline pytest tests/test_benchmarks.py --benchmark-save = baseline # After changes pytest tests/test_benchmarks.py --benchmark-compare = baseline","title":"Benchmark Results"},{"location":"usage/benchmarks/#benchmark-results","text":"The following numbers were measured on a standard CI Linux runner (2 vCPU, 7 GB RAM) with both workers running in-process ( go run ). Real hardware will be faster.","title":"Benchmark Results"},{"location":"usage/benchmarks/#results","text":"Benchmark Mean latency Throughput REST PUT (sequential, warm) ~1 ms ~1,000 ops/s REST GET (warm cache, sequential) ~1 ms ~1,000 ops/s REST PUT\u2192GET round-trip ~2 ms ~520 ops/s gRPC PUT (proc-worker direct) ~0.6 ms ~1,700 ops/s gRPC GET (warm cache, proc-worker) ~0.3 ms ~3,500 ops/s Concurrent PUT (32 threads \u00d7 20 each) \u2014 ~910 ops/s total Concurrent GET (32 threads \u00d7 25 each) \u2014 ~970 ops/s total Bulk write 1,000 entities ~1 s total ~1,000 ops/s","title":"Results"},{"location":"usage/benchmarks/#running-the-benchmarks","text":"# Install Python dependencies (once) cd tests && pip install -r requirements.txt # Run all benchmarks sorted by mean latency pytest tests/test_benchmarks.py -v --benchmark-sort = mean # Compare against a previous run pytest-benchmark compare","title":"Running the Benchmarks"},{"location":"usage/benchmarks/#key-observations","text":"","title":"Key Observations"},{"location":"usage/benchmarks/#cache-hit-rate-is-critical","text":"Warm cache GET: ~1 ms \u2014 data served directly from LRU cache, no disk I/O. Cold cache GET: ~3\u20135 ms \u2014 disk read + AES-GCM decrypt + cache update. Tuning -cache-size to cover your working set is the single most impactful performance optimisation.","title":"Cache Hit Rate Is Critical"},{"location":"usage/benchmarks/#grpc-vs-rest","text":"gRPC is ~40\u201350% faster than REST for the same operation: Protocol GET latency PUT latency REST (HTTP/JSON) ~1 ms ~1 ms gRPC (direct to proc-worker) ~0.3 ms ~0.6 ms For latency-sensitive applications, use the gRPC API directly.","title":"gRPC vs REST"},{"location":"usage/benchmarks/#horizontal-scaling","text":"Adding more Processing Workers increases concurrent throughput: Workers Concurrent PUT ops/s 1 ~910 2 ~1,700 (estimated) 4 ~3,000 (estimated) Throughput scales linearly until the shared filesystem becomes the bottleneck. Use S3-compatible storage for higher-throughput multi-worker deployments.","title":"Horizontal Scaling"},{"location":"usage/benchmarks/#tracking-regressions","text":"Run benchmarks on your branch and compare against main : # Run and save baseline pytest tests/test_benchmarks.py --benchmark-save = baseline # After changes pytest tests/test_benchmarks.py --benchmark-compare = baseline","title":"Tracking Regressions"},{"location":"usage/caching/","text":"Caching Model \u00b6 Each Processing Worker maintains an LRU (Least Recently Used) in-memory cache of decrypted entities. The cache is the primary performance lever in DeltaDatabase \u2014 most reads in a warm system never touch disk. Overview \u00b6 Type: LRU-only eviction. No time-based TTL expiry by default. Scope: Per-worker, in-memory. Not shared across workers (each worker has its own cache). Key: \"{database}/{entity_key}\" \u2014 e.g., \"chatdb/session_001\" . Value: Decrypted JSON document + version number. Persistence: None. The cache is cleared on worker shutdown. Write Path (PUT) \u00b6 Client PUT request \u2502 \u25bc Main Worker (auth + routing) \u2502 \u25bc Processing Worker 1. Validate JSON against schema 2. Encrypt with AES-256-GCM 3. Write .json.enc + .meta.json to storage atomically 4. \u2705 Update LRU cache with the new decrypted JSON After a write, the entity is immediately available in cache for subsequent reads. Read Path (GET) \u00b6 Client GET request \u2502 \u25bc Main Worker ( auth + routing \u2014 prefers worker that last served this entity ) \u2502 \u25bc Processing Worker 1 . Check LRU cache \u2502 \u251c\u2500 \ud83d\udfe2 CACHE HIT \u2192 return decrypted JSON ( no disk I / O ) \u2502 \u2514\u2500 \ud83d\udd34 CACHE MISS \u2502 \u251c\u2500 Is cache full ? \u2502 Yes \u2192 evict LRU entry to make room \u2502 \u251c\u2500 Read . json . enc + . meta . json from storage \u251c\u2500 Check meta . version against any stale cached entry \u251c\u2500 Decrypt with AES - 256 - GCM \u251c\u2500 Store in cache \u2514\u2500 Return decrypted JSON Cache Coherence \u00b6 Because multiple Processing Workers share the same storage backend, a write by worker A should not serve a stale read from worker B's cache. DeltaDatabase handles this with version-based coherence : Every write increments the entity's version in .meta.json . When a worker reads an entity from disk, it checks meta.version against the cached version. If the versions differ, the disk copy wins and the cache is refreshed. The Main Worker's cache-aware routing reduces cross-worker reads: it routes each entity's requests to the same worker that most recently served it, maximising cache hit rates. Configuration \u00b6 Flag Default Description -cache-size 256 Maximum number of entities per worker LRU cache -cache-ttl 0 TTL per cache entry. 0 = LRU-only eviction Choosing a Cache Size \u00b6 The optimal cache size depends on your working set: Working set Recommended -cache-size < 256 entities 256 (default) \u2014 everything fits in cache 256 \u2013 1000 entities 512 or 1024 > 1000 entities Increase cache or add more Processing Workers Each cached entry holds the full decrypted JSON document in memory. A typical chat session (~50 messages) uses ~10 KB. 256 entries \u00d7 10 KB = ~2.5 MB per worker. Time-Based Expiry \u00b6 If you need cache entries to expire after a fixed duration (e.g., for compliance or to bound memory usage), set -cache-ttl : ./bin/proc-worker \\ -cache-size = 512 \\ -cache-ttl = 10m \\ ... With -cache-ttl=10m , entries are evicted after 10 minutes regardless of LRU pressure. Cache and Multiple Workers \u00b6 When running multiple Processing Workers: Each worker has its own independent LRU cache . The Main Worker's cache-aware routing minimises cross-worker cache misses. If the same entity is accessed by two different workers simultaneously, both may hold a copy in cache \u2014 this is expected and safe (version checks ensure coherence). Benchmark Impact \u00b6 The LRU cache is the biggest performance lever: Scenario Mean latency GET \u2014 warm cache (cache hit) ~1 ms GET \u2014 cold cache (cache miss, disk read + decrypt) ~3\u20135 ms PUT \u2014 (validate + encrypt + disk write + cache update) ~1 ms See the Benchmark Results page for full numbers.","title":"Caching Model"},{"location":"usage/caching/#caching-model","text":"Each Processing Worker maintains an LRU (Least Recently Used) in-memory cache of decrypted entities. The cache is the primary performance lever in DeltaDatabase \u2014 most reads in a warm system never touch disk.","title":"Caching Model"},{"location":"usage/caching/#overview","text":"Type: LRU-only eviction. No time-based TTL expiry by default. Scope: Per-worker, in-memory. Not shared across workers (each worker has its own cache). Key: \"{database}/{entity_key}\" \u2014 e.g., \"chatdb/session_001\" . Value: Decrypted JSON document + version number. Persistence: None. The cache is cleared on worker shutdown.","title":"Overview"},{"location":"usage/caching/#write-path-put","text":"Client PUT request \u2502 \u25bc Main Worker (auth + routing) \u2502 \u25bc Processing Worker 1. Validate JSON against schema 2. Encrypt with AES-256-GCM 3. Write .json.enc + .meta.json to storage atomically 4. \u2705 Update LRU cache with the new decrypted JSON After a write, the entity is immediately available in cache for subsequent reads.","title":"Write Path (PUT)"},{"location":"usage/caching/#read-path-get","text":"Client GET request \u2502 \u25bc Main Worker ( auth + routing \u2014 prefers worker that last served this entity ) \u2502 \u25bc Processing Worker 1 . Check LRU cache \u2502 \u251c\u2500 \ud83d\udfe2 CACHE HIT \u2192 return decrypted JSON ( no disk I / O ) \u2502 \u2514\u2500 \ud83d\udd34 CACHE MISS \u2502 \u251c\u2500 Is cache full ? \u2502 Yes \u2192 evict LRU entry to make room \u2502 \u251c\u2500 Read . json . enc + . meta . json from storage \u251c\u2500 Check meta . version against any stale cached entry \u251c\u2500 Decrypt with AES - 256 - GCM \u251c\u2500 Store in cache \u2514\u2500 Return decrypted JSON","title":"Read Path (GET)"},{"location":"usage/caching/#cache-coherence","text":"Because multiple Processing Workers share the same storage backend, a write by worker A should not serve a stale read from worker B's cache. DeltaDatabase handles this with version-based coherence : Every write increments the entity's version in .meta.json . When a worker reads an entity from disk, it checks meta.version against the cached version. If the versions differ, the disk copy wins and the cache is refreshed. The Main Worker's cache-aware routing reduces cross-worker reads: it routes each entity's requests to the same worker that most recently served it, maximising cache hit rates.","title":"Cache Coherence"},{"location":"usage/caching/#configuration","text":"Flag Default Description -cache-size 256 Maximum number of entities per worker LRU cache -cache-ttl 0 TTL per cache entry. 0 = LRU-only eviction","title":"Configuration"},{"location":"usage/caching/#choosing-a-cache-size","text":"The optimal cache size depends on your working set: Working set Recommended -cache-size < 256 entities 256 (default) \u2014 everything fits in cache 256 \u2013 1000 entities 512 or 1024 > 1000 entities Increase cache or add more Processing Workers Each cached entry holds the full decrypted JSON document in memory. A typical chat session (~50 messages) uses ~10 KB. 256 entries \u00d7 10 KB = ~2.5 MB per worker.","title":"Choosing a Cache Size"},{"location":"usage/caching/#time-based-expiry","text":"If you need cache entries to expire after a fixed duration (e.g., for compliance or to bound memory usage), set -cache-ttl : ./bin/proc-worker \\ -cache-size = 512 \\ -cache-ttl = 10m \\ ... With -cache-ttl=10m , entries are evicted after 10 minutes regardless of LRU pressure.","title":"Time-Based Expiry"},{"location":"usage/caching/#cache-and-multiple-workers","text":"When running multiple Processing Workers: Each worker has its own independent LRU cache . The Main Worker's cache-aware routing minimises cross-worker cache misses. If the same entity is accessed by two different workers simultaneously, both may hold a copy in cache \u2014 this is expected and safe (version checks ensure coherence).","title":"Cache and Multiple Workers"},{"location":"usage/caching/#benchmark-impact","text":"The LRU cache is the biggest performance lever: Scenario Mean latency GET \u2014 warm cache (cache hit) ~1 ms GET \u2014 cold cache (cache miss, disk read + decrypt) ~3\u20135 ms PUT \u2014 (validate + encrypt + disk write + cache update) ~1 ms See the Benchmark Results page for full numbers.","title":"Benchmark Impact"},{"location":"usage/configuration/","text":"Configuration Reference \u00b6 Both workers are configured entirely through command-line flags . Some sensitive values (S3 credentials) can be supplied as environment variables instead to keep them out of process argument lists. Main Worker Flags \u00b6 Start the Main Worker with ./bin/main-worker [flags] . Flag Default Description -grpc-addr 127.0.0.1:50051 TCP address for the gRPC server (used by Processing Workers) -rest-addr 127.0.0.1:8080 TCP address for the REST HTTP server (used by clients) -shared-fs ./shared/db Path to the shared filesystem root. Ignored when -s3-endpoint is set -master-key (auto-generated) Hex-encoded 32-byte AES master key. If omitted, a new random key is generated on startup -key-id main-key-v1 Logical identifier for the master key (stored in entity metadata) -worker-ttl 1h TTL for Processing Worker session tokens -client-ttl 24h TTL for client Bearer tokens -s3-endpoint (empty) S3-compatible endpoint (e.g. minio:9000 ). Setting this enables the S3 backend -s3-access-key (empty) S3 access key ID. Prefer the S3_ACCESS_KEY env var -s3-secret-key (empty) S3 secret access key. Prefer the S3_SECRET_KEY env var -s3-bucket deltadatabase S3 bucket name -s3-use-ssl false Enable TLS for the S3 connection. Set true for AWS S3 -s3-region (empty) S3 region. Optional \u2014 leave empty for MinIO/SeaweedFS Example: Main Worker with a persistent key \u00b6 ./bin/main-worker \\ -grpc-addr = 0 .0.0.0:50051 \\ -rest-addr = 0 .0.0.0:8080 \\ -shared-fs = /data/db \\ -master-key = a1b2c3d4e5f60718293a4b5c6d7e8f90a1b2c3d4e5f60718293a4b5c6d7e8f9 \\ -client-ttl = 12h \\ -worker-ttl = 30m Example: Main Worker with MinIO \u00b6 ./bin/main-worker \\ -grpc-addr = 0 .0.0.0:50051 \\ -rest-addr = 0 .0.0.0:8080 \\ -s3-endpoint = minio:9000 \\ -s3-bucket = deltadatabase \\ -s3-use-ssl = false Processing Worker Flags \u00b6 Start the Processing Worker with ./bin/proc-worker [flags] . Flag Default Description -main-addr 127.0.0.1:50051 Main Worker gRPC address to subscribe to -worker-id (hostname) Unique identifier for this worker instance -grpc-addr 127.0.0.1:0 TCP address for this worker's own gRPC server -shared-fs ./shared/db Path to the shared filesystem root. Ignored when -s3-endpoint is set -cache-size 256 Maximum number of entities to keep in the LRU cache -cache-ttl 0 TTL per cache entry. 0 = LRU-only eviction, no time-based expiry -s3-endpoint (empty) S3-compatible endpoint. Setting this enables the S3 backend -s3-access-key (empty) S3 access key ID. Prefer the S3_ACCESS_KEY env var -s3-secret-key (empty) S3 secret access key. Prefer the S3_SECRET_KEY env var -s3-bucket deltadatabase S3 bucket name -s3-use-ssl false Enable TLS for the S3 connection -s3-region (empty) S3 region. Optional Example: Processing Worker with a large cache \u00b6 ./bin/proc-worker \\ -main-addr = main-worker:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 0 .0.0.0:50052 \\ -shared-fs = /data/db \\ -cache-size = 1024 Example: Processing Worker with AWS S3 \u00b6 export S3_ACCESS_KEY = AKIAIOSFODNN7EXAMPLE export S3_SECRET_KEY = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY ./bin/proc-worker \\ -main-addr = main-worker:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 0 .0.0.0:50052 \\ -s3-endpoint = s3.amazonaws.com \\ -s3-use-ssl = true \\ -s3-region = us-east-1 \\ -s3-bucket = my-deltadatabase-bucket Environment Variables \u00b6 Variable Equivalent Flag Workers S3_ACCESS_KEY -s3-access-key Both S3_SECRET_KEY -s3-secret-key Both Warning Security note: The -master-key flag value appears in the shell command history. In production, load the key from an environment variable or a secrets manager and pass it via a wrapper script. Configuration in Docker Compose \u00b6 When using Docker Compose, pass flags via the command: field and environment variables via environment: : services : main-worker : image : deltadatabase/main-worker:latest command : > -grpc-addr=0.0.0.0:50051 -rest-addr=0.0.0.0:8080 -shared-fs=/shared/db environment : - MASTER_KEY=${MASTER_KEY} ports : - \"8080:8080\" - \"50051:50051\" Configuration in Kubernetes \u00b6 Use a Secret for the master key and a ConfigMap for non-sensitive settings: apiVersion : v1 kind : Secret metadata : name : delta-master-key namespace : deltadatabase stringData : master-key : \"a1b2c3d4...\" # your hex key here Reference it in the Deployment: env : - name : MASTER_KEY valueFrom : secretKeyRef : name : delta-master-key key : master-key See the Deployment guide for complete Kubernetes examples.","title":"Configuration"},{"location":"usage/configuration/#configuration-reference","text":"Both workers are configured entirely through command-line flags . Some sensitive values (S3 credentials) can be supplied as environment variables instead to keep them out of process argument lists.","title":"Configuration Reference"},{"location":"usage/configuration/#main-worker-flags","text":"Start the Main Worker with ./bin/main-worker [flags] . Flag Default Description -grpc-addr 127.0.0.1:50051 TCP address for the gRPC server (used by Processing Workers) -rest-addr 127.0.0.1:8080 TCP address for the REST HTTP server (used by clients) -shared-fs ./shared/db Path to the shared filesystem root. Ignored when -s3-endpoint is set -master-key (auto-generated) Hex-encoded 32-byte AES master key. If omitted, a new random key is generated on startup -key-id main-key-v1 Logical identifier for the master key (stored in entity metadata) -worker-ttl 1h TTL for Processing Worker session tokens -client-ttl 24h TTL for client Bearer tokens -s3-endpoint (empty) S3-compatible endpoint (e.g. minio:9000 ). Setting this enables the S3 backend -s3-access-key (empty) S3 access key ID. Prefer the S3_ACCESS_KEY env var -s3-secret-key (empty) S3 secret access key. Prefer the S3_SECRET_KEY env var -s3-bucket deltadatabase S3 bucket name -s3-use-ssl false Enable TLS for the S3 connection. Set true for AWS S3 -s3-region (empty) S3 region. Optional \u2014 leave empty for MinIO/SeaweedFS","title":"Main Worker Flags"},{"location":"usage/configuration/#example-main-worker-with-a-persistent-key","text":"./bin/main-worker \\ -grpc-addr = 0 .0.0.0:50051 \\ -rest-addr = 0 .0.0.0:8080 \\ -shared-fs = /data/db \\ -master-key = a1b2c3d4e5f60718293a4b5c6d7e8f90a1b2c3d4e5f60718293a4b5c6d7e8f9 \\ -client-ttl = 12h \\ -worker-ttl = 30m","title":"Example: Main Worker with a persistent key"},{"location":"usage/configuration/#example-main-worker-with-minio","text":"./bin/main-worker \\ -grpc-addr = 0 .0.0.0:50051 \\ -rest-addr = 0 .0.0.0:8080 \\ -s3-endpoint = minio:9000 \\ -s3-bucket = deltadatabase \\ -s3-use-ssl = false","title":"Example: Main Worker with MinIO"},{"location":"usage/configuration/#processing-worker-flags","text":"Start the Processing Worker with ./bin/proc-worker [flags] . Flag Default Description -main-addr 127.0.0.1:50051 Main Worker gRPC address to subscribe to -worker-id (hostname) Unique identifier for this worker instance -grpc-addr 127.0.0.1:0 TCP address for this worker's own gRPC server -shared-fs ./shared/db Path to the shared filesystem root. Ignored when -s3-endpoint is set -cache-size 256 Maximum number of entities to keep in the LRU cache -cache-ttl 0 TTL per cache entry. 0 = LRU-only eviction, no time-based expiry -s3-endpoint (empty) S3-compatible endpoint. Setting this enables the S3 backend -s3-access-key (empty) S3 access key ID. Prefer the S3_ACCESS_KEY env var -s3-secret-key (empty) S3 secret access key. Prefer the S3_SECRET_KEY env var -s3-bucket deltadatabase S3 bucket name -s3-use-ssl false Enable TLS for the S3 connection -s3-region (empty) S3 region. Optional","title":"Processing Worker Flags"},{"location":"usage/configuration/#example-processing-worker-with-a-large-cache","text":"./bin/proc-worker \\ -main-addr = main-worker:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 0 .0.0.0:50052 \\ -shared-fs = /data/db \\ -cache-size = 1024","title":"Example: Processing Worker with a large cache"},{"location":"usage/configuration/#example-processing-worker-with-aws-s3","text":"export S3_ACCESS_KEY = AKIAIOSFODNN7EXAMPLE export S3_SECRET_KEY = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY ./bin/proc-worker \\ -main-addr = main-worker:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 0 .0.0.0:50052 \\ -s3-endpoint = s3.amazonaws.com \\ -s3-use-ssl = true \\ -s3-region = us-east-1 \\ -s3-bucket = my-deltadatabase-bucket","title":"Example: Processing Worker with AWS S3"},{"location":"usage/configuration/#environment-variables","text":"Variable Equivalent Flag Workers S3_ACCESS_KEY -s3-access-key Both S3_SECRET_KEY -s3-secret-key Both Warning Security note: The -master-key flag value appears in the shell command history. In production, load the key from an environment variable or a secrets manager and pass it via a wrapper script.","title":"Environment Variables"},{"location":"usage/configuration/#configuration-in-docker-compose","text":"When using Docker Compose, pass flags via the command: field and environment variables via environment: : services : main-worker : image : deltadatabase/main-worker:latest command : > -grpc-addr=0.0.0.0:50051 -rest-addr=0.0.0.0:8080 -shared-fs=/shared/db environment : - MASTER_KEY=${MASTER_KEY} ports : - \"8080:8080\" - \"50051:50051\"","title":"Configuration in Docker Compose"},{"location":"usage/configuration/#configuration-in-kubernetes","text":"Use a Secret for the master key and a ConfigMap for non-sensitive settings: apiVersion : v1 kind : Secret metadata : name : delta-master-key namespace : deltadatabase stringData : master-key : \"a1b2c3d4...\" # your hex key here Reference it in the Deployment: env : - name : MASTER_KEY valueFrom : secretKeyRef : name : delta-master-key key : master-key See the Deployment guide for complete Kubernetes examples.","title":"Configuration in Kubernetes"},{"location":"usage/deployment/","text":"Deployment \u00b6 DeltaDatabase supports several deployment topologies, from a single all-in-one container to a cloud-native Kubernetes cluster with autoscaling. Deployment Topologies \u00b6 Scenario Recommendation Guide Local development / CI All-in-one container All-in-One Small production 1 Main + 1 Processing Worker 1M + 1W Scale-out 1 Main + N Processing Workers 1M + NW Cloud / auto-scaling Kubernetes + HPA Kubernetes Managed storage S3-compatible backend S3 Storage All-in-One (Single Container) \u00b6 Both workers run inside the same Docker container. Ideal for development, CI, or edge nodes. Docker Compose (recommended) \u00b6 docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up The REST API is available at http://localhost:8080 . Plain Docker \u00b6 # Build docker build \\ -f deploy/docker/Dockerfile.all-in-one \\ -t deltadatabase/all-in-one:latest \\ . # Run with a persistent master key and admin key MASTER_KEY = $( openssl rand -hex 32 ) ADMIN_KEY = $( openssl rand -hex 24 ) docker run -d \\ --name deltadatabase \\ -p 8080 :8080 \\ -e MASTER_KEY = \" ${ MASTER_KEY } \" \\ -e ADMIN_KEY = \" ${ ADMIN_KEY } \" \\ -v delta_data:/shared/db \\ deltadatabase/all-in-one:latest Container Architecture \u00b6 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Docker container \u2502 \u2502 \u2502 \u2502 main-worker :8080 (REST) \u2502 \u2502 :50051 (gRPC) \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 gRPC subscribe \u2502 \u2502 \u25bc \u2502 \u2502 proc-worker :50052 (gRPC) \u2502 \u2502 \u2502 \u2502 /shared/db (named volume) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 1 Main Worker + 1 Processing Worker \u00b6 The simplest production-like setup: two separate containers. docker compose \\ -f deploy/docker-compose/docker-compose.one-main-one-worker.yml \\ up --build 1 Main Worker + N Processing Workers \u00b6 Horizontal scale-out for higher throughput. All Processing Workers share the same filesystem volume. # Start with 3 Processing Workers (default) docker compose \\ -f deploy/docker-compose/docker-compose.one-main-multiple-workers.yml \\ up --build # Scale to 5 workers docker compose \\ -f deploy/docker-compose/docker-compose.one-main-multiple-workers.yml \\ up --build --scale proc-worker = 5 Architecture \u00b6 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Docker Compose \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 gRPC subscribe \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 main-worker \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 proc-worker-1 \u2502 \u2502 \u2502 \u2502 :8080 REST \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 proc-worker-2 \u2502 \u2502 \u2502 \u2502 :50051 gRPC \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 proc-worker-3 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 /shared/db (volume) \u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Kubernetes with Autoscaling \u00b6 Processing Workers start at 1 replica and scale up to 10 based on CPU utilisation via a HorizontalPodAutoscaler . Prerequisites \u00b6 Kubernetes cluster v1.26+ with the Metrics Server installed. A ReadWriteMany StorageClass (NFS, Azure Files, AWS EFS, or Longhorn with RWX). A container registry accessible from the cluster. Build and Push Images \u00b6 REGISTRY = ghcr.io/myorg docker build -f deploy/docker/Dockerfile.main-worker \\ -t ${ REGISTRY } /delta-main-worker:latest . docker build -f deploy/docker/Dockerfile.proc-worker \\ -t ${ REGISTRY } /delta-proc-worker:latest . docker push ${ REGISTRY } /delta-main-worker:latest docker push ${ REGISTRY } /delta-proc-worker:latest Deploy \u00b6 # Create namespace and secret kubectl create namespace deltadatabase MASTER_KEY = $( openssl rand -hex 32 ) kubectl -n deltadatabase create secret generic delta-master-key \\ --from-literal = master-key = \" ${ MASTER_KEY } \" # Apply manifests kubectl apply -f deploy/kubernetes/shared-pvc.yaml kubectl apply -f deploy/kubernetes/main-worker.yaml kubectl apply -f deploy/kubernetes/proc-worker.yaml kubectl apply -f deploy/kubernetes/proc-worker-hpa.yaml # Wait for rollout kubectl -n deltadatabase rollout status deployment/main-worker kubectl -n deltadatabase rollout status deployment/proc-worker Kubernetes Architecture \u00b6 Internet / Ingress \u2502 \u25bc REST :8080 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 main-worker \u2502 (Deployment, 1 replica) \u2502 ClusterIP svc \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 gRPC :50051 \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 proc-worker-1 proc-worker-2 \u2026 (HPA: 1\u201310) \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 /shared/db (ReadWriteMany PVC) HPA Behaviour \u00b6 The HorizontalPodAutoscaler targets 60% CPU utilisation : Adds up to 2 new pods per 60 seconds when CPU exceeds the target. Removes 1 pod per 120 seconds when CPU drops below the target. Always keeps at least 1 pod; never exceeds 10 pods. S3-Compatible Storage \u00b6 Replace the shared POSIX filesystem with any S3-compatible object store. No ReadWriteMany PVC needed. Supported services: MinIO \u00b7 RustFS \u00b7 SeaweedFS \u00b7 AWS S3 \u00b7 Ceph RadosGW Quick Start with MinIO \u00b6 docker compose -f deploy/docker-compose/docker-compose.with-s3.yml up --build This starts MinIO, the Main Worker, and 3 Processing Workers all configured to use the S3 backend. Open the MinIO console at http://localhost:9001 (user: minioadmin , password: minioadmin ). Manual S3 Configuration \u00b6 # Processing Worker with MinIO ./bin/proc-worker \\ -main-addr = 127 .0.0.1:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 127 .0.0.1:50052 \\ -s3-endpoint = minio:9000 \\ -s3-bucket = deltadatabase \\ -s3-use-ssl = false \\ -s3-access-key = minioadmin \\ -s3-secret-key = minioadmin # Processing Worker with AWS S3 export S3_ACCESS_KEY = AKIAIOSFODNN7EXAMPLE export S3_SECRET_KEY = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY ./bin/proc-worker \\ -main-addr = 127 .0.0.1:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 127 .0.0.1:50052 \\ -s3-endpoint = s3.amazonaws.com \\ -s3-use-ssl = true \\ -s3-region = us-east-1 \\ -s3-bucket = my-deltadatabase-bucket S3 Object Layout \u00b6 deltadatabase/ \u251c\u2500\u2500 files/<entityID>.json.enc \u2014 AES-256-GCM encrypted blob \u251c\u2500\u2500 files/<entityID>.meta.json \u2014 metadata (key ID, IV, tag, schema, version) \u2514\u2500\u2500 templates/<schemaID>.json \u2014 JSON Schema templates Supply a Persistent Master Key \u00b6 By default, the Main Worker generates a new random key on each startup. Entities encrypted with the old key will be unreadable after a restart. To persist data across restarts, generate a key once and supply it on every start: # Generate once and save MASTER_KEY = $( openssl rand -hex 32 ) echo \"MASTER_KEY= ${ MASTER_KEY } \" >> .env # Docker Compose picks up .env automatically docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up Warning Store the master key securely. If the key is lost, all stored data becomes permanently unrecoverable. Supply an Admin Key \u00b6 The admin key is the master Bearer credential for the Management UI and REST API. Without it, any caller can issue session tokens (dev mode only \u2014 not suitable for production). # Generate once and save ADMIN_KEY = $( openssl rand -hex 24 ) echo \"ADMIN_KEY= ${ ADMIN_KEY } \" >> .env # Docker Compose picks up .env automatically docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up Use the admin key to log in to the Management UI at http://localhost:8080/ or as a Bearer token in API calls: curl -s http://localhost:8080/admin/workers \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \" Warning Set a strong, randomly-generated admin key before exposing DeltaDatabase to any network. Store it in a secrets manager \u2014 never commit it to source control.","title":"Deployment"},{"location":"usage/deployment/#deployment","text":"DeltaDatabase supports several deployment topologies, from a single all-in-one container to a cloud-native Kubernetes cluster with autoscaling.","title":"Deployment"},{"location":"usage/deployment/#deployment-topologies","text":"Scenario Recommendation Guide Local development / CI All-in-one container All-in-One Small production 1 Main + 1 Processing Worker 1M + 1W Scale-out 1 Main + N Processing Workers 1M + NW Cloud / auto-scaling Kubernetes + HPA Kubernetes Managed storage S3-compatible backend S3 Storage","title":"Deployment Topologies"},{"location":"usage/deployment/#all-in-one-single-container","text":"Both workers run inside the same Docker container. Ideal for development, CI, or edge nodes.","title":"All-in-One (Single Container)"},{"location":"usage/deployment/#docker-compose-recommended","text":"docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up The REST API is available at http://localhost:8080 .","title":"Docker Compose (recommended)"},{"location":"usage/deployment/#plain-docker","text":"# Build docker build \\ -f deploy/docker/Dockerfile.all-in-one \\ -t deltadatabase/all-in-one:latest \\ . # Run with a persistent master key and admin key MASTER_KEY = $( openssl rand -hex 32 ) ADMIN_KEY = $( openssl rand -hex 24 ) docker run -d \\ --name deltadatabase \\ -p 8080 :8080 \\ -e MASTER_KEY = \" ${ MASTER_KEY } \" \\ -e ADMIN_KEY = \" ${ ADMIN_KEY } \" \\ -v delta_data:/shared/db \\ deltadatabase/all-in-one:latest","title":"Plain Docker"},{"location":"usage/deployment/#container-architecture","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Docker container \u2502 \u2502 \u2502 \u2502 main-worker :8080 (REST) \u2502 \u2502 :50051 (gRPC) \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 gRPC subscribe \u2502 \u2502 \u25bc \u2502 \u2502 proc-worker :50052 (gRPC) \u2502 \u2502 \u2502 \u2502 /shared/db (named volume) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Container Architecture"},{"location":"usage/deployment/#1-main-worker-1-processing-worker","text":"The simplest production-like setup: two separate containers. docker compose \\ -f deploy/docker-compose/docker-compose.one-main-one-worker.yml \\ up --build","title":"1 Main Worker + 1 Processing Worker"},{"location":"usage/deployment/#1-main-worker-n-processing-workers","text":"Horizontal scale-out for higher throughput. All Processing Workers share the same filesystem volume. # Start with 3 Processing Workers (default) docker compose \\ -f deploy/docker-compose/docker-compose.one-main-multiple-workers.yml \\ up --build # Scale to 5 workers docker compose \\ -f deploy/docker-compose/docker-compose.one-main-multiple-workers.yml \\ up --build --scale proc-worker = 5","title":"1 Main Worker + N Processing Workers"},{"location":"usage/deployment/#architecture","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Docker Compose \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 gRPC subscribe \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 main-worker \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 proc-worker-1 \u2502 \u2502 \u2502 \u2502 :8080 REST \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 proc-worker-2 \u2502 \u2502 \u2502 \u2502 :50051 gRPC \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 proc-worker-3 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 /shared/db (volume) \u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Architecture"},{"location":"usage/deployment/#kubernetes-with-autoscaling","text":"Processing Workers start at 1 replica and scale up to 10 based on CPU utilisation via a HorizontalPodAutoscaler .","title":"Kubernetes with Autoscaling"},{"location":"usage/deployment/#prerequisites","text":"Kubernetes cluster v1.26+ with the Metrics Server installed. A ReadWriteMany StorageClass (NFS, Azure Files, AWS EFS, or Longhorn with RWX). A container registry accessible from the cluster.","title":"Prerequisites"},{"location":"usage/deployment/#build-and-push-images","text":"REGISTRY = ghcr.io/myorg docker build -f deploy/docker/Dockerfile.main-worker \\ -t ${ REGISTRY } /delta-main-worker:latest . docker build -f deploy/docker/Dockerfile.proc-worker \\ -t ${ REGISTRY } /delta-proc-worker:latest . docker push ${ REGISTRY } /delta-main-worker:latest docker push ${ REGISTRY } /delta-proc-worker:latest","title":"Build and Push Images"},{"location":"usage/deployment/#deploy","text":"# Create namespace and secret kubectl create namespace deltadatabase MASTER_KEY = $( openssl rand -hex 32 ) kubectl -n deltadatabase create secret generic delta-master-key \\ --from-literal = master-key = \" ${ MASTER_KEY } \" # Apply manifests kubectl apply -f deploy/kubernetes/shared-pvc.yaml kubectl apply -f deploy/kubernetes/main-worker.yaml kubectl apply -f deploy/kubernetes/proc-worker.yaml kubectl apply -f deploy/kubernetes/proc-worker-hpa.yaml # Wait for rollout kubectl -n deltadatabase rollout status deployment/main-worker kubectl -n deltadatabase rollout status deployment/proc-worker","title":"Deploy"},{"location":"usage/deployment/#kubernetes-architecture","text":"Internet / Ingress \u2502 \u25bc REST :8080 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 main-worker \u2502 (Deployment, 1 replica) \u2502 ClusterIP svc \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 gRPC :50051 \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 proc-worker-1 proc-worker-2 \u2026 (HPA: 1\u201310) \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 /shared/db (ReadWriteMany PVC)","title":"Kubernetes Architecture"},{"location":"usage/deployment/#hpa-behaviour","text":"The HorizontalPodAutoscaler targets 60% CPU utilisation : Adds up to 2 new pods per 60 seconds when CPU exceeds the target. Removes 1 pod per 120 seconds when CPU drops below the target. Always keeps at least 1 pod; never exceeds 10 pods.","title":"HPA Behaviour"},{"location":"usage/deployment/#s3-compatible-storage","text":"Replace the shared POSIX filesystem with any S3-compatible object store. No ReadWriteMany PVC needed. Supported services: MinIO \u00b7 RustFS \u00b7 SeaweedFS \u00b7 AWS S3 \u00b7 Ceph RadosGW","title":"S3-Compatible Storage"},{"location":"usage/deployment/#quick-start-with-minio","text":"docker compose -f deploy/docker-compose/docker-compose.with-s3.yml up --build This starts MinIO, the Main Worker, and 3 Processing Workers all configured to use the S3 backend. Open the MinIO console at http://localhost:9001 (user: minioadmin , password: minioadmin ).","title":"Quick Start with MinIO"},{"location":"usage/deployment/#manual-s3-configuration","text":"# Processing Worker with MinIO ./bin/proc-worker \\ -main-addr = 127 .0.0.1:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 127 .0.0.1:50052 \\ -s3-endpoint = minio:9000 \\ -s3-bucket = deltadatabase \\ -s3-use-ssl = false \\ -s3-access-key = minioadmin \\ -s3-secret-key = minioadmin # Processing Worker with AWS S3 export S3_ACCESS_KEY = AKIAIOSFODNN7EXAMPLE export S3_SECRET_KEY = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY ./bin/proc-worker \\ -main-addr = 127 .0.0.1:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 127 .0.0.1:50052 \\ -s3-endpoint = s3.amazonaws.com \\ -s3-use-ssl = true \\ -s3-region = us-east-1 \\ -s3-bucket = my-deltadatabase-bucket","title":"Manual S3 Configuration"},{"location":"usage/deployment/#s3-object-layout","text":"deltadatabase/ \u251c\u2500\u2500 files/<entityID>.json.enc \u2014 AES-256-GCM encrypted blob \u251c\u2500\u2500 files/<entityID>.meta.json \u2014 metadata (key ID, IV, tag, schema, version) \u2514\u2500\u2500 templates/<schemaID>.json \u2014 JSON Schema templates","title":"S3 Object Layout"},{"location":"usage/deployment/#supply-a-persistent-master-key","text":"By default, the Main Worker generates a new random key on each startup. Entities encrypted with the old key will be unreadable after a restart. To persist data across restarts, generate a key once and supply it on every start: # Generate once and save MASTER_KEY = $( openssl rand -hex 32 ) echo \"MASTER_KEY= ${ MASTER_KEY } \" >> .env # Docker Compose picks up .env automatically docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up Warning Store the master key securely. If the key is lost, all stored data becomes permanently unrecoverable.","title":"Supply a Persistent Master Key"},{"location":"usage/deployment/#supply-an-admin-key","text":"The admin key is the master Bearer credential for the Management UI and REST API. Without it, any caller can issue session tokens (dev mode only \u2014 not suitable for production). # Generate once and save ADMIN_KEY = $( openssl rand -hex 24 ) echo \"ADMIN_KEY= ${ ADMIN_KEY } \" >> .env # Docker Compose picks up .env automatically docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up Use the admin key to log in to the Management UI at http://localhost:8080/ or as a Bearer token in API calls: curl -s http://localhost:8080/admin/workers \\ -H \"Authorization: Bearer ${ ADMIN_KEY } \" Warning Set a strong, randomly-generated admin key before exposing DeltaDatabase to any network. Store it in a secrets manager \u2014 never commit it to source control.","title":"Supply an Admin Key"},{"location":"usage/frontend/","text":"Management UI Guide \u00b6 DeltaDatabase ships with a built-in browser-based Management UI available at http://localhost:8080/ . This page walks through every screen with screenshots and explains how to use each feature. Login \u00b6 When you open the UI you are presented with a login screen. Enter one of the following: Credential Description Admin key The value of -admin-key / $ADMIN_KEY \u2014 grants full access including key management API key ( dk_\u2026 ) A named RBAC key created via POST /api/keys \u2014 access limited to its configured permissions A short-lived session token is issued behind the scenes; it inherits the exact permissions of the credential you entered. Example \u2014 log in with the admin key: # The UI calls this automatically when you click Login curl -s -X POST http://localhost:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"key\":\"YOUR_ADMIN_KEY\"}' Dashboard \u00b6 The Dashboard is the first screen after login. It shows: System Health \u2014 live status from GET /health . A green \u25cf OK badge means the server is reachable. Header status dot \u2014 green when healthy, red when the server is unreachable. Registered / Available Workers \u2014 counts of Processing Workers known to the Main Worker. The header always shows your current session identity (e.g. \ud83d\udc64 admin ) and a Logout button. Workers \u00b6 The Workers tab lists all registered Processing Workers returned by GET /admin/workers . Requires admin permission. Column Description Worker ID Unique identifier set with -worker-id when starting the proc-worker Status Available (green) or Deallocating (red) Key ID The master key ID the worker is currently using Last Seen Timestamp of the last successful subscription Tags Arbitrary key-value metadata (e.g. grpc_addr ) Use the \u21bb Refresh button to reload the list at any time. Entities \u00b6 The Entities tab lets you read and write JSON entities directly from the browser. Get Entity \u00b6 Enter the Database name (e.g. chatdb ). Enter the Key (entity key inside that database, e.g. session_001 ). Click GET . The entity's JSON document is displayed below the form on success, or an error badge on failure. Put Entity \u00b6 Enter the Database name. Enter the JSON Body \u2014 a JSON object where each top-level key is an entity key and its value is the entity document. Example: {\"session_001\": {\"messages\": [{\"role\":\"user\",\"content\":\"Hello\"}]}} Click PUT . Multiple entities can be written in a single PUT by including multiple top-level keys. Schemas \u00b6 The Schemas tab manages JSON Schema templates used to validate entity data. Available Schemas \u00b6 Lists all schema IDs currently registered (from GET /admin/schemas ). Click Edit next to any schema to load it into the editor. Create / Edit Schema \u00b6 Enter a Schema ID (e.g. chat.v1 or product.v1 ). Paste or write a JSON Schema draft-07 document in the editor. Click Load to fetch an existing schema from the server into the editor. Click Save to write the schema to the server ( PUT /schema/{id} ). Export Schema \u00b6 Once a schema is loaded in the editor you can generate typed models from it: \ud83d\udc0d Export as Pydantic \u2014 generates a Python BaseModel class file ready to use with Pydantic v2 . \ud83d\udd37 Export as TypeScript \u2014 generates a TypeScript interface declaration file. Click Copy to copy the generated code to the clipboard, or \u2b07 Download to save it as a file. API Keys \u00b6 The API Keys tab manages persistent RBAC API keys backed by POST /api/keys and DELETE /api/keys/{id} . Requires admin permission. Create New Key \u00b6 Field Description Name A human-readable label (e.g. ci-deploy ) Permissions Select one or more: read , write , admin Expires In Optional duration: 24h , 7d , 30d , etc. Leave blank for non-expiring. Click Create Key . The raw secret ( dk_\u2026 ) is displayed once only \u2014 copy it immediately. Warning The secret is never stored in plaintext and cannot be retrieved again after you close or refresh the page. Existing Keys \u00b6 Lists all API keys with their ID, permissions, creation date, expiry, and enabled status. Click Delete to permanently remove a key. Explorer \u00b6 The Explorer tab is a lightweight HTTP client for testing any API endpoint. Raw Request \u00b6 Select the Method ( GET or PUT ). Enter the Path (e.g. /health , /entity/mydb?key=hello ). For PUT requests, enter a JSON Body . Click Send . The response status, HTTP code, latency in milliseconds, and body are shown below the form. Quick Endpoints \u00b6 Pre-built buttons to quickly invoke common endpoints: Button Endpoint GET /health Checks server health (no auth required) GET /admin/workers Lists all registered Processing Workers Logging Out \u00b6 Click the Logout button in the top-right corner at any time. This clears the session token from memory and returns you to the login screen. The token is not explicitly revoked on the server \u2014 it will naturally expire after the configured TTL.","title":"Management UI"},{"location":"usage/frontend/#management-ui-guide","text":"DeltaDatabase ships with a built-in browser-based Management UI available at http://localhost:8080/ . This page walks through every screen with screenshots and explains how to use each feature.","title":"Management UI Guide"},{"location":"usage/frontend/#login","text":"When you open the UI you are presented with a login screen. Enter one of the following: Credential Description Admin key The value of -admin-key / $ADMIN_KEY \u2014 grants full access including key management API key ( dk_\u2026 ) A named RBAC key created via POST /api/keys \u2014 access limited to its configured permissions A short-lived session token is issued behind the scenes; it inherits the exact permissions of the credential you entered. Example \u2014 log in with the admin key: # The UI calls this automatically when you click Login curl -s -X POST http://localhost:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"key\":\"YOUR_ADMIN_KEY\"}'","title":"Login"},{"location":"usage/frontend/#dashboard","text":"The Dashboard is the first screen after login. It shows: System Health \u2014 live status from GET /health . A green \u25cf OK badge means the server is reachable. Header status dot \u2014 green when healthy, red when the server is unreachable. Registered / Available Workers \u2014 counts of Processing Workers known to the Main Worker. The header always shows your current session identity (e.g. \ud83d\udc64 admin ) and a Logout button.","title":"Dashboard"},{"location":"usage/frontend/#workers","text":"The Workers tab lists all registered Processing Workers returned by GET /admin/workers . Requires admin permission. Column Description Worker ID Unique identifier set with -worker-id when starting the proc-worker Status Available (green) or Deallocating (red) Key ID The master key ID the worker is currently using Last Seen Timestamp of the last successful subscription Tags Arbitrary key-value metadata (e.g. grpc_addr ) Use the \u21bb Refresh button to reload the list at any time.","title":"Workers"},{"location":"usage/frontend/#entities","text":"The Entities tab lets you read and write JSON entities directly from the browser.","title":"Entities"},{"location":"usage/frontend/#get-entity","text":"Enter the Database name (e.g. chatdb ). Enter the Key (entity key inside that database, e.g. session_001 ). Click GET . The entity's JSON document is displayed below the form on success, or an error badge on failure.","title":"Get Entity"},{"location":"usage/frontend/#put-entity","text":"Enter the Database name. Enter the JSON Body \u2014 a JSON object where each top-level key is an entity key and its value is the entity document. Example: {\"session_001\": {\"messages\": [{\"role\":\"user\",\"content\":\"Hello\"}]}} Click PUT . Multiple entities can be written in a single PUT by including multiple top-level keys.","title":"Put Entity"},{"location":"usage/frontend/#schemas","text":"The Schemas tab manages JSON Schema templates used to validate entity data.","title":"Schemas"},{"location":"usage/frontend/#available-schemas","text":"Lists all schema IDs currently registered (from GET /admin/schemas ). Click Edit next to any schema to load it into the editor.","title":"Available Schemas"},{"location":"usage/frontend/#create-edit-schema","text":"Enter a Schema ID (e.g. chat.v1 or product.v1 ). Paste or write a JSON Schema draft-07 document in the editor. Click Load to fetch an existing schema from the server into the editor. Click Save to write the schema to the server ( PUT /schema/{id} ).","title":"Create / Edit Schema"},{"location":"usage/frontend/#export-schema","text":"Once a schema is loaded in the editor you can generate typed models from it: \ud83d\udc0d Export as Pydantic \u2014 generates a Python BaseModel class file ready to use with Pydantic v2 . \ud83d\udd37 Export as TypeScript \u2014 generates a TypeScript interface declaration file. Click Copy to copy the generated code to the clipboard, or \u2b07 Download to save it as a file.","title":"Export Schema"},{"location":"usage/frontend/#api-keys","text":"The API Keys tab manages persistent RBAC API keys backed by POST /api/keys and DELETE /api/keys/{id} . Requires admin permission.","title":"API Keys"},{"location":"usage/frontend/#create-new-key","text":"Field Description Name A human-readable label (e.g. ci-deploy ) Permissions Select one or more: read , write , admin Expires In Optional duration: 24h , 7d , 30d , etc. Leave blank for non-expiring. Click Create Key . The raw secret ( dk_\u2026 ) is displayed once only \u2014 copy it immediately. Warning The secret is never stored in plaintext and cannot be retrieved again after you close or refresh the page.","title":"Create New Key"},{"location":"usage/frontend/#existing-keys","text":"Lists all API keys with their ID, permissions, creation date, expiry, and enabled status. Click Delete to permanently remove a key.","title":"Existing Keys"},{"location":"usage/frontend/#explorer","text":"The Explorer tab is a lightweight HTTP client for testing any API endpoint.","title":"Explorer"},{"location":"usage/frontend/#raw-request","text":"Select the Method ( GET or PUT ). Enter the Path (e.g. /health , /entity/mydb?key=hello ). For PUT requests, enter a JSON Body . Click Send . The response status, HTTP code, latency in milliseconds, and body are shown below the form.","title":"Raw Request"},{"location":"usage/frontend/#quick-endpoints","text":"Pre-built buttons to quickly invoke common endpoints: Button Endpoint GET /health Checks server health (no auth required) GET /admin/workers Lists all registered Processing Workers","title":"Quick Endpoints"},{"location":"usage/frontend/#logging-out","text":"Click the Logout button in the top-right corner at any time. This clears the session token from memory and returns you to the login screen. The token is not explicitly revoked on the server \u2014 it will naturally expire after the configured TTL.","title":"Logging Out"},{"location":"usage/quickstart/","text":"Quick Start \u00b6 Get DeltaDatabase running in under 5 minutes. Tip Recommended: Use Docker for the easiest experience. The binary approach is shown below for local development. Option A \u2014 Docker (Recommended) \u00b6 The quickest way to run DeltaDatabase is with the all-in-one Docker Compose file: # Clone the repository git clone https://github.com/DeltaRule/DeltaDatabase.git cd DeltaDatabase # Set an admin key (required for the Management UI and API key management) export ADMIN_KEY = mysecretadminkey # Start everything (Main Worker + Processing Worker in one container) docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up The REST API is available at http://localhost:8080 and the web UI at http://localhost:8080/ . Option B \u2014 Pre-built Binaries \u00b6 1. Create the shared filesystem directory \u00b6 mkdir -p ./shared/db/files ./shared/db/templates 2. Start the Main Worker \u00b6 ./bin/main-worker \\ -grpc-addr = 127 .0.0.1:50051 \\ -rest-addr = 127 .0.0.1:8080 \\ -shared-fs = ./shared/db \\ -admin-key = mysecretadminkey Note the generated master key in the startup output and save it for restarts: 2026 / 02 / 24 12 : 00 : 00 Key ( hex ): a1b2c3d4 ... \u2190 save this for restarts ! 3. Start a Processing Worker \u00b6 Open a second terminal: ./bin/proc-worker \\ -main-addr = 127 .0.0.1:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 127 .0.0.1:50052 \\ -shared-fs = ./shared/db Your First API Calls \u00b6 Check health \u00b6 curl http://127.0.0.1:8080/health { \"status\" : \"ok\" } Authenticate \u00b6 Use the admin key directly as a Bearer token (no login step needed): # Option A \u2014 use the admin key directly (recommended for scripts/CI) curl -s http://127.0.0.1:8080/admin/workers \\ -H \"Authorization: Bearer mysecretadminkey\" # Option B \u2014 exchange the admin key for a short-lived session token (browser/UI) TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"key\":\"mysecretadminkey\"}' | jq -r .token ) echo \"Token: $TOKEN \" Store an entity \u00b6 curl -s -X PUT http://127.0.0.1:8080/entity/mydb \\ -H \"Authorization: Bearer mysecretadminkey\" \\ -H 'Content-Type: application/json' \\ -d '{\"hello_world\": {\"message\": \"Hello from DeltaDatabase!\", \"count\": 1}}' { \"status\" : \"ok\" } Retrieve the entity \u00b6 curl -s \"http://127.0.0.1:8080/entity/mydb?key=hello_world\" \\ -H \"Authorization: Bearer mysecretadminkey\" { \"message\" : \"Hello from DeltaDatabase!\" , \"count\" : 1 } Create a scoped API key \u00b6 curl -s -X POST http://127.0.0.1:8080/api/keys \\ -H \"Authorization: Bearer mysecretadminkey\" \\ -H 'Content-Type: application/json' \\ -d '{\"name\":\"myservice\",\"permissions\":[\"read\",\"write\"]}' { \"id\" : \"a1b2c3d4e5f6a7b8\" , \"name\" : \"myservice\" , \"secret\" : \"dk_abc123\u2026\" , \"permissions\" : [ \"read\" , \"write\" ] } Save the secret \u2014 it is shown only once. Use it as a Bearer token: curl -s \"http://127.0.0.1:8080/entity/mydb?key=hello_world\" \\ -H \"Authorization: Bearer dk_abc123\u2026\" View all workers \u00b6 curl -s -H \"Authorization: Bearer mysecretadminkey\" \\ http://127.0.0.1:8080/admin/workers | jq . [ { \"worker_id\" : \"proc-1\" , \"status\" : \"Available\" , \"key_id\" : \"main-key-v1\" , \"last_seen\" : \"2026-02-24T12:01:30Z\" , \"tags\" : { \"grpc_addr\" : \"127.0.0.1:50052\" } } ] Web Management UI \u00b6 Open http://127.0.0.1:8080/ in your browser to access the built-in management UI. Enter your admin key or an API key in the login screen. Tab Description Dashboard Live health status and worker count Workers All registered Processing Workers Entities GET and PUT entities through a form Schemas Manage JSON Schema templates; export as Pydantic or TypeScript API Keys Create, list, and delete RBAC API keys Explorer Send custom requests and view response and timing See Frontend UI Guide for detailed screenshots and usage instructions. Next Steps \u00b6 Configure flags and environment variables Learn the full REST API Set up JSON Schema validation Deploy with Docker Compose or Kubernetes See real-world examples","title":"Quick Start"},{"location":"usage/quickstart/#quick-start","text":"Get DeltaDatabase running in under 5 minutes. Tip Recommended: Use Docker for the easiest experience. The binary approach is shown below for local development.","title":"Quick Start"},{"location":"usage/quickstart/#option-a-docker-recommended","text":"The quickest way to run DeltaDatabase is with the all-in-one Docker Compose file: # Clone the repository git clone https://github.com/DeltaRule/DeltaDatabase.git cd DeltaDatabase # Set an admin key (required for the Management UI and API key management) export ADMIN_KEY = mysecretadminkey # Start everything (Main Worker + Processing Worker in one container) docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up The REST API is available at http://localhost:8080 and the web UI at http://localhost:8080/ .","title":"Option A \u2014 Docker (Recommended)"},{"location":"usage/quickstart/#option-b-pre-built-binaries","text":"","title":"Option B \u2014 Pre-built Binaries"},{"location":"usage/quickstart/#1-create-the-shared-filesystem-directory","text":"mkdir -p ./shared/db/files ./shared/db/templates","title":"1. Create the shared filesystem directory"},{"location":"usage/quickstart/#2-start-the-main-worker","text":"./bin/main-worker \\ -grpc-addr = 127 .0.0.1:50051 \\ -rest-addr = 127 .0.0.1:8080 \\ -shared-fs = ./shared/db \\ -admin-key = mysecretadminkey Note the generated master key in the startup output and save it for restarts: 2026 / 02 / 24 12 : 00 : 00 Key ( hex ): a1b2c3d4 ... \u2190 save this for restarts !","title":"2. Start the Main Worker"},{"location":"usage/quickstart/#3-start-a-processing-worker","text":"Open a second terminal: ./bin/proc-worker \\ -main-addr = 127 .0.0.1:50051 \\ -worker-id = proc-1 \\ -grpc-addr = 127 .0.0.1:50052 \\ -shared-fs = ./shared/db","title":"3. Start a Processing Worker"},{"location":"usage/quickstart/#your-first-api-calls","text":"","title":"Your First API Calls"},{"location":"usage/quickstart/#check-health","text":"curl http://127.0.0.1:8080/health { \"status\" : \"ok\" }","title":"Check health"},{"location":"usage/quickstart/#authenticate","text":"Use the admin key directly as a Bearer token (no login step needed): # Option A \u2014 use the admin key directly (recommended for scripts/CI) curl -s http://127.0.0.1:8080/admin/workers \\ -H \"Authorization: Bearer mysecretadminkey\" # Option B \u2014 exchange the admin key for a short-lived session token (browser/UI) TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"key\":\"mysecretadminkey\"}' | jq -r .token ) echo \"Token: $TOKEN \"","title":"Authenticate"},{"location":"usage/quickstart/#store-an-entity","text":"curl -s -X PUT http://127.0.0.1:8080/entity/mydb \\ -H \"Authorization: Bearer mysecretadminkey\" \\ -H 'Content-Type: application/json' \\ -d '{\"hello_world\": {\"message\": \"Hello from DeltaDatabase!\", \"count\": 1}}' { \"status\" : \"ok\" }","title":"Store an entity"},{"location":"usage/quickstart/#retrieve-the-entity","text":"curl -s \"http://127.0.0.1:8080/entity/mydb?key=hello_world\" \\ -H \"Authorization: Bearer mysecretadminkey\" { \"message\" : \"Hello from DeltaDatabase!\" , \"count\" : 1 }","title":"Retrieve the entity"},{"location":"usage/quickstart/#create-a-scoped-api-key","text":"curl -s -X POST http://127.0.0.1:8080/api/keys \\ -H \"Authorization: Bearer mysecretadminkey\" \\ -H 'Content-Type: application/json' \\ -d '{\"name\":\"myservice\",\"permissions\":[\"read\",\"write\"]}' { \"id\" : \"a1b2c3d4e5f6a7b8\" , \"name\" : \"myservice\" , \"secret\" : \"dk_abc123\u2026\" , \"permissions\" : [ \"read\" , \"write\" ] } Save the secret \u2014 it is shown only once. Use it as a Bearer token: curl -s \"http://127.0.0.1:8080/entity/mydb?key=hello_world\" \\ -H \"Authorization: Bearer dk_abc123\u2026\"","title":"Create a scoped API key"},{"location":"usage/quickstart/#view-all-workers","text":"curl -s -H \"Authorization: Bearer mysecretadminkey\" \\ http://127.0.0.1:8080/admin/workers | jq . [ { \"worker_id\" : \"proc-1\" , \"status\" : \"Available\" , \"key_id\" : \"main-key-v1\" , \"last_seen\" : \"2026-02-24T12:01:30Z\" , \"tags\" : { \"grpc_addr\" : \"127.0.0.1:50052\" } } ]","title":"View all workers"},{"location":"usage/quickstart/#web-management-ui","text":"Open http://127.0.0.1:8080/ in your browser to access the built-in management UI. Enter your admin key or an API key in the login screen. Tab Description Dashboard Live health status and worker count Workers All registered Processing Workers Entities GET and PUT entities through a form Schemas Manage JSON Schema templates; export as Pydantic or TypeScript API Keys Create, list, and delete RBAC API keys Explorer Send custom requests and view response and timing See Frontend UI Guide for detailed screenshots and usage instructions.","title":"Web Management UI"},{"location":"usage/quickstart/#next-steps","text":"Configure flags and environment variables Learn the full REST API Set up JSON Schema validation Deploy with Docker Compose or Kubernetes See real-world examples","title":"Next Steps"},{"location":"usage/schemas/","text":"JSON Schema Templates \u00b6 DeltaDatabase validates every PUT entity payload against a JSON Schema (draft-07) template before encryption and storage. Invalid data is rejected with HTTP 400 . Schemas are stored in {shared-fs}/templates/ (or as S3 objects under templates/ ) and can be managed via the REST API, the web UI, or by placing files directly on disk. Why Use Schemas? \u00b6 Data integrity \u2014 ensure every stored entity has the expected fields and types. Early rejection \u2014 bad data is caught before encryption and disk I/O. Self-documenting \u2014 schemas serve as the authoritative contract for your data model. Creating a Schema \u00b6 Via the REST API (recommended) \u00b6 TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"admin\"}' | jq -r .token ) curl -s -X PUT http://127.0.0.1:8080/schema/chat.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"chat.v1\", \"type\": \"object\", \"properties\": { \"messages\": { \"type\": \"array\", \"items\": { \"type\": \"object\", \"properties\": { \"role\": {\"type\": \"string\", \"enum\": [\"user\", \"assistant\", \"system\"]}, \"content\": {\"type\": \"string\"} }, \"required\": [\"role\", \"content\"] } } }, \"required\": [\"messages\"] }' Via the Web UI \u00b6 Open http://localhost:8080/ \u2192 Schemas tab \u2192 New Schema and paste your JSON Schema document. Directly on Disk \u00b6 Place a file at {shared-fs}/templates/{schemaID}.json : cat > ./shared/db/templates/chat.v1.json << 'EOF' { \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"chat.v1\", \"type\": \"object\", \"properties\": { \"messages\": {\"type\": \"array\"} }, \"required\": [\"messages\"] } EOF The worker picks up the file automatically \u2014 no restart required. Listing and Retrieving Schemas \u00b6 # List all registered schema IDs curl http://127.0.0.1:8080/admin/schemas # Retrieve a specific schema curl http://127.0.0.1:8080/schema/chat.v1 Schema Naming Convention \u00b6 Schema IDs use the format {name}.{version} : Schema ID Purpose chat.v1 Chat session with messages array user.v1 User profile data product.v2 Product catalogue entry (v2 with new fields) iot_reading.v1 IoT sensor reading Example Schemas \u00b6 Chat Messages \u00b6 { \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"chat.v1\" , \"type\" : \"object\" , \"properties\" : { \"messages\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"properties\" : { \"role\" : { \"type\" : \"string\" , \"enum\" : [ \"user\" , \"assistant\" , \"system\" ]}, \"content\" : { \"type\" : \"string\" } }, \"required\" : [ \"role\" , \"content\" ] } } }, \"required\" : [ \"messages\" ] } User Profile \u00b6 { \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"user.v1\" , \"type\" : \"object\" , \"properties\" : { \"id\" : { \"type\" : \"string\" }, \"name\" : { \"type\" : \"string\" }, \"email\" : { \"type\" : \"string\" , \"format\" : \"email\" }, \"created_at\" : { \"type\" : \"string\" , \"format\" : \"date-time\" }, \"settings\" : { \"type\" : \"object\" } }, \"required\" : [ \"id\" , \"email\" ] } IoT Sensor Reading \u00b6 { \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"iot_reading.v1\" , \"type\" : \"object\" , \"properties\" : { \"device_id\" : { \"type\" : \"string\" }, \"timestamp\" : { \"type\" : \"string\" , \"format\" : \"date-time\" }, \"temperature\" : { \"type\" : \"number\" }, \"humidity\" : { \"type\" : \"number\" , \"minimum\" : 0 , \"maximum\" : 100 }, \"location\" : { \"type\" : \"object\" , \"properties\" : { \"lat\" : { \"type\" : \"number\" }, \"lng\" : { \"type\" : \"number\" } } } }, \"required\" : [ \"device_id\" , \"timestamp\" ] } Product Catalogue \u00b6 { \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"product.v1\" , \"type\" : \"object\" , \"properties\" : { \"sku\" : { \"type\" : \"string\" }, \"name\" : { \"type\" : \"string\" }, \"description\" : { \"type\" : \"string\" }, \"price\" : { \"type\" : \"number\" , \"minimum\" : 0 }, \"currency\" : { \"type\" : \"string\" , \"enum\" : [ \"USD\" , \"EUR\" , \"GBP\" ]}, \"in_stock\" : { \"type\" : \"boolean\" }, \"tags\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"string\" }} }, \"required\" : [ \"sku\" , \"name\" , \"price\" , \"currency\" ] } What Happens on Validation Failure \u00b6 If a PUT /entity/{database} request contains data that does not match the registered schema: The Processing Worker rejects the payload. The Main Worker returns HTTP 400 with an error message. Nothing is written to disk. Example: # This will fail \u2014 \"messages\" is required but missing curl -s -X PUT http://127.0.0.1:8080/entity/chatdb \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{\"session_bad\": {\"wrong_field\": \"oops\"}}' { \"error\" : \"schema validation failed: messages is required\" } Schema Versioning \u00b6 When you need to evolve your data model: Create a new schema with an incremented version: chat.v2 . Write new entities using the new schema. Old entities remain stored under their original schema ID. There is no automatic migration \u2014 migration logic belongs in your application.","title":"JSON Schema Templates"},{"location":"usage/schemas/#json-schema-templates","text":"DeltaDatabase validates every PUT entity payload against a JSON Schema (draft-07) template before encryption and storage. Invalid data is rejected with HTTP 400 . Schemas are stored in {shared-fs}/templates/ (or as S3 objects under templates/ ) and can be managed via the REST API, the web UI, or by placing files directly on disk.","title":"JSON Schema Templates"},{"location":"usage/schemas/#why-use-schemas","text":"Data integrity \u2014 ensure every stored entity has the expected fields and types. Early rejection \u2014 bad data is caught before encryption and disk I/O. Self-documenting \u2014 schemas serve as the authoritative contract for your data model.","title":"Why Use Schemas?"},{"location":"usage/schemas/#creating-a-schema","text":"","title":"Creating a Schema"},{"location":"usage/schemas/#via-the-rest-api-recommended","text":"TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"admin\"}' | jq -r .token ) curl -s -X PUT http://127.0.0.1:8080/schema/chat.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"chat.v1\", \"type\": \"object\", \"properties\": { \"messages\": { \"type\": \"array\", \"items\": { \"type\": \"object\", \"properties\": { \"role\": {\"type\": \"string\", \"enum\": [\"user\", \"assistant\", \"system\"]}, \"content\": {\"type\": \"string\"} }, \"required\": [\"role\", \"content\"] } } }, \"required\": [\"messages\"] }'","title":"Via the REST API (recommended)"},{"location":"usage/schemas/#via-the-web-ui","text":"Open http://localhost:8080/ \u2192 Schemas tab \u2192 New Schema and paste your JSON Schema document.","title":"Via the Web UI"},{"location":"usage/schemas/#directly-on-disk","text":"Place a file at {shared-fs}/templates/{schemaID}.json : cat > ./shared/db/templates/chat.v1.json << 'EOF' { \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"chat.v1\", \"type\": \"object\", \"properties\": { \"messages\": {\"type\": \"array\"} }, \"required\": [\"messages\"] } EOF The worker picks up the file automatically \u2014 no restart required.","title":"Directly on Disk"},{"location":"usage/schemas/#listing-and-retrieving-schemas","text":"# List all registered schema IDs curl http://127.0.0.1:8080/admin/schemas # Retrieve a specific schema curl http://127.0.0.1:8080/schema/chat.v1","title":"Listing and Retrieving Schemas"},{"location":"usage/schemas/#schema-naming-convention","text":"Schema IDs use the format {name}.{version} : Schema ID Purpose chat.v1 Chat session with messages array user.v1 User profile data product.v2 Product catalogue entry (v2 with new fields) iot_reading.v1 IoT sensor reading","title":"Schema Naming Convention"},{"location":"usage/schemas/#example-schemas","text":"","title":"Example Schemas"},{"location":"usage/schemas/#chat-messages","text":"{ \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"chat.v1\" , \"type\" : \"object\" , \"properties\" : { \"messages\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"properties\" : { \"role\" : { \"type\" : \"string\" , \"enum\" : [ \"user\" , \"assistant\" , \"system\" ]}, \"content\" : { \"type\" : \"string\" } }, \"required\" : [ \"role\" , \"content\" ] } } }, \"required\" : [ \"messages\" ] }","title":"Chat Messages"},{"location":"usage/schemas/#user-profile","text":"{ \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"user.v1\" , \"type\" : \"object\" , \"properties\" : { \"id\" : { \"type\" : \"string\" }, \"name\" : { \"type\" : \"string\" }, \"email\" : { \"type\" : \"string\" , \"format\" : \"email\" }, \"created_at\" : { \"type\" : \"string\" , \"format\" : \"date-time\" }, \"settings\" : { \"type\" : \"object\" } }, \"required\" : [ \"id\" , \"email\" ] }","title":"User Profile"},{"location":"usage/schemas/#iot-sensor-reading","text":"{ \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"iot_reading.v1\" , \"type\" : \"object\" , \"properties\" : { \"device_id\" : { \"type\" : \"string\" }, \"timestamp\" : { \"type\" : \"string\" , \"format\" : \"date-time\" }, \"temperature\" : { \"type\" : \"number\" }, \"humidity\" : { \"type\" : \"number\" , \"minimum\" : 0 , \"maximum\" : 100 }, \"location\" : { \"type\" : \"object\" , \"properties\" : { \"lat\" : { \"type\" : \"number\" }, \"lng\" : { \"type\" : \"number\" } } } }, \"required\" : [ \"device_id\" , \"timestamp\" ] }","title":"IoT Sensor Reading"},{"location":"usage/schemas/#product-catalogue","text":"{ \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"product.v1\" , \"type\" : \"object\" , \"properties\" : { \"sku\" : { \"type\" : \"string\" }, \"name\" : { \"type\" : \"string\" }, \"description\" : { \"type\" : \"string\" }, \"price\" : { \"type\" : \"number\" , \"minimum\" : 0 }, \"currency\" : { \"type\" : \"string\" , \"enum\" : [ \"USD\" , \"EUR\" , \"GBP\" ]}, \"in_stock\" : { \"type\" : \"boolean\" }, \"tags\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"string\" }} }, \"required\" : [ \"sku\" , \"name\" , \"price\" , \"currency\" ] }","title":"Product Catalogue"},{"location":"usage/schemas/#what-happens-on-validation-failure","text":"If a PUT /entity/{database} request contains data that does not match the registered schema: The Processing Worker rejects the payload. The Main Worker returns HTTP 400 with an error message. Nothing is written to disk. Example: # This will fail \u2014 \"messages\" is required but missing curl -s -X PUT http://127.0.0.1:8080/entity/chatdb \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{\"session_bad\": {\"wrong_field\": \"oops\"}}' { \"error\" : \"schema validation failed: messages is required\" }","title":"What Happens on Validation Failure"},{"location":"usage/schemas/#schema-versioning","text":"When you need to evolve your data model: Create a new schema with an incremented version: chat.v2 . Write new entities using the new schema. Old entities remain stored under their original schema ID. There is no automatic migration \u2014 migration logic belongs in your application.","title":"Schema Versioning"},{"location":"usage/security/","text":"Security Model \u00b6 DeltaDatabase is designed with security-first principles. This page describes every security mechanism in the system. Security Properties at a Glance \u00b6 Property Implementation Encryption at rest AES-256-GCM per entity; nonce and AEAD tag stored in .meta.json Key distribution RSA-OAEP wrap/unwrap; master key never leaves the Main Worker in plaintext Keys in memory only Processing Workers clear keys on shutdown; keys are never written to disk Tamper detection AEAD tag checked on every decryption; reads fail closed on mismatch Schema validation JSON Schema draft-07 enforced before every write Log redaction No plaintext entity data or key material is emitted in logs Token expiry Worker tokens: 1 h (configurable). Client tokens: 24 h (configurable) Path traversal protection Entity keys, database names, and schema IDs are validated to reject / , \\ , and .. Request body limit REST PUT/schema endpoints reject bodies larger than 1 MiB Write durability (FS) fdatasync before atomic rename guarantees no data loss on worker crash S3 credentials Pass via S3_ACCESS_KEY / S3_SECRET_KEY env vars, not CLI flags Encryption Details \u00b6 Algorithm \u00b6 AES-256-GCM (Authenticated Encryption with Associated Data): 256-bit key derived from the master key. Random 12-byte nonce per entity write. 128-bit AEAD authentication tag. On-disk Format \u00b6 For each entity, two files are written: files/<entityID>.json.enc \u2514\u2500 raw AES-256-GCM ciphertext files/<entityID>.meta.json \u2514\u2500 { \"key_id\": \"main-key-v1\", \"alg\": \"AES-GCM\", \"iv\": \"<base64-nonce>\", \"tag\": \"<base64-AEAD-tag>\", \"schema_id\": \"chat.v1\", \"version\": 3, \"writer_id\": \"proc-1\" } The AEAD tag is checked on every read. If the tag does not match (e.g., due to file corruption or tampering), the read fails with an error and a security event is logged. Key Derivation and Distribution \u00b6 Main Worker \u2502 \u251c\u2500 Holds master AES key in volatile RAM (never on disk) \u2502 \u2514\u2500 On Processing Worker Subscribe: \u2502 \u251c\u2500 Worker sends its ephemeral RSA public key \u2502 \u251c\u2500 Main Worker encrypts master key with RSA-OAEP \u2502 \u2514\u2500 Worker decrypts with its RSA private key \u2192 stores plaintext key in volatile RAM only \u2192 RSA private key discarded after use Key Management \u00b6 Key Rotation \u00b6 Generate a new 32-byte AES key: openssl rand -hex 32 . Restart the Main Worker with -master-key=<new_key> . Processing Workers receive the new key on their next subscription. New writes use the new key. Old entities remain encrypted under the old key. Old entities are re-encrypted lazily on the next write, or via a background rewrap job. Warning Keep a secure backup of all master keys ever used. Entities encrypted under an old key require the old key to be readable. Key Storage Best Practices \u00b6 Never commit the master key to source control. Never pass the master key as a CLI flag in production (it appears in ps output and shell history). Use a secrets manager (HashiCorp Vault, AWS Secrets Manager, Kubernetes Secret) to inject the key as an environment variable. Use HSM or OS keyring integration for hardware-backed key storage in high-security environments. Authentication Security \u00b6 Client Tokens \u00b6 Tokens are signed server-side and validated on every request. Token TTL is configurable via -client-ttl (default: 24 h). Tokens are not refreshable; clients must re-login. Worker Tokens \u00b6 Processing Workers receive a short-lived session token (default: 1 h) during subscription. The token is used for all subsequent gRPC calls to the Main Worker. Workers must re-subscribe after token expiry. Input Validation \u00b6 Path Traversal Protection \u00b6 Entity keys, database names, and schema IDs are validated to reject: - / (path separator) - \\ (Windows path separator) - .. (parent directory traversal) Request Size Limits \u00b6 PUT entity and PUT schema endpoints reject request bodies larger than 1 MiB . Schema Validation \u00b6 Every PUT /entity/{database} request is validated against the registered JSON Schema before being encrypted and stored. Validation failures return HTTP 400 and nothing is written to disk. Log Redaction \u00b6 Logs never contain: - Decrypted entity content. - Encryption keys or key material. - Bearer tokens or worker session tokens. All security events (tamper detection, auth failures, key rotation) are logged without exposing sensitive data. Network Security Recommendations \u00b6 For production deployments: TLS everywhere \u2014 put the Main Worker behind a TLS-terminating reverse proxy (nginx, Traefik, AWS ALB). Restrict gRPC port \u2014 the internal gRPC port ( :50051 ) should not be exposed to external networks. Use network policies in Kubernetes or firewall rules in bare-metal deployments. Network policies \u2014 in Kubernetes, use NetworkPolicy to ensure only Processing Workers can reach the Main Worker's gRPC port. Token TTL \u2014 shorten -client-ttl for sensitive applications (e.g., 1h ). Reporting Security Issues \u00b6 If you discover a security vulnerability, please report it privately by opening a GitHub Security Advisory at: https://github.com/DeltaRule/DeltaDatabase/security/advisories/new Do not open a public issue for security vulnerabilities.","title":"Security Model"},{"location":"usage/security/#security-model","text":"DeltaDatabase is designed with security-first principles. This page describes every security mechanism in the system.","title":"Security Model"},{"location":"usage/security/#security-properties-at-a-glance","text":"Property Implementation Encryption at rest AES-256-GCM per entity; nonce and AEAD tag stored in .meta.json Key distribution RSA-OAEP wrap/unwrap; master key never leaves the Main Worker in plaintext Keys in memory only Processing Workers clear keys on shutdown; keys are never written to disk Tamper detection AEAD tag checked on every decryption; reads fail closed on mismatch Schema validation JSON Schema draft-07 enforced before every write Log redaction No plaintext entity data or key material is emitted in logs Token expiry Worker tokens: 1 h (configurable). Client tokens: 24 h (configurable) Path traversal protection Entity keys, database names, and schema IDs are validated to reject / , \\ , and .. Request body limit REST PUT/schema endpoints reject bodies larger than 1 MiB Write durability (FS) fdatasync before atomic rename guarantees no data loss on worker crash S3 credentials Pass via S3_ACCESS_KEY / S3_SECRET_KEY env vars, not CLI flags","title":"Security Properties at a Glance"},{"location":"usage/security/#encryption-details","text":"","title":"Encryption Details"},{"location":"usage/security/#algorithm","text":"AES-256-GCM (Authenticated Encryption with Associated Data): 256-bit key derived from the master key. Random 12-byte nonce per entity write. 128-bit AEAD authentication tag.","title":"Algorithm"},{"location":"usage/security/#on-disk-format","text":"For each entity, two files are written: files/<entityID>.json.enc \u2514\u2500 raw AES-256-GCM ciphertext files/<entityID>.meta.json \u2514\u2500 { \"key_id\": \"main-key-v1\", \"alg\": \"AES-GCM\", \"iv\": \"<base64-nonce>\", \"tag\": \"<base64-AEAD-tag>\", \"schema_id\": \"chat.v1\", \"version\": 3, \"writer_id\": \"proc-1\" } The AEAD tag is checked on every read. If the tag does not match (e.g., due to file corruption or tampering), the read fails with an error and a security event is logged.","title":"On-disk Format"},{"location":"usage/security/#key-derivation-and-distribution","text":"Main Worker \u2502 \u251c\u2500 Holds master AES key in volatile RAM (never on disk) \u2502 \u2514\u2500 On Processing Worker Subscribe: \u2502 \u251c\u2500 Worker sends its ephemeral RSA public key \u2502 \u251c\u2500 Main Worker encrypts master key with RSA-OAEP \u2502 \u2514\u2500 Worker decrypts with its RSA private key \u2192 stores plaintext key in volatile RAM only \u2192 RSA private key discarded after use","title":"Key Derivation and Distribution"},{"location":"usage/security/#key-management","text":"","title":"Key Management"},{"location":"usage/security/#key-rotation","text":"Generate a new 32-byte AES key: openssl rand -hex 32 . Restart the Main Worker with -master-key=<new_key> . Processing Workers receive the new key on their next subscription. New writes use the new key. Old entities remain encrypted under the old key. Old entities are re-encrypted lazily on the next write, or via a background rewrap job. Warning Keep a secure backup of all master keys ever used. Entities encrypted under an old key require the old key to be readable.","title":"Key Rotation"},{"location":"usage/security/#key-storage-best-practices","text":"Never commit the master key to source control. Never pass the master key as a CLI flag in production (it appears in ps output and shell history). Use a secrets manager (HashiCorp Vault, AWS Secrets Manager, Kubernetes Secret) to inject the key as an environment variable. Use HSM or OS keyring integration for hardware-backed key storage in high-security environments.","title":"Key Storage Best Practices"},{"location":"usage/security/#authentication-security","text":"","title":"Authentication Security"},{"location":"usage/security/#client-tokens","text":"Tokens are signed server-side and validated on every request. Token TTL is configurable via -client-ttl (default: 24 h). Tokens are not refreshable; clients must re-login.","title":"Client Tokens"},{"location":"usage/security/#worker-tokens","text":"Processing Workers receive a short-lived session token (default: 1 h) during subscription. The token is used for all subsequent gRPC calls to the Main Worker. Workers must re-subscribe after token expiry.","title":"Worker Tokens"},{"location":"usage/security/#input-validation","text":"","title":"Input Validation"},{"location":"usage/security/#path-traversal-protection","text":"Entity keys, database names, and schema IDs are validated to reject: - / (path separator) - \\ (Windows path separator) - .. (parent directory traversal)","title":"Path Traversal Protection"},{"location":"usage/security/#request-size-limits","text":"PUT entity and PUT schema endpoints reject request bodies larger than 1 MiB .","title":"Request Size Limits"},{"location":"usage/security/#schema-validation","text":"Every PUT /entity/{database} request is validated against the registered JSON Schema before being encrypted and stored. Validation failures return HTTP 400 and nothing is written to disk.","title":"Schema Validation"},{"location":"usage/security/#log-redaction","text":"Logs never contain: - Decrypted entity content. - Encryption keys or key material. - Bearer tokens or worker session tokens. All security events (tamper detection, auth failures, key rotation) are logged without exposing sensitive data.","title":"Log Redaction"},{"location":"usage/security/#network-security-recommendations","text":"For production deployments: TLS everywhere \u2014 put the Main Worker behind a TLS-terminating reverse proxy (nginx, Traefik, AWS ALB). Restrict gRPC port \u2014 the internal gRPC port ( :50051 ) should not be exposed to external networks. Use network policies in Kubernetes or firewall rules in bare-metal deployments. Network policies \u2014 in Kubernetes, use NetworkPolicy to ensure only Processing Workers can reach the Main Worker's gRPC port. Token TTL \u2014 shorten -client-ttl for sensitive applications (e.g., 1h ).","title":"Network Security Recommendations"},{"location":"usage/security/#reporting-security-issues","text":"If you discover a security vulnerability, please report it privately by opening a GitHub Security Advisory at: https://github.com/DeltaRule/DeltaDatabase/security/advisories/new Do not open a public issue for security vulnerabilities.","title":"Reporting Security Issues"},{"location":"usage/examples/","text":"Examples \u00b6 The following examples show how to use DeltaDatabase for different real-world applications. Each example includes complete, runnable code in multiple languages. Available Examples \u00b6 Example Use Case Languages Chat Application Store AI/LLM conversation histories Go, Python, curl User Profiles CRUD for user accounts and settings Python, curl IoT Sensor Data Store time-series sensor readings Python, curl Configuration Store Manage per-service and per-environment config Go, curl E-Commerce Catalogue Product catalogue and inventory Python, curl Common Pattern \u00b6 All examples follow the same three-step pattern: 1. Log in \u2192 POS T / api / log in \u2192 get Bearer to ken 2. Write \u2192 PUT / entity / { db } \u2192 store JSON entity 3. Read \u2192 GET / entity / { db }? key = ... \u2192 retrieve entity Minimal Working Example (curl) \u00b6 BASE = \"http://127.0.0.1:8080\" # 1. Get a token TOKEN = $( curl -sf -X POST \" $BASE /api/login\" \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"demo\"}' | jq -r .token ) # 2. Write an entity curl -sf -X PUT \" $BASE /entity/mydb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{\"my_key\": {\"hello\": \"world\"}}' # 3. Read it back curl -sf \" $BASE /entity/mydb?key=my_key\" \\ -H \"Authorization: Bearer $TOKEN \" # \u2192 {\"hello\":\"world\"} Before Running Examples \u00b6 Make sure DeltaDatabase is running: # Quickest way \u2014 Docker all-in-one docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up -d # Verify curl http://127.0.0.1:8080/health # \u2192 {\"status\":\"ok\"}","title":"Overview"},{"location":"usage/examples/#examples","text":"The following examples show how to use DeltaDatabase for different real-world applications. Each example includes complete, runnable code in multiple languages.","title":"Examples"},{"location":"usage/examples/#available-examples","text":"Example Use Case Languages Chat Application Store AI/LLM conversation histories Go, Python, curl User Profiles CRUD for user accounts and settings Python, curl IoT Sensor Data Store time-series sensor readings Python, curl Configuration Store Manage per-service and per-environment config Go, curl E-Commerce Catalogue Product catalogue and inventory Python, curl","title":"Available Examples"},{"location":"usage/examples/#common-pattern","text":"All examples follow the same three-step pattern: 1. Log in \u2192 POS T / api / log in \u2192 get Bearer to ken 2. Write \u2192 PUT / entity / { db } \u2192 store JSON entity 3. Read \u2192 GET / entity / { db }? key = ... \u2192 retrieve entity","title":"Common Pattern"},{"location":"usage/examples/#minimal-working-example-curl","text":"BASE = \"http://127.0.0.1:8080\" # 1. Get a token TOKEN = $( curl -sf -X POST \" $BASE /api/login\" \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"demo\"}' | jq -r .token ) # 2. Write an entity curl -sf -X PUT \" $BASE /entity/mydb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{\"my_key\": {\"hello\": \"world\"}}' # 3. Read it back curl -sf \" $BASE /entity/mydb?key=my_key\" \\ -H \"Authorization: Bearer $TOKEN \" # \u2192 {\"hello\":\"world\"}","title":"Minimal Working Example (curl)"},{"location":"usage/examples/#before-running-examples","text":"Make sure DeltaDatabase is running: # Quickest way \u2014 Docker all-in-one docker compose -f deploy/docker-compose/docker-compose.all-in-one.yml up -d # Verify curl http://127.0.0.1:8080/health # \u2192 {\"status\":\"ok\"}","title":"Before Running Examples"},{"location":"usage/examples/chat-app/","text":"Example: Chat Application \u00b6 This example ships a complete, runnable chat application in examples/chat/ that uses DeltaDatabase as its sole storage backend. The application is built with Flask and tested with Playwright . Screenshots \u00b6 Sign in \u00b6 Register \u00b6 Chat (empty state) \u00b6 Chat (conversation) \u00b6 Settings \u00b6 Admin Panel \u00b6 Features \u00b6 Feature Details \ud83d\udd10 Authentication Session-based login/register \u2014 every page except /login and /register is protected \ud83d\udcac Per-user chats Chat histories are isolated per user \u2699 User settings Each user stores their own OpenAI API key, custom base URL, and default model \ud83d\udee1 Admin panel Admins see all users and assign per-user allowed model lists \ud83e\udd16 OpenAI backend OpenAI-compatible APIs only (key + optional custom endpoint) \ud83d\uddc4 DeltaDatabase All data stored exclusively in DeltaDatabase \ud83e\uddea Playwright tests End-to-end browser tests for all major flows Quick Start \u00b6 Docker Compose \u00b6 cd examples/chat docker compose up --build Open http://localhost:5000 . Default admin credentials: admin / admin123 . To run without a real OpenAI key, enable mock mode: MOCK_OPENAI = true docker compose up --build Local Python \u00b6 # Start DeltaDatabase docker compose -f ../../deploy/docker-compose/docker-compose.all-in-one.yml up -d # Install deps and run pip install -r examples/chat/requirements.txt DELTA_DB_URL = http://localhost:8080 MOCK_OPENAI = true python examples/chat/app.py DeltaDatabase Schema \u00b6 The app stores data across five logical databases \u2014 no external database is needed: Database Key pattern Contents chat_users <username> Password hash, admin flag, creation timestamp chat_sessions <username>__<chat_id> Full message history, title, timestamps chat_index <username> Ordered list of chat IDs for that user chat_user_config <username> OpenAI API key, base URL, default model chat_admin_config global Global available models + per-user overrides chat_admin_config users_index Ordered list of all registered usernames Schema example \u2014 a chat session \u00b6 { \"username\" : \"alice\" , \"id\" : \"a1b2c3d4e5\" , \"title\" : \"What is DeltaDatabase?\" , \"messages\" : [ { \"role\" : \"user\" , \"content\" : \"What is DeltaDatabase?\" }, { \"role\" : \"assistant\" , \"content\" : \"An encrypted-at-rest JSON database written in Go.\" } ], \"created_at\" : \"2026-02-25T10:00:00\" , \"updated_at\" : \"2026-02-25T10:00:05\" } Environment Variables \u00b6 Variable Default Description DELTA_DB_URL http://localhost:8080 DeltaDatabase REST endpoint DELTA_DB_CLIENT_ID chat-app Client ID for DeltaDatabase auth FLASK_SECRET_KEY random Flask session signing key ADMIN_USERNAME admin Username created on first run ADMIN_PASSWORD admin123 Password for the default admin MOCK_OPENAI false Return stub replies instead of calling OpenAI PORT 5000 HTTP port Running Playwright Tests \u00b6 # Start the stack in mock mode MOCK_OPENAI = true docker compose -f examples/chat/docker-compose.yml up -d --build # Install and run tests cd examples/chat/tests npm install npx playwright install --with-deps chromium npm test Test suites: File Covers auth.spec.js Login, register, protected-route redirects, logout chat.spec.js New chat, send/receive message, title update, delete settings.spec.js Open settings, save API key, model selection, navigation admin.spec.js Admin visibility, model assignment, non-admin blocked Architecture \u00b6 Browser \u2502 HTTP \u25bc Flask (examples/chat/app.py) :5000 \u2502 REST (HTTP/JSON) \u25bc DeltaDatabase Main Worker :8080 \u2502 gRPC \u25bc DeltaDatabase Processing Worker \u2502 Encrypted JSON on disk The Flask app holds a single DeltaDatabase Bearer token (refreshed automatically on expiry) and maps every application concept \u2014 users, chats, config \u2014 to DeltaDatabase entities. No SQL, no Redis, no separate session store. Source \u00b6 Full source code: examples/chat/","title":"Chat Application"},{"location":"usage/examples/chat-app/#example-chat-application","text":"This example ships a complete, runnable chat application in examples/chat/ that uses DeltaDatabase as its sole storage backend. The application is built with Flask and tested with Playwright .","title":"Example: Chat Application"},{"location":"usage/examples/chat-app/#screenshots","text":"","title":"Screenshots"},{"location":"usage/examples/chat-app/#sign-in","text":"","title":"Sign in"},{"location":"usage/examples/chat-app/#register","text":"","title":"Register"},{"location":"usage/examples/chat-app/#chat-empty-state","text":"","title":"Chat (empty state)"},{"location":"usage/examples/chat-app/#chat-conversation","text":"","title":"Chat (conversation)"},{"location":"usage/examples/chat-app/#settings","text":"","title":"Settings"},{"location":"usage/examples/chat-app/#admin-panel","text":"","title":"Admin Panel"},{"location":"usage/examples/chat-app/#features","text":"Feature Details \ud83d\udd10 Authentication Session-based login/register \u2014 every page except /login and /register is protected \ud83d\udcac Per-user chats Chat histories are isolated per user \u2699 User settings Each user stores their own OpenAI API key, custom base URL, and default model \ud83d\udee1 Admin panel Admins see all users and assign per-user allowed model lists \ud83e\udd16 OpenAI backend OpenAI-compatible APIs only (key + optional custom endpoint) \ud83d\uddc4 DeltaDatabase All data stored exclusively in DeltaDatabase \ud83e\uddea Playwright tests End-to-end browser tests for all major flows","title":"Features"},{"location":"usage/examples/chat-app/#quick-start","text":"","title":"Quick Start"},{"location":"usage/examples/chat-app/#docker-compose","text":"cd examples/chat docker compose up --build Open http://localhost:5000 . Default admin credentials: admin / admin123 . To run without a real OpenAI key, enable mock mode: MOCK_OPENAI = true docker compose up --build","title":"Docker Compose"},{"location":"usage/examples/chat-app/#local-python","text":"# Start DeltaDatabase docker compose -f ../../deploy/docker-compose/docker-compose.all-in-one.yml up -d # Install deps and run pip install -r examples/chat/requirements.txt DELTA_DB_URL = http://localhost:8080 MOCK_OPENAI = true python examples/chat/app.py","title":"Local Python"},{"location":"usage/examples/chat-app/#deltadatabase-schema","text":"The app stores data across five logical databases \u2014 no external database is needed: Database Key pattern Contents chat_users <username> Password hash, admin flag, creation timestamp chat_sessions <username>__<chat_id> Full message history, title, timestamps chat_index <username> Ordered list of chat IDs for that user chat_user_config <username> OpenAI API key, base URL, default model chat_admin_config global Global available models + per-user overrides chat_admin_config users_index Ordered list of all registered usernames","title":"DeltaDatabase Schema"},{"location":"usage/examples/chat-app/#schema-example-a-chat-session","text":"{ \"username\" : \"alice\" , \"id\" : \"a1b2c3d4e5\" , \"title\" : \"What is DeltaDatabase?\" , \"messages\" : [ { \"role\" : \"user\" , \"content\" : \"What is DeltaDatabase?\" }, { \"role\" : \"assistant\" , \"content\" : \"An encrypted-at-rest JSON database written in Go.\" } ], \"created_at\" : \"2026-02-25T10:00:00\" , \"updated_at\" : \"2026-02-25T10:00:05\" }","title":"Schema example \u2014 a chat session"},{"location":"usage/examples/chat-app/#environment-variables","text":"Variable Default Description DELTA_DB_URL http://localhost:8080 DeltaDatabase REST endpoint DELTA_DB_CLIENT_ID chat-app Client ID for DeltaDatabase auth FLASK_SECRET_KEY random Flask session signing key ADMIN_USERNAME admin Username created on first run ADMIN_PASSWORD admin123 Password for the default admin MOCK_OPENAI false Return stub replies instead of calling OpenAI PORT 5000 HTTP port","title":"Environment Variables"},{"location":"usage/examples/chat-app/#running-playwright-tests","text":"# Start the stack in mock mode MOCK_OPENAI = true docker compose -f examples/chat/docker-compose.yml up -d --build # Install and run tests cd examples/chat/tests npm install npx playwright install --with-deps chromium npm test Test suites: File Covers auth.spec.js Login, register, protected-route redirects, logout chat.spec.js New chat, send/receive message, title update, delete settings.spec.js Open settings, save API key, model selection, navigation admin.spec.js Admin visibility, model assignment, non-admin blocked","title":"Running Playwright Tests"},{"location":"usage/examples/chat-app/#architecture","text":"Browser \u2502 HTTP \u25bc Flask (examples/chat/app.py) :5000 \u2502 REST (HTTP/JSON) \u25bc DeltaDatabase Main Worker :8080 \u2502 gRPC \u25bc DeltaDatabase Processing Worker \u2502 Encrypted JSON on disk The Flask app holds a single DeltaDatabase Bearer token (refreshed automatically on expiry) and maps every application concept \u2014 users, chats, config \u2014 to DeltaDatabase entities. No SQL, no Redis, no separate session store.","title":"Architecture"},{"location":"usage/examples/chat-app/#source","text":"Full source code: examples/chat/","title":"Source"},{"location":"usage/examples/config-store/","text":"Example: Configuration Store \u00b6 Use DeltaDatabase as a secure, versioned configuration store for microservices. Each service reads its own configuration entity at startup and optionally polls for changes. Use case: Feature flags, per-environment config (dev/staging/prod), per-tenant overrides, A/B test parameters. Database: configdb Entity key: \"{service}.{environment}\" (e.g., api-gateway.production ) Entity value: arbitrary service configuration object Schema Setup \u00b6 Schemas are optional for config stores \u2014 you can use a permissive schema that accepts any object: TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"admin\"}' | jq -r .token ) # Permissive schema \u2014 any JSON object is valid curl -s -X PUT http://127.0.0.1:8080/schema/config.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"config.v1\", \"type\": \"object\" }' Or enforce a typed structure: { \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"service_config.v1\" , \"type\" : \"object\" , \"properties\" : { \"service\" : { \"type\" : \"string\" }, \"environment\" : { \"type\" : \"string\" , \"enum\" : [ \"development\" , \"staging\" , \"production\" ]}, \"enabled\" : { \"type\" : \"boolean\" }, \"rate_limit\" : { \"type\" : \"integer\" , \"minimum\" : 0 }, \"log_level\" : { \"type\" : \"string\" , \"enum\" : [ \"debug\" , \"info\" , \"warn\" , \"error\" ]}, \"features\" : { \"type\" : \"object\" }, \"updated_at\" : { \"type\" : \"string\" , \"format\" : \"date-time\" } }, \"required\" : [ \"service\" , \"environment\" ] } Go Client \u00b6 package main import ( \"bytes\" \"encoding/json\" \"fmt\" \"log\" \"net/http\" \"net/url\" \"time\" ) const ( baseURL = \"http://127.0.0.1:8080\" database = \"configdb\" ) // ServiceConfig is the configuration for a single service + environment. type ServiceConfig struct { Service string `json:\"service\"` Environment string `json:\"environment\"` Enabled bool `json:\"enabled\"` RateLimit int `json:\"rate_limit\"` LogLevel string `json:\"log_level\"` Features map [ string ] interface {} `json:\"features\"` UpdatedAt time . Time `json:\"updated_at\"` } type ConfigClient struct { httpClient * http . Client token string } func NewConfigClient ( clientID string ) ( * ConfigClient , error ) { c := & ConfigClient { httpClient : & http . Client {}} body , _ := json . Marshal ( map [ string ] string { \"client_id\" : clientID }) resp , err := c . httpClient . Post ( baseURL + \"/api/login\" , \"application/json\" , bytes . NewReader ( body )) if err != nil { return nil , err } defer resp . Body . Close () var result struct { Token string `json:\"token\"` } json . NewDecoder ( resp . Body ). Decode ( & result ) c . token = result . Token return c , nil } func configKey ( service , environment string ) string { return service + \".\" + environment } func ( c * ConfigClient ) Get ( service , environment string ) ( * ServiceConfig , error ) { key := url . QueryEscape ( configKey ( service , environment )) req , _ := http . NewRequest ( http . MethodGet , fmt . Sprintf ( \"%s/entity/%s?key=%s\" , baseURL , database , key ), nil ) req . Header . Set ( \"Authorization\" , \"Bearer \" + c . token ) resp , err := c . httpClient . Do ( req ) if err != nil { return nil , err } defer resp . Body . Close () if resp . StatusCode == http . StatusNotFound { return nil , nil } var cfg ServiceConfig return & cfg , json . NewDecoder ( resp . Body ). Decode ( & cfg ) } func ( c * ConfigClient ) Set ( cfg ServiceConfig ) error { cfg . UpdatedAt = time . Now (). UTC () entityJSON , _ := json . Marshal ( cfg ) key := configKey ( cfg . Service , cfg . Environment ) payload , _ := json . Marshal ( map [ string ] json . RawMessage { key : entityJSON }) req , _ := http . NewRequest ( http . MethodPut , fmt . Sprintf ( \"%s/entity/%s\" , baseURL , database ), bytes . NewReader ( payload )) req . Header . Set ( \"Authorization\" , \"Bearer \" + c . token ) req . Header . Set ( \"Content-Type\" , \"application/json\" ) resp , err := c . httpClient . Do ( req ) if err != nil { return err } defer resp . Body . Close () if resp . StatusCode != http . StatusOK { return fmt . Errorf ( \"set config failed: status %d\" , resp . StatusCode ) } return nil } func main () { client , err := NewConfigClient ( \"config-manager\" ) if err != nil { log . Fatal ( err ) } // Write configs for different environments configs := [] ServiceConfig { { Service : \"api-gateway\" , Environment : \"development\" , Enabled : true , RateLimit : 1000 , LogLevel : \"debug\" , Features : map [ string ] interface {}{ \"new_ui\" : true , \"beta_api\" : true }, }, { Service : \"api-gateway\" , Environment : \"production\" , Enabled : true , RateLimit : 100 , LogLevel : \"warn\" , Features : map [ string ] interface {}{ \"new_ui\" : false , \"beta_api\" : false }, }, } for _ , cfg := range configs { if err := client . Set ( cfg ); err != nil { log . Fatalf ( \"set config: %v\" , err ) } fmt . Printf ( \"Saved config: %s.%s\\n\" , cfg . Service , cfg . Environment ) } // Read back prodCfg , err := client . Get ( \"api-gateway\" , \"production\" ) if err != nil { log . Fatal ( err ) } fmt . Printf ( \"\\nProduction config:\\n\" ) fmt . Printf ( \" rate_limit: %d\\n\" , prodCfg . RateLimit ) fmt . Printf ( \" log_level: %s\\n\" , prodCfg . LogLevel ) fmt . Printf ( \" features: %v\\n\" , prodCfg . Features ) } curl Walkthrough \u00b6 BASE = \"http://127.0.0.1:8080\" TOKEN = $( curl -sf -X POST \" $BASE /api/login\" \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"ops\"}' | jq -r .token ) # Write production config curl -sf -X PUT \" $BASE /entity/configdb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"payment-service.production\": { \"service\": \"payment-service\", \"environment\": \"production\", \"enabled\": true, \"rate_limit\": 50, \"log_level\": \"warn\", \"features\": { \"stripe_v2\": true, \"paypal\": false, \"apple_pay\": true } } }' # Read it back curl -sf \" $BASE /entity/configdb?key=payment-service.production\" \\ -H \"Authorization: Bearer $TOKEN \" | jq . # Enable PayPal CURRENT = $( curl -sf \" $BASE /entity/configdb?key=payment-service.production\" \\ -H \"Authorization: Bearer $TOKEN \" ) UPDATED = $( echo \" $CURRENT \" | jq '.features.paypal = true' ) curl -sf -X PUT \" $BASE /entity/configdb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d \"{\\\"payment-service.production\\\": $UPDATED }\" echo \"PayPal enabled\" Feature Flag Pattern \u00b6 Store feature flags per service with per-tenant overrides: import requests BASE_URL = \"http://127.0.0.1:8080\" token = requests . post ( f \" { BASE_URL } /api/login\" , json = { \"client_id\" : \"flag-service\" }) . json ()[ \"token\" ] headers = { \"Authorization\" : f \"Bearer { token } \" } def get_flags ( service : str , tenant_id : str | None = None ) -> dict : \"\"\" Get feature flags for a service. Tenant overrides take precedence over service defaults. \"\"\" # Base flags for the service resp = requests . get ( f \" { BASE_URL } /entity/configdb\" , params = { \"key\" : f \" { service } .flags\" }, headers = headers ) base_flags = resp . json () . get ( \"flags\" , {}) if resp . status_code == 200 else {} if tenant_id is None : return base_flags # Per-tenant overrides resp = requests . get ( f \" { BASE_URL } /entity/configdb\" , params = { \"key\" : f \" { service } .flags. { tenant_id } \" }, headers = headers ) tenant_flags = resp . json () . get ( \"flags\" , {}) if resp . status_code == 200 else {} return { ** base_flags , ** tenant_flags } # tenant overrides win # Set global flags requests . put ( f \" { BASE_URL } /entity/configdb\" , headers = headers , json = { \"recommendation-engine.flags\" : { \"flags\" : { \"new_algorithm\" : False , \"personalization\" : True , \"ab_test_v2\" : False } } }) . raise_for_status () # Set per-tenant override (enable new algorithm for tenant \"acme\") requests . put ( f \" { BASE_URL } /entity/configdb\" , headers = headers , json = { \"recommendation-engine.flags.acme\" : { \"flags\" : { \"new_algorithm\" : True , \"ab_test_v2\" : True } } }) . raise_for_status () # Check flags print ( \"Default flags:\" , get_flags ( \"recommendation-engine\" )) print ( \"ACME flags: \" , get_flags ( \"recommendation-engine\" , \"acme\" )) Output: Default flags: {'new_algorithm': False, 'personalization': True, 'ab_test_v2': False} ACME flags: {'new_algorithm': True, 'personalization': True, 'ab_test_v2': True} Config Polling Pattern \u00b6 Services can poll for configuration changes: import time import threading def poll_config ( service : str , env : str , interval_s : int = 30 ): \"\"\"Poll DeltaDatabase for config changes every `interval_s` seconds.\"\"\" current_config = {} while True : resp = requests . get ( f \" { BASE_URL } /entity/configdb\" , params = { \"key\" : f \" { service } . { env } \" }, headers = headers , ) if resp . status_code == 200 : new_config = resp . json () if new_config != current_config : print ( f \"Config changed for { service } . { env } : { new_config } \" ) current_config = new_config apply_config ( new_config ) # your application logic here time . sleep ( interval_s ) def apply_config ( config : dict ) -> None : \"\"\"Apply the new configuration to the running service.\"\"\" print ( f \"Applying: rate_limit= { config . get ( 'rate_limit' ) } , \" f \"log_level= { config . get ( 'log_level' ) } \" ) # Start polling in a background thread threading . Thread ( target = poll_config , args = ( \"api-gateway\" , \"production\" ), daemon = True ) . start ()","title":"Configuration Store"},{"location":"usage/examples/config-store/#example-configuration-store","text":"Use DeltaDatabase as a secure, versioned configuration store for microservices. Each service reads its own configuration entity at startup and optionally polls for changes. Use case: Feature flags, per-environment config (dev/staging/prod), per-tenant overrides, A/B test parameters. Database: configdb Entity key: \"{service}.{environment}\" (e.g., api-gateway.production ) Entity value: arbitrary service configuration object","title":"Example: Configuration Store"},{"location":"usage/examples/config-store/#schema-setup","text":"Schemas are optional for config stores \u2014 you can use a permissive schema that accepts any object: TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"admin\"}' | jq -r .token ) # Permissive schema \u2014 any JSON object is valid curl -s -X PUT http://127.0.0.1:8080/schema/config.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"config.v1\", \"type\": \"object\" }' Or enforce a typed structure: { \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"service_config.v1\" , \"type\" : \"object\" , \"properties\" : { \"service\" : { \"type\" : \"string\" }, \"environment\" : { \"type\" : \"string\" , \"enum\" : [ \"development\" , \"staging\" , \"production\" ]}, \"enabled\" : { \"type\" : \"boolean\" }, \"rate_limit\" : { \"type\" : \"integer\" , \"minimum\" : 0 }, \"log_level\" : { \"type\" : \"string\" , \"enum\" : [ \"debug\" , \"info\" , \"warn\" , \"error\" ]}, \"features\" : { \"type\" : \"object\" }, \"updated_at\" : { \"type\" : \"string\" , \"format\" : \"date-time\" } }, \"required\" : [ \"service\" , \"environment\" ] }","title":"Schema Setup"},{"location":"usage/examples/config-store/#go-client","text":"package main import ( \"bytes\" \"encoding/json\" \"fmt\" \"log\" \"net/http\" \"net/url\" \"time\" ) const ( baseURL = \"http://127.0.0.1:8080\" database = \"configdb\" ) // ServiceConfig is the configuration for a single service + environment. type ServiceConfig struct { Service string `json:\"service\"` Environment string `json:\"environment\"` Enabled bool `json:\"enabled\"` RateLimit int `json:\"rate_limit\"` LogLevel string `json:\"log_level\"` Features map [ string ] interface {} `json:\"features\"` UpdatedAt time . Time `json:\"updated_at\"` } type ConfigClient struct { httpClient * http . Client token string } func NewConfigClient ( clientID string ) ( * ConfigClient , error ) { c := & ConfigClient { httpClient : & http . Client {}} body , _ := json . Marshal ( map [ string ] string { \"client_id\" : clientID }) resp , err := c . httpClient . Post ( baseURL + \"/api/login\" , \"application/json\" , bytes . NewReader ( body )) if err != nil { return nil , err } defer resp . Body . Close () var result struct { Token string `json:\"token\"` } json . NewDecoder ( resp . Body ). Decode ( & result ) c . token = result . Token return c , nil } func configKey ( service , environment string ) string { return service + \".\" + environment } func ( c * ConfigClient ) Get ( service , environment string ) ( * ServiceConfig , error ) { key := url . QueryEscape ( configKey ( service , environment )) req , _ := http . NewRequest ( http . MethodGet , fmt . Sprintf ( \"%s/entity/%s?key=%s\" , baseURL , database , key ), nil ) req . Header . Set ( \"Authorization\" , \"Bearer \" + c . token ) resp , err := c . httpClient . Do ( req ) if err != nil { return nil , err } defer resp . Body . Close () if resp . StatusCode == http . StatusNotFound { return nil , nil } var cfg ServiceConfig return & cfg , json . NewDecoder ( resp . Body ). Decode ( & cfg ) } func ( c * ConfigClient ) Set ( cfg ServiceConfig ) error { cfg . UpdatedAt = time . Now (). UTC () entityJSON , _ := json . Marshal ( cfg ) key := configKey ( cfg . Service , cfg . Environment ) payload , _ := json . Marshal ( map [ string ] json . RawMessage { key : entityJSON }) req , _ := http . NewRequest ( http . MethodPut , fmt . Sprintf ( \"%s/entity/%s\" , baseURL , database ), bytes . NewReader ( payload )) req . Header . Set ( \"Authorization\" , \"Bearer \" + c . token ) req . Header . Set ( \"Content-Type\" , \"application/json\" ) resp , err := c . httpClient . Do ( req ) if err != nil { return err } defer resp . Body . Close () if resp . StatusCode != http . StatusOK { return fmt . Errorf ( \"set config failed: status %d\" , resp . StatusCode ) } return nil } func main () { client , err := NewConfigClient ( \"config-manager\" ) if err != nil { log . Fatal ( err ) } // Write configs for different environments configs := [] ServiceConfig { { Service : \"api-gateway\" , Environment : \"development\" , Enabled : true , RateLimit : 1000 , LogLevel : \"debug\" , Features : map [ string ] interface {}{ \"new_ui\" : true , \"beta_api\" : true }, }, { Service : \"api-gateway\" , Environment : \"production\" , Enabled : true , RateLimit : 100 , LogLevel : \"warn\" , Features : map [ string ] interface {}{ \"new_ui\" : false , \"beta_api\" : false }, }, } for _ , cfg := range configs { if err := client . Set ( cfg ); err != nil { log . Fatalf ( \"set config: %v\" , err ) } fmt . Printf ( \"Saved config: %s.%s\\n\" , cfg . Service , cfg . Environment ) } // Read back prodCfg , err := client . Get ( \"api-gateway\" , \"production\" ) if err != nil { log . Fatal ( err ) } fmt . Printf ( \"\\nProduction config:\\n\" ) fmt . Printf ( \" rate_limit: %d\\n\" , prodCfg . RateLimit ) fmt . Printf ( \" log_level: %s\\n\" , prodCfg . LogLevel ) fmt . Printf ( \" features: %v\\n\" , prodCfg . Features ) }","title":"Go Client"},{"location":"usage/examples/config-store/#curl-walkthrough","text":"BASE = \"http://127.0.0.1:8080\" TOKEN = $( curl -sf -X POST \" $BASE /api/login\" \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"ops\"}' | jq -r .token ) # Write production config curl -sf -X PUT \" $BASE /entity/configdb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"payment-service.production\": { \"service\": \"payment-service\", \"environment\": \"production\", \"enabled\": true, \"rate_limit\": 50, \"log_level\": \"warn\", \"features\": { \"stripe_v2\": true, \"paypal\": false, \"apple_pay\": true } } }' # Read it back curl -sf \" $BASE /entity/configdb?key=payment-service.production\" \\ -H \"Authorization: Bearer $TOKEN \" | jq . # Enable PayPal CURRENT = $( curl -sf \" $BASE /entity/configdb?key=payment-service.production\" \\ -H \"Authorization: Bearer $TOKEN \" ) UPDATED = $( echo \" $CURRENT \" | jq '.features.paypal = true' ) curl -sf -X PUT \" $BASE /entity/configdb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d \"{\\\"payment-service.production\\\": $UPDATED }\" echo \"PayPal enabled\"","title":"curl Walkthrough"},{"location":"usage/examples/config-store/#feature-flag-pattern","text":"Store feature flags per service with per-tenant overrides: import requests BASE_URL = \"http://127.0.0.1:8080\" token = requests . post ( f \" { BASE_URL } /api/login\" , json = { \"client_id\" : \"flag-service\" }) . json ()[ \"token\" ] headers = { \"Authorization\" : f \"Bearer { token } \" } def get_flags ( service : str , tenant_id : str | None = None ) -> dict : \"\"\" Get feature flags for a service. Tenant overrides take precedence over service defaults. \"\"\" # Base flags for the service resp = requests . get ( f \" { BASE_URL } /entity/configdb\" , params = { \"key\" : f \" { service } .flags\" }, headers = headers ) base_flags = resp . json () . get ( \"flags\" , {}) if resp . status_code == 200 else {} if tenant_id is None : return base_flags # Per-tenant overrides resp = requests . get ( f \" { BASE_URL } /entity/configdb\" , params = { \"key\" : f \" { service } .flags. { tenant_id } \" }, headers = headers ) tenant_flags = resp . json () . get ( \"flags\" , {}) if resp . status_code == 200 else {} return { ** base_flags , ** tenant_flags } # tenant overrides win # Set global flags requests . put ( f \" { BASE_URL } /entity/configdb\" , headers = headers , json = { \"recommendation-engine.flags\" : { \"flags\" : { \"new_algorithm\" : False , \"personalization\" : True , \"ab_test_v2\" : False } } }) . raise_for_status () # Set per-tenant override (enable new algorithm for tenant \"acme\") requests . put ( f \" { BASE_URL } /entity/configdb\" , headers = headers , json = { \"recommendation-engine.flags.acme\" : { \"flags\" : { \"new_algorithm\" : True , \"ab_test_v2\" : True } } }) . raise_for_status () # Check flags print ( \"Default flags:\" , get_flags ( \"recommendation-engine\" )) print ( \"ACME flags: \" , get_flags ( \"recommendation-engine\" , \"acme\" )) Output: Default flags: {'new_algorithm': False, 'personalization': True, 'ab_test_v2': False} ACME flags: {'new_algorithm': True, 'personalization': True, 'ab_test_v2': True}","title":"Feature Flag Pattern"},{"location":"usage/examples/config-store/#config-polling-pattern","text":"Services can poll for configuration changes: import time import threading def poll_config ( service : str , env : str , interval_s : int = 30 ): \"\"\"Poll DeltaDatabase for config changes every `interval_s` seconds.\"\"\" current_config = {} while True : resp = requests . get ( f \" { BASE_URL } /entity/configdb\" , params = { \"key\" : f \" { service } . { env } \" }, headers = headers , ) if resp . status_code == 200 : new_config = resp . json () if new_config != current_config : print ( f \"Config changed for { service } . { env } : { new_config } \" ) current_config = new_config apply_config ( new_config ) # your application logic here time . sleep ( interval_s ) def apply_config ( config : dict ) -> None : \"\"\"Apply the new configuration to the running service.\"\"\" print ( f \"Applying: rate_limit= { config . get ( 'rate_limit' ) } , \" f \"log_level= { config . get ( 'log_level' ) } \" ) # Start polling in a background thread threading . Thread ( target = poll_config , args = ( \"api-gateway\" , \"production\" ), daemon = True ) . start ()","title":"Config Polling Pattern"},{"location":"usage/examples/ecommerce/","text":"Example: E-Commerce Catalogue \u00b6 Store and manage a product catalogue, inventory, and order records. DeltaDatabase's JSON schema validation ensures product data integrity across your catalogue. Use case: Product catalogue, inventory management, order storage, shopping carts. Databases: - products \u2014 product catalogue (keyed by SKU) - inventory \u2014 stock levels (keyed by SKU) - orders \u2014 order records (keyed by order ID) - carts \u2014 active shopping carts (keyed by session/user ID) Schema Setup \u00b6 TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"admin\"}' | jq -r .token ) # Product schema curl -s -X PUT http://127.0.0.1:8080/schema/product.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"product.v1\", \"type\": \"object\", \"properties\": { \"sku\": {\"type\": \"string\"}, \"name\": {\"type\": \"string\"}, \"description\": {\"type\": \"string\"}, \"price\": {\"type\": \"number\", \"minimum\": 0}, \"currency\": {\"type\": \"string\", \"enum\": [\"USD\", \"EUR\", \"GBP\"]}, \"category\": {\"type\": \"string\"}, \"tags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"images\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"attributes\": {\"type\": \"object\"} }, \"required\": [\"sku\", \"name\", \"price\", \"currency\"] }' # Order schema curl -s -X PUT http://127.0.0.1:8080/schema/order.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"order.v1\", \"type\": \"object\", \"properties\": { \"order_id\": {\"type\": \"string\"}, \"user_id\": {\"type\": \"string\"}, \"status\": {\"type\": \"string\", \"enum\": [\"pending\",\"confirmed\",\"shipped\",\"delivered\",\"cancelled\"]}, \"items\": { \"type\": \"array\", \"items\": { \"type\": \"object\", \"properties\": { \"sku\": {\"type\": \"string\"}, \"name\": {\"type\": \"string\"}, \"quantity\": {\"type\": \"integer\", \"minimum\": 1}, \"price\": {\"type\": \"number\", \"minimum\": 0} }, \"required\": [\"sku\", \"quantity\", \"price\"] } }, \"total\": {\"type\": \"number\", \"minimum\": 0}, \"currency\": {\"type\": \"string\"}, \"created_at\": {\"type\": \"string\", \"format\": \"date-time\"} }, \"required\": [\"order_id\", \"user_id\", \"status\", \"items\", \"total\", \"currency\"] }' Python Client \u00b6 \"\"\" ecommerce.py \u2014 E-Commerce catalogue with DeltaDatabase Install: pip install requests \"\"\" import requests import uuid from datetime import datetime , timezone BASE_URL = \"http://127.0.0.1:8080\" class ECommerceClient : def __init__ ( self , client_id : str = \"shop-service\" ): self . session = requests . Session () resp = self . session . post ( f \" { BASE_URL } /api/login\" , json = { \"client_id\" : client_id } ) resp . raise_for_status () self . session . headers [ \"Authorization\" ] = f \"Bearer { resp . json ()[ 'token' ] } \" # \u2500\u2500 Products \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def add_product ( self , sku : str , name : str , price : float , currency : str = \"USD\" , ** kwargs ) -> dict : \"\"\"Add or update a product in the catalogue.\"\"\" product = { \"sku\" : sku , \"name\" : name , \"price\" : price , \"currency\" : currency , ** kwargs } self . session . put ( f \" { BASE_URL } /entity/products\" , json = { sku : product }) . raise_for_status () print ( f \"Added product: { sku } \u2014 { name } ( { currency } { price : .2f } )\" ) return product def get_product ( self , sku : str ) -> dict | None : resp = self . session . get ( f \" { BASE_URL } /entity/products\" , params = { \"key\" : sku }) if resp . status_code == 404 : return None resp . raise_for_status () return resp . json () def update_price ( self , sku : str , new_price : float ) -> None : product = self . get_product ( sku ) if product is None : raise ValueError ( f \"Product ' { sku } ' not found\" ) product [ \"price\" ] = new_price self . session . put ( f \" { BASE_URL } /entity/products\" , json = { sku : product }) . raise_for_status () print ( f \"Updated price for { sku } : { new_price : .2f } { product [ 'currency' ] } \" ) # \u2500\u2500 Inventory \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def set_stock ( self , sku : str , quantity : int , warehouse : str = \"main\" ) -> None : \"\"\"Set stock level for a SKU.\"\"\" inventory = { \"sku\" : sku , \"warehouse\" : warehouse , \"quantity\" : quantity , \"updated_at\" : datetime . now ( timezone . utc ) . isoformat ()} self . session . put ( f \" { BASE_URL } /entity/inventory\" , json = { f \" { sku } . { warehouse } \" : inventory }) . raise_for_status () print ( f \"Stock set: { sku } @ { warehouse } = { quantity } units\" ) def get_stock ( self , sku : str , warehouse : str = \"main\" ) -> int : resp = self . session . get ( f \" { BASE_URL } /entity/inventory\" , params = { \"key\" : f \" { sku } . { warehouse } \" }) if resp . status_code == 404 : return 0 resp . raise_for_status () return resp . json () . get ( \"quantity\" , 0 ) def reserve_stock ( self , sku : str , quantity : int , warehouse : str = \"main\" ) -> bool : \"\"\"Reserve stock for an order. Returns False if insufficient stock.\"\"\" key = f \" { sku } . { warehouse } \" resp = self . session . get ( f \" { BASE_URL } /entity/inventory\" , params = { \"key\" : key }) if resp . status_code == 404 : return False inventory = resp . json () if inventory [ \"quantity\" ] < quantity : return False inventory [ \"quantity\" ] -= quantity inventory [ \"updated_at\" ] = datetime . now ( timezone . utc ) . isoformat () self . session . put ( f \" { BASE_URL } /entity/inventory\" , json = { key : inventory }) . raise_for_status () return True # \u2500\u2500 Orders \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def create_order ( self , user_id : str , items : list [ dict ]) -> dict : \"\"\" Create a new order. items: [{\"sku\": \"...\", \"quantity\": N, \"price\": X.XX}, ...] \"\"\" order_id = f \"order_ { uuid . uuid4 () . hex [: 12 ] } \" total = sum ( i [ \"price\" ] * i [ \"quantity\" ] for i in items ) order = { \"order_id\" : order_id , \"user_id\" : user_id , \"status\" : \"pending\" , \"items\" : items , \"total\" : round ( total , 2 ), \"currency\" : \"USD\" , \"created_at\" : datetime . now ( timezone . utc ) . isoformat (), } self . session . put ( f \" { BASE_URL } /entity/orders\" , json = { order_id : order }) . raise_for_status () print ( f \"Order created: { order_id } (total: USD { total : .2f } )\" ) return order def update_order_status ( self , order_id : str , status : str ) -> None : resp = self . session . get ( f \" { BASE_URL } /entity/orders\" , params = { \"key\" : order_id }) resp . raise_for_status () order = resp . json () old_status = order [ \"status\" ] order [ \"status\" ] = status self . session . put ( f \" { BASE_URL } /entity/orders\" , json = { order_id : order }) . raise_for_status () print ( f \"Order { order_id } : { old_status } \u2192 { status } \" ) if __name__ == \"__main__\" : client = ECommerceClient () # \u2500\u2500 1. Load the catalogue \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 print ( \"=== Loading Catalogue ===\" ) client . add_product ( \"LAPTOP-PRO-15\" , \"Pro Laptop 15 \\\" \" , 1299.99 , category = \"Electronics\" , tags = [ \"laptop\" , \"professional\" ], attributes = { \"ram_gb\" : 16 , \"storage_gb\" : 512 , \"screen_inches\" : 15.6 }) client . add_product ( \"WIRELESS-MOUSE\" , \"Ergonomic Wireless Mouse\" , 49.99 , category = \"Accessories\" , tags = [ \"mouse\" , \"wireless\" , \"ergonomic\" ]) client . add_product ( \"USB-C-HUB\" , \"7-in-1 USB-C Hub\" , 39.99 , category = \"Accessories\" , tags = [ \"hub\" , \"usb-c\" ]) # \u2500\u2500 2. Set initial stock \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 print ( \" \\n === Setting Stock ===\" ) client . set_stock ( \"LAPTOP-PRO-15\" , 50 ) client . set_stock ( \"WIRELESS-MOUSE\" , 200 ) client . set_stock ( \"USB-C-HUB\" , 150 ) # \u2500\u2500 3. Customer places an order \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 print ( \" \\n === Processing Order ===\" ) order_items = [ { \"sku\" : \"LAPTOP-PRO-15\" , \"name\" : \"Pro Laptop 15 \\\" \" , \"quantity\" : 1 , \"price\" : 1299.99 }, { \"sku\" : \"WIRELESS-MOUSE\" , \"name\" : \"Ergonomic Wireless Mouse\" , \"quantity\" : 2 , \"price\" : 49.99 }, ] # Reserve stock for item in order_items : if client . reserve_stock ( item [ \"sku\" ], item [ \"quantity\" ]): print ( f \" Reserved { item [ 'quantity' ] } x { item [ 'sku' ] } \" ) else : print ( f \" \u274c Insufficient stock for { item [ 'sku' ] } \" ) order = client . create_order ( \"user_001\" , order_items ) # \u2500\u2500 4. Update order status \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 print ( \" \\n === Fulfilling Order ===\" ) client . update_order_status ( order [ \"order_id\" ], \"confirmed\" ) client . update_order_status ( order [ \"order_id\" ], \"shipped\" ) # \u2500\u2500 5. Verify stock was updated \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 print ( \" \\n === Current Stock ===\" ) for sku in [ \"LAPTOP-PRO-15\" , \"WIRELESS-MOUSE\" , \"USB-C-HUB\" ]: stock = client . get_stock ( sku ) print ( f \" { sku } : { stock } units\" ) curl Walkthrough \u00b6 BASE = \"http://127.0.0.1:8080\" TOKEN = $( curl -sf -X POST \" $BASE /api/login\" \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"shop\"}' | jq -r .token ) # Add a product curl -sf -X PUT \" $BASE /entity/products\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"HDMI-CABLE-2M\": { \"sku\": \"HDMI-CABLE-2M\", \"name\": \"HDMI 2.1 Cable 2m\", \"price\": 14.99, \"currency\": \"USD\", \"category\": \"Cables\", \"tags\": [\"hdmi\", \"cable\", \"4k\"] } }' # Look up the product curl -sf \" $BASE /entity/products?key=HDMI-CABLE-2M\" \\ -H \"Authorization: Bearer $TOKEN \" | jq . # Apply a 10% discount PRODUCT = $( curl -sf \" $BASE /entity/products?key=HDMI-CABLE-2M\" \\ -H \"Authorization: Bearer $TOKEN \" ) DISCOUNTED = $( echo \" $PRODUCT \" | jq '.price = (.price * 0.9 | round * 100 / 100)' ) curl -sf -X PUT \" $BASE /entity/products\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d \"{\\\"HDMI-CABLE-2M\\\": $DISCOUNTED }\" echo \"Discount applied: $( echo $DISCOUNTED | jq .price ) \" Shopping Cart Pattern \u00b6 class CartClient : \"\"\"Manage shopping carts per user session.\"\"\" def __init__ ( self , session_token : str ): self . session = requests . Session () self . session . headers [ \"Authorization\" ] = f \"Bearer { session_token } \" def get_cart ( self , user_id : str ) -> dict : resp = self . session . get ( f \" { BASE_URL } /entity/carts\" , params = { \"key\" : user_id }) if resp . status_code == 404 : return { \"user_id\" : user_id , \"items\" : [], \"updated_at\" : None } resp . raise_for_status () return resp . json () def add_to_cart ( self , user_id : str , sku : str , quantity : int , price : float ) -> None : cart = self . get_cart ( user_id ) # Update quantity if SKU already in cart for item in cart [ \"items\" ]: if item [ \"sku\" ] == sku : item [ \"quantity\" ] += quantity break else : cart [ \"items\" ] . append ({ \"sku\" : sku , \"quantity\" : quantity , \"price\" : price }) cart [ \"updated_at\" ] = datetime . now ( timezone . utc ) . isoformat () self . session . put ( f \" { BASE_URL } /entity/carts\" , json = { user_id : cart }) . raise_for_status () def clear_cart ( self , user_id : str ) -> None : cart = self . get_cart ( user_id ) cart [ \"items\" ] = [] self . session . put ( f \" { BASE_URL } /entity/carts\" , json = { user_id : cart }) . raise_for_status () def get_total ( self , user_id : str ) -> float : cart = self . get_cart ( user_id ) return sum ( i [ \"price\" ] * i [ \"quantity\" ] for i in cart [ \"items\" ])","title":"E-Commerce Catalogue"},{"location":"usage/examples/ecommerce/#example-e-commerce-catalogue","text":"Store and manage a product catalogue, inventory, and order records. DeltaDatabase's JSON schema validation ensures product data integrity across your catalogue. Use case: Product catalogue, inventory management, order storage, shopping carts. Databases: - products \u2014 product catalogue (keyed by SKU) - inventory \u2014 stock levels (keyed by SKU) - orders \u2014 order records (keyed by order ID) - carts \u2014 active shopping carts (keyed by session/user ID)","title":"Example: E-Commerce Catalogue"},{"location":"usage/examples/ecommerce/#schema-setup","text":"TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"admin\"}' | jq -r .token ) # Product schema curl -s -X PUT http://127.0.0.1:8080/schema/product.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"product.v1\", \"type\": \"object\", \"properties\": { \"sku\": {\"type\": \"string\"}, \"name\": {\"type\": \"string\"}, \"description\": {\"type\": \"string\"}, \"price\": {\"type\": \"number\", \"minimum\": 0}, \"currency\": {\"type\": \"string\", \"enum\": [\"USD\", \"EUR\", \"GBP\"]}, \"category\": {\"type\": \"string\"}, \"tags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"images\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"attributes\": {\"type\": \"object\"} }, \"required\": [\"sku\", \"name\", \"price\", \"currency\"] }' # Order schema curl -s -X PUT http://127.0.0.1:8080/schema/order.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"order.v1\", \"type\": \"object\", \"properties\": { \"order_id\": {\"type\": \"string\"}, \"user_id\": {\"type\": \"string\"}, \"status\": {\"type\": \"string\", \"enum\": [\"pending\",\"confirmed\",\"shipped\",\"delivered\",\"cancelled\"]}, \"items\": { \"type\": \"array\", \"items\": { \"type\": \"object\", \"properties\": { \"sku\": {\"type\": \"string\"}, \"name\": {\"type\": \"string\"}, \"quantity\": {\"type\": \"integer\", \"minimum\": 1}, \"price\": {\"type\": \"number\", \"minimum\": 0} }, \"required\": [\"sku\", \"quantity\", \"price\"] } }, \"total\": {\"type\": \"number\", \"minimum\": 0}, \"currency\": {\"type\": \"string\"}, \"created_at\": {\"type\": \"string\", \"format\": \"date-time\"} }, \"required\": [\"order_id\", \"user_id\", \"status\", \"items\", \"total\", \"currency\"] }'","title":"Schema Setup"},{"location":"usage/examples/ecommerce/#python-client","text":"\"\"\" ecommerce.py \u2014 E-Commerce catalogue with DeltaDatabase Install: pip install requests \"\"\" import requests import uuid from datetime import datetime , timezone BASE_URL = \"http://127.0.0.1:8080\" class ECommerceClient : def __init__ ( self , client_id : str = \"shop-service\" ): self . session = requests . Session () resp = self . session . post ( f \" { BASE_URL } /api/login\" , json = { \"client_id\" : client_id } ) resp . raise_for_status () self . session . headers [ \"Authorization\" ] = f \"Bearer { resp . json ()[ 'token' ] } \" # \u2500\u2500 Products \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def add_product ( self , sku : str , name : str , price : float , currency : str = \"USD\" , ** kwargs ) -> dict : \"\"\"Add or update a product in the catalogue.\"\"\" product = { \"sku\" : sku , \"name\" : name , \"price\" : price , \"currency\" : currency , ** kwargs } self . session . put ( f \" { BASE_URL } /entity/products\" , json = { sku : product }) . raise_for_status () print ( f \"Added product: { sku } \u2014 { name } ( { currency } { price : .2f } )\" ) return product def get_product ( self , sku : str ) -> dict | None : resp = self . session . get ( f \" { BASE_URL } /entity/products\" , params = { \"key\" : sku }) if resp . status_code == 404 : return None resp . raise_for_status () return resp . json () def update_price ( self , sku : str , new_price : float ) -> None : product = self . get_product ( sku ) if product is None : raise ValueError ( f \"Product ' { sku } ' not found\" ) product [ \"price\" ] = new_price self . session . put ( f \" { BASE_URL } /entity/products\" , json = { sku : product }) . raise_for_status () print ( f \"Updated price for { sku } : { new_price : .2f } { product [ 'currency' ] } \" ) # \u2500\u2500 Inventory \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def set_stock ( self , sku : str , quantity : int , warehouse : str = \"main\" ) -> None : \"\"\"Set stock level for a SKU.\"\"\" inventory = { \"sku\" : sku , \"warehouse\" : warehouse , \"quantity\" : quantity , \"updated_at\" : datetime . now ( timezone . utc ) . isoformat ()} self . session . put ( f \" { BASE_URL } /entity/inventory\" , json = { f \" { sku } . { warehouse } \" : inventory }) . raise_for_status () print ( f \"Stock set: { sku } @ { warehouse } = { quantity } units\" ) def get_stock ( self , sku : str , warehouse : str = \"main\" ) -> int : resp = self . session . get ( f \" { BASE_URL } /entity/inventory\" , params = { \"key\" : f \" { sku } . { warehouse } \" }) if resp . status_code == 404 : return 0 resp . raise_for_status () return resp . json () . get ( \"quantity\" , 0 ) def reserve_stock ( self , sku : str , quantity : int , warehouse : str = \"main\" ) -> bool : \"\"\"Reserve stock for an order. Returns False if insufficient stock.\"\"\" key = f \" { sku } . { warehouse } \" resp = self . session . get ( f \" { BASE_URL } /entity/inventory\" , params = { \"key\" : key }) if resp . status_code == 404 : return False inventory = resp . json () if inventory [ \"quantity\" ] < quantity : return False inventory [ \"quantity\" ] -= quantity inventory [ \"updated_at\" ] = datetime . now ( timezone . utc ) . isoformat () self . session . put ( f \" { BASE_URL } /entity/inventory\" , json = { key : inventory }) . raise_for_status () return True # \u2500\u2500 Orders \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def create_order ( self , user_id : str , items : list [ dict ]) -> dict : \"\"\" Create a new order. items: [{\"sku\": \"...\", \"quantity\": N, \"price\": X.XX}, ...] \"\"\" order_id = f \"order_ { uuid . uuid4 () . hex [: 12 ] } \" total = sum ( i [ \"price\" ] * i [ \"quantity\" ] for i in items ) order = { \"order_id\" : order_id , \"user_id\" : user_id , \"status\" : \"pending\" , \"items\" : items , \"total\" : round ( total , 2 ), \"currency\" : \"USD\" , \"created_at\" : datetime . now ( timezone . utc ) . isoformat (), } self . session . put ( f \" { BASE_URL } /entity/orders\" , json = { order_id : order }) . raise_for_status () print ( f \"Order created: { order_id } (total: USD { total : .2f } )\" ) return order def update_order_status ( self , order_id : str , status : str ) -> None : resp = self . session . get ( f \" { BASE_URL } /entity/orders\" , params = { \"key\" : order_id }) resp . raise_for_status () order = resp . json () old_status = order [ \"status\" ] order [ \"status\" ] = status self . session . put ( f \" { BASE_URL } /entity/orders\" , json = { order_id : order }) . raise_for_status () print ( f \"Order { order_id } : { old_status } \u2192 { status } \" ) if __name__ == \"__main__\" : client = ECommerceClient () # \u2500\u2500 1. Load the catalogue \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 print ( \"=== Loading Catalogue ===\" ) client . add_product ( \"LAPTOP-PRO-15\" , \"Pro Laptop 15 \\\" \" , 1299.99 , category = \"Electronics\" , tags = [ \"laptop\" , \"professional\" ], attributes = { \"ram_gb\" : 16 , \"storage_gb\" : 512 , \"screen_inches\" : 15.6 }) client . add_product ( \"WIRELESS-MOUSE\" , \"Ergonomic Wireless Mouse\" , 49.99 , category = \"Accessories\" , tags = [ \"mouse\" , \"wireless\" , \"ergonomic\" ]) client . add_product ( \"USB-C-HUB\" , \"7-in-1 USB-C Hub\" , 39.99 , category = \"Accessories\" , tags = [ \"hub\" , \"usb-c\" ]) # \u2500\u2500 2. Set initial stock \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 print ( \" \\n === Setting Stock ===\" ) client . set_stock ( \"LAPTOP-PRO-15\" , 50 ) client . set_stock ( \"WIRELESS-MOUSE\" , 200 ) client . set_stock ( \"USB-C-HUB\" , 150 ) # \u2500\u2500 3. Customer places an order \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 print ( \" \\n === Processing Order ===\" ) order_items = [ { \"sku\" : \"LAPTOP-PRO-15\" , \"name\" : \"Pro Laptop 15 \\\" \" , \"quantity\" : 1 , \"price\" : 1299.99 }, { \"sku\" : \"WIRELESS-MOUSE\" , \"name\" : \"Ergonomic Wireless Mouse\" , \"quantity\" : 2 , \"price\" : 49.99 }, ] # Reserve stock for item in order_items : if client . reserve_stock ( item [ \"sku\" ], item [ \"quantity\" ]): print ( f \" Reserved { item [ 'quantity' ] } x { item [ 'sku' ] } \" ) else : print ( f \" \u274c Insufficient stock for { item [ 'sku' ] } \" ) order = client . create_order ( \"user_001\" , order_items ) # \u2500\u2500 4. Update order status \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 print ( \" \\n === Fulfilling Order ===\" ) client . update_order_status ( order [ \"order_id\" ], \"confirmed\" ) client . update_order_status ( order [ \"order_id\" ], \"shipped\" ) # \u2500\u2500 5. Verify stock was updated \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 print ( \" \\n === Current Stock ===\" ) for sku in [ \"LAPTOP-PRO-15\" , \"WIRELESS-MOUSE\" , \"USB-C-HUB\" ]: stock = client . get_stock ( sku ) print ( f \" { sku } : { stock } units\" )","title":"Python Client"},{"location":"usage/examples/ecommerce/#curl-walkthrough","text":"BASE = \"http://127.0.0.1:8080\" TOKEN = $( curl -sf -X POST \" $BASE /api/login\" \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"shop\"}' | jq -r .token ) # Add a product curl -sf -X PUT \" $BASE /entity/products\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"HDMI-CABLE-2M\": { \"sku\": \"HDMI-CABLE-2M\", \"name\": \"HDMI 2.1 Cable 2m\", \"price\": 14.99, \"currency\": \"USD\", \"category\": \"Cables\", \"tags\": [\"hdmi\", \"cable\", \"4k\"] } }' # Look up the product curl -sf \" $BASE /entity/products?key=HDMI-CABLE-2M\" \\ -H \"Authorization: Bearer $TOKEN \" | jq . # Apply a 10% discount PRODUCT = $( curl -sf \" $BASE /entity/products?key=HDMI-CABLE-2M\" \\ -H \"Authorization: Bearer $TOKEN \" ) DISCOUNTED = $( echo \" $PRODUCT \" | jq '.price = (.price * 0.9 | round * 100 / 100)' ) curl -sf -X PUT \" $BASE /entity/products\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d \"{\\\"HDMI-CABLE-2M\\\": $DISCOUNTED }\" echo \"Discount applied: $( echo $DISCOUNTED | jq .price ) \"","title":"curl Walkthrough"},{"location":"usage/examples/ecommerce/#shopping-cart-pattern","text":"class CartClient : \"\"\"Manage shopping carts per user session.\"\"\" def __init__ ( self , session_token : str ): self . session = requests . Session () self . session . headers [ \"Authorization\" ] = f \"Bearer { session_token } \" def get_cart ( self , user_id : str ) -> dict : resp = self . session . get ( f \" { BASE_URL } /entity/carts\" , params = { \"key\" : user_id }) if resp . status_code == 404 : return { \"user_id\" : user_id , \"items\" : [], \"updated_at\" : None } resp . raise_for_status () return resp . json () def add_to_cart ( self , user_id : str , sku : str , quantity : int , price : float ) -> None : cart = self . get_cart ( user_id ) # Update quantity if SKU already in cart for item in cart [ \"items\" ]: if item [ \"sku\" ] == sku : item [ \"quantity\" ] += quantity break else : cart [ \"items\" ] . append ({ \"sku\" : sku , \"quantity\" : quantity , \"price\" : price }) cart [ \"updated_at\" ] = datetime . now ( timezone . utc ) . isoformat () self . session . put ( f \" { BASE_URL } /entity/carts\" , json = { user_id : cart }) . raise_for_status () def clear_cart ( self , user_id : str ) -> None : cart = self . get_cart ( user_id ) cart [ \"items\" ] = [] self . session . put ( f \" { BASE_URL } /entity/carts\" , json = { user_id : cart }) . raise_for_status () def get_total ( self , user_id : str ) -> float : cart = self . get_cart ( user_id ) return sum ( i [ \"price\" ] * i [ \"quantity\" ] for i in cart [ \"items\" ])","title":"Shopping Cart Pattern"},{"location":"usage/examples/iot-sensors/","text":"Example: IoT Sensor Data \u00b6 Store and retrieve sensor readings from IoT devices. Each device has its own entity containing its latest readings and a rolling history. Use case: Smart home, industrial monitoring, environmental sensors, fleet telemetry. Database: iotdb Entity key: device ID (e.g., sensor_living_room , device_A3F2 ) Entity value: {\"device_id\": \"...\", \"latest\": {...}, \"history\": [...]} Schema Setup \u00b6 TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"iot-service\"}' | jq -r .token ) curl -s -X PUT http://127.0.0.1:8080/schema/iot_device.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"iot_device.v1\", \"type\": \"object\", \"properties\": { \"device_id\": {\"type\": \"string\"}, \"name\": {\"type\": \"string\"}, \"location\": {\"type\": \"string\"}, \"latest\": { \"type\": \"object\", \"properties\": { \"timestamp\": {\"type\": \"string\", \"format\": \"date-time\"}, \"temperature\": {\"type\": \"number\"}, \"humidity\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 100}, \"pressure\": {\"type\": \"number\"}, \"battery_pct\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 100} } }, \"history\": { \"type\": \"array\", \"maxItems\": 100, \"items\": { \"type\": \"object\", \"properties\": { \"timestamp\": {\"type\": \"string\"}, \"temperature\": {\"type\": \"number\"}, \"humidity\": {\"type\": \"number\"} } } } }, \"required\": [\"device_id\"] }' Python Client \u00b6 \"\"\" iot_client.py \u2014 IoT sensor data storage with DeltaDatabase Install: pip install requests \"\"\" import requests from datetime import datetime , timezone from typing import Optional BASE_URL = \"http://127.0.0.1:8080\" DATABASE = \"iotdb\" MAX_HISTORY = 100 # keep last 100 readings per device class IoTClient : def __init__ ( self , client_id : str = \"iot-service\" ): self . session = requests . Session () resp = self . session . post ( f \" { BASE_URL } /api/login\" , json = { \"client_id\" : client_id } ) resp . raise_for_status () self . session . headers [ \"Authorization\" ] = f \"Bearer { resp . json ()[ 'token' ] } \" def register_device ( self , device_id : str , name : str , location : str ) -> None : \"\"\"Register a new IoT device.\"\"\" device = { \"device_id\" : device_id , \"name\" : name , \"location\" : location , \"latest\" : {}, \"history\" : [], } self . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = { device_id : device } ) . raise_for_status () print ( f \"Registered device ' { device_id } ' at ' { location } '\" ) def push_reading ( self , device_id : str , temperature : float , humidity : float , pressure : Optional [ float ] = None , battery_pct : Optional [ float ] = None , ) -> None : \"\"\"Push a new sensor reading for a device.\"\"\" # Fetch current device state resp = self . session . get ( f \" { BASE_URL } /entity/ { DATABASE } \" , params = { \"key\" : device_id } ) if resp . status_code == 404 : device = { \"device_id\" : device_id , \"latest\" : {}, \"history\" : []} else : resp . raise_for_status () device = resp . json () now = datetime . now ( timezone . utc ) . isoformat () # Update latest reading reading = { \"timestamp\" : now , \"temperature\" : temperature , \"humidity\" : humidity , } if pressure is not None : reading [ \"pressure\" ] = pressure if battery_pct is not None : reading [ \"battery_pct\" ] = battery_pct device [ \"latest\" ] = reading # Append to rolling history (keep last MAX_HISTORY entries) device . setdefault ( \"history\" , []) . append ( reading ) if len ( device [ \"history\" ]) > MAX_HISTORY : device [ \"history\" ] = device [ \"history\" ][ - MAX_HISTORY :] # Persist self . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = { device_id : device } ) . raise_for_status () print ( f \"[ { device_id } ] { now [: 19 ] } temp= { temperature } \u00b0C hum= { humidity } %\" ) def get_latest ( self , device_id : str ) -> Optional [ dict ]: \"\"\"Get the most recent reading for a device.\"\"\" resp = self . session . get ( f \" { BASE_URL } /entity/ { DATABASE } \" , params = { \"key\" : device_id } ) if resp . status_code == 404 : return None resp . raise_for_status () return resp . json () . get ( \"latest\" ) def get_history ( self , device_id : str , last_n : int = 10 ) -> list [ dict ]: \"\"\"Get the last N readings for a device.\"\"\" resp = self . session . get ( f \" { BASE_URL } /entity/ { DATABASE } \" , params = { \"key\" : device_id } ) if resp . status_code == 404 : return [] resp . raise_for_status () return resp . json () . get ( \"history\" , [])[ - last_n :] if __name__ == \"__main__\" : client = IoTClient () # Register sensors client . register_device ( \"living_room\" , \"Living Room Sensor\" , \"Living Room\" ) client . register_device ( \"outdoor\" , \"Outdoor Station\" , \"Garden\" ) client . register_device ( \"server_rack\" , \"Server Room Monitor\" , \"Basement\" ) # Simulate readings coming in import random , time readings = [ ( \"living_room\" , 21.5 , 45.0 ), ( \"outdoor\" , 15.2 , 78.0 ), ( \"server_rack\" , 28.0 , 30.0 ), ( \"living_room\" , 21.8 , 44.5 ), ( \"outdoor\" , 14.9 , 80.0 ), ( \"living_room\" , 22.1 , 43.0 ), ] print ( \" \\n --- Pushing readings ---\" ) for device_id , temp , hum in readings : client . push_reading ( device_id , temp , hum , battery_pct = random . uniform ( 60 , 100 )) time . sleep ( 0.1 ) # Check latest readings print ( \" \\n --- Current readings ---\" ) for device_id in [ \"living_room\" , \"outdoor\" , \"server_rack\" ]: latest = client . get_latest ( device_id ) if latest : print ( f \" { device_id } : { latest [ 'temperature' ] } \u00b0C, { latest [ 'humidity' ] } % humidity\" ) # Temperature history for living room print ( \" \\n --- Living room history ---\" ) for reading in client . get_history ( \"living_room\" ): print ( f \" { reading [ 'timestamp' ][: 19 ] } { reading [ 'temperature' ] } \u00b0C\" ) curl: Push a Reading \u00b6 BASE = \"http://127.0.0.1:8080\" TOKEN = $( curl -sf -X POST \" $BASE /api/login\" \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"iot\"}' | jq -r .token ) DEVICE = \"outdoor_sensor_01\" NOW = $( date -u + \"%Y-%m-%dT%H:%M:%SZ\" ) # Fetch existing state (or start fresh) CURRENT = $( curl -sf \" $BASE /entity/iotdb?key= $DEVICE \" \\ -H \"Authorization: Bearer $TOKEN \" 2 >/dev/null \\ || echo '{\"device_id\":\"' $DEVICE '\",\"latest\":{},\"history\":[]}' ) # Append new reading UPDATED = $( echo \" $CURRENT \" | jq \\ --arg ts \" $NOW \" \\ --argjson temp 16 .3 \\ --argjson hum 72 .5 \\ '.latest = {\"timestamp\":$ts,\"temperature\":$temp,\"humidity\":$hum} | .history += [{\"timestamp\":$ts,\"temperature\":$temp,\"humidity\":$hum}] | .history = .history[-100:]' ) # keep last 100 curl -sf -X PUT \" $BASE /entity/iotdb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d \"{\\\" $DEVICE \\\": $UPDATED }\" && echo \"OK\" # Read latest echo \"--- Latest reading ---\" curl -sf \" $BASE /entity/iotdb?key= $DEVICE \" \\ -H \"Authorization: Bearer $TOKEN \" | jq .latest Alert Pattern \u00b6 Add threshold alerting on the client side: def check_alerts ( client : IoTClient , device_id : str ) -> list [ str ]: \"\"\"Return a list of active alerts for a device.\"\"\" latest = client . get_latest ( device_id ) if not latest : return [] alerts = [] if latest . get ( \"temperature\" , 0 ) > 35 : alerts . append ( f \"HIGH TEMP: { latest [ 'temperature' ] } \u00b0C\" ) if latest . get ( \"humidity\" , 0 ) > 85 : alerts . append ( f \"HIGH HUMIDITY: { latest [ 'humidity' ] } %\" ) if latest . get ( \"battery_pct\" , 100 ) < 15 : alerts . append ( f \"LOW BATTERY: { latest [ 'battery_pct' ] } %\" ) return alerts alerts = check_alerts ( client , \"server_rack\" ) if alerts : print ( f \"\u26a0\ufe0f Alerts for server_rack: { alerts } \" ) High-Frequency Ingestion Tips \u00b6 For high-frequency sensor data (> 1 reading/second per device): Batch readings \u2014 collect N readings in memory and write them together in one PUT. Separate databases per device type \u2014 temp_sensors , motion_sensors , etc. Increase -cache-size \u2014 if you have many active devices, ensure the working set fits in cache. Use S3 storage \u2014 for multi-region or multi-node deployments, S3 removes the need for a shared PVC.","title":"IoT Sensor Data"},{"location":"usage/examples/iot-sensors/#example-iot-sensor-data","text":"Store and retrieve sensor readings from IoT devices. Each device has its own entity containing its latest readings and a rolling history. Use case: Smart home, industrial monitoring, environmental sensors, fleet telemetry. Database: iotdb Entity key: device ID (e.g., sensor_living_room , device_A3F2 ) Entity value: {\"device_id\": \"...\", \"latest\": {...}, \"history\": [...]}","title":"Example: IoT Sensor Data"},{"location":"usage/examples/iot-sensors/#schema-setup","text":"TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"iot-service\"}' | jq -r .token ) curl -s -X PUT http://127.0.0.1:8080/schema/iot_device.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"iot_device.v1\", \"type\": \"object\", \"properties\": { \"device_id\": {\"type\": \"string\"}, \"name\": {\"type\": \"string\"}, \"location\": {\"type\": \"string\"}, \"latest\": { \"type\": \"object\", \"properties\": { \"timestamp\": {\"type\": \"string\", \"format\": \"date-time\"}, \"temperature\": {\"type\": \"number\"}, \"humidity\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 100}, \"pressure\": {\"type\": \"number\"}, \"battery_pct\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 100} } }, \"history\": { \"type\": \"array\", \"maxItems\": 100, \"items\": { \"type\": \"object\", \"properties\": { \"timestamp\": {\"type\": \"string\"}, \"temperature\": {\"type\": \"number\"}, \"humidity\": {\"type\": \"number\"} } } } }, \"required\": [\"device_id\"] }'","title":"Schema Setup"},{"location":"usage/examples/iot-sensors/#python-client","text":"\"\"\" iot_client.py \u2014 IoT sensor data storage with DeltaDatabase Install: pip install requests \"\"\" import requests from datetime import datetime , timezone from typing import Optional BASE_URL = \"http://127.0.0.1:8080\" DATABASE = \"iotdb\" MAX_HISTORY = 100 # keep last 100 readings per device class IoTClient : def __init__ ( self , client_id : str = \"iot-service\" ): self . session = requests . Session () resp = self . session . post ( f \" { BASE_URL } /api/login\" , json = { \"client_id\" : client_id } ) resp . raise_for_status () self . session . headers [ \"Authorization\" ] = f \"Bearer { resp . json ()[ 'token' ] } \" def register_device ( self , device_id : str , name : str , location : str ) -> None : \"\"\"Register a new IoT device.\"\"\" device = { \"device_id\" : device_id , \"name\" : name , \"location\" : location , \"latest\" : {}, \"history\" : [], } self . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = { device_id : device } ) . raise_for_status () print ( f \"Registered device ' { device_id } ' at ' { location } '\" ) def push_reading ( self , device_id : str , temperature : float , humidity : float , pressure : Optional [ float ] = None , battery_pct : Optional [ float ] = None , ) -> None : \"\"\"Push a new sensor reading for a device.\"\"\" # Fetch current device state resp = self . session . get ( f \" { BASE_URL } /entity/ { DATABASE } \" , params = { \"key\" : device_id } ) if resp . status_code == 404 : device = { \"device_id\" : device_id , \"latest\" : {}, \"history\" : []} else : resp . raise_for_status () device = resp . json () now = datetime . now ( timezone . utc ) . isoformat () # Update latest reading reading = { \"timestamp\" : now , \"temperature\" : temperature , \"humidity\" : humidity , } if pressure is not None : reading [ \"pressure\" ] = pressure if battery_pct is not None : reading [ \"battery_pct\" ] = battery_pct device [ \"latest\" ] = reading # Append to rolling history (keep last MAX_HISTORY entries) device . setdefault ( \"history\" , []) . append ( reading ) if len ( device [ \"history\" ]) > MAX_HISTORY : device [ \"history\" ] = device [ \"history\" ][ - MAX_HISTORY :] # Persist self . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = { device_id : device } ) . raise_for_status () print ( f \"[ { device_id } ] { now [: 19 ] } temp= { temperature } \u00b0C hum= { humidity } %\" ) def get_latest ( self , device_id : str ) -> Optional [ dict ]: \"\"\"Get the most recent reading for a device.\"\"\" resp = self . session . get ( f \" { BASE_URL } /entity/ { DATABASE } \" , params = { \"key\" : device_id } ) if resp . status_code == 404 : return None resp . raise_for_status () return resp . json () . get ( \"latest\" ) def get_history ( self , device_id : str , last_n : int = 10 ) -> list [ dict ]: \"\"\"Get the last N readings for a device.\"\"\" resp = self . session . get ( f \" { BASE_URL } /entity/ { DATABASE } \" , params = { \"key\" : device_id } ) if resp . status_code == 404 : return [] resp . raise_for_status () return resp . json () . get ( \"history\" , [])[ - last_n :] if __name__ == \"__main__\" : client = IoTClient () # Register sensors client . register_device ( \"living_room\" , \"Living Room Sensor\" , \"Living Room\" ) client . register_device ( \"outdoor\" , \"Outdoor Station\" , \"Garden\" ) client . register_device ( \"server_rack\" , \"Server Room Monitor\" , \"Basement\" ) # Simulate readings coming in import random , time readings = [ ( \"living_room\" , 21.5 , 45.0 ), ( \"outdoor\" , 15.2 , 78.0 ), ( \"server_rack\" , 28.0 , 30.0 ), ( \"living_room\" , 21.8 , 44.5 ), ( \"outdoor\" , 14.9 , 80.0 ), ( \"living_room\" , 22.1 , 43.0 ), ] print ( \" \\n --- Pushing readings ---\" ) for device_id , temp , hum in readings : client . push_reading ( device_id , temp , hum , battery_pct = random . uniform ( 60 , 100 )) time . sleep ( 0.1 ) # Check latest readings print ( \" \\n --- Current readings ---\" ) for device_id in [ \"living_room\" , \"outdoor\" , \"server_rack\" ]: latest = client . get_latest ( device_id ) if latest : print ( f \" { device_id } : { latest [ 'temperature' ] } \u00b0C, { latest [ 'humidity' ] } % humidity\" ) # Temperature history for living room print ( \" \\n --- Living room history ---\" ) for reading in client . get_history ( \"living_room\" ): print ( f \" { reading [ 'timestamp' ][: 19 ] } { reading [ 'temperature' ] } \u00b0C\" )","title":"Python Client"},{"location":"usage/examples/iot-sensors/#curl-push-a-reading","text":"BASE = \"http://127.0.0.1:8080\" TOKEN = $( curl -sf -X POST \" $BASE /api/login\" \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"iot\"}' | jq -r .token ) DEVICE = \"outdoor_sensor_01\" NOW = $( date -u + \"%Y-%m-%dT%H:%M:%SZ\" ) # Fetch existing state (or start fresh) CURRENT = $( curl -sf \" $BASE /entity/iotdb?key= $DEVICE \" \\ -H \"Authorization: Bearer $TOKEN \" 2 >/dev/null \\ || echo '{\"device_id\":\"' $DEVICE '\",\"latest\":{},\"history\":[]}' ) # Append new reading UPDATED = $( echo \" $CURRENT \" | jq \\ --arg ts \" $NOW \" \\ --argjson temp 16 .3 \\ --argjson hum 72 .5 \\ '.latest = {\"timestamp\":$ts,\"temperature\":$temp,\"humidity\":$hum} | .history += [{\"timestamp\":$ts,\"temperature\":$temp,\"humidity\":$hum}] | .history = .history[-100:]' ) # keep last 100 curl -sf -X PUT \" $BASE /entity/iotdb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d \"{\\\" $DEVICE \\\": $UPDATED }\" && echo \"OK\" # Read latest echo \"--- Latest reading ---\" curl -sf \" $BASE /entity/iotdb?key= $DEVICE \" \\ -H \"Authorization: Bearer $TOKEN \" | jq .latest","title":"curl: Push a Reading"},{"location":"usage/examples/iot-sensors/#alert-pattern","text":"Add threshold alerting on the client side: def check_alerts ( client : IoTClient , device_id : str ) -> list [ str ]: \"\"\"Return a list of active alerts for a device.\"\"\" latest = client . get_latest ( device_id ) if not latest : return [] alerts = [] if latest . get ( \"temperature\" , 0 ) > 35 : alerts . append ( f \"HIGH TEMP: { latest [ 'temperature' ] } \u00b0C\" ) if latest . get ( \"humidity\" , 0 ) > 85 : alerts . append ( f \"HIGH HUMIDITY: { latest [ 'humidity' ] } %\" ) if latest . get ( \"battery_pct\" , 100 ) < 15 : alerts . append ( f \"LOW BATTERY: { latest [ 'battery_pct' ] } %\" ) return alerts alerts = check_alerts ( client , \"server_rack\" ) if alerts : print ( f \"\u26a0\ufe0f Alerts for server_rack: { alerts } \" )","title":"Alert Pattern"},{"location":"usage/examples/iot-sensors/#high-frequency-ingestion-tips","text":"For high-frequency sensor data (> 1 reading/second per device): Batch readings \u2014 collect N readings in memory and write them together in one PUT. Separate databases per device type \u2014 temp_sensors , motion_sensors , etc. Increase -cache-size \u2014 if you have many active devices, ensure the working set fits in cache. Use S3 storage \u2014 for multi-region or multi-node deployments, S3 removes the need for a shared PVC.","title":"High-Frequency Ingestion Tips"},{"location":"usage/examples/user-profiles/","text":"Example: User Profiles \u00b6 Store and manage user accounts, profile data, and per-user settings. Each user is stored as a separate entity with a unique user ID as the key. Use case: User registration system, profile service, preferences store. Database: userdb Entity key: user ID (e.g., user_42 , alice@example.com ) Entity value: {\"id\": \"...\", \"name\": \"...\", \"email\": \"...\", \"settings\": {...}} Schema Setup \u00b6 TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"admin\"}' | jq -r .token ) curl -s -X PUT http://127.0.0.1:8080/schema/user.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"user.v1\", \"type\": \"object\", \"properties\": { \"id\": {\"type\": \"string\"}, \"name\": {\"type\": \"string\"}, \"email\": {\"type\": \"string\", \"format\": \"email\"}, \"created_at\": {\"type\": \"string\", \"format\": \"date-time\"}, \"settings\": { \"type\": \"object\", \"properties\": { \"theme\": {\"type\": \"string\", \"enum\": [\"light\", \"dark\"]}, \"notifications\": {\"type\": \"boolean\"}, \"language\": {\"type\": \"string\"} } } }, \"required\": [\"id\", \"email\"] }' Python Client \u00b6 \"\"\" user_profiles.py \u2014 User profile CRUD using DeltaDatabase Install: pip install requests \"\"\" import requests from datetime import datetime , timezone BASE_URL = \"http://127.0.0.1:8080\" DATABASE = \"userdb\" class UserProfileClient : def __init__ ( self , client_id : str = \"user-service\" ): self . session = requests . Session () resp = self . session . post ( f \" { BASE_URL } /api/login\" , json = { \"client_id\" : client_id } ) resp . raise_for_status () self . session . headers [ \"Authorization\" ] = f \"Bearer { resp . json ()[ 'token' ] } \" def create_user ( self , user_id : str , name : str , email : str , ** settings ) -> dict : \"\"\"Create a new user profile.\"\"\" profile = { \"id\" : user_id , \"name\" : name , \"email\" : email , \"created_at\" : datetime . now ( timezone . utc ) . isoformat (), \"settings\" : settings or { \"theme\" : \"light\" , \"notifications\" : True }, } resp = self . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = { user_id : profile }, ) resp . raise_for_status () print ( f \"Created user ' { user_id } ' ( { email } )\" ) return profile def get_user ( self , user_id : str ) -> dict | None : \"\"\"Retrieve a user profile. Returns None if not found.\"\"\" resp = self . session . get ( f \" { BASE_URL } /entity/ { DATABASE } \" , params = { \"key\" : user_id } ) if resp . status_code == 404 : return None resp . raise_for_status () return resp . json () def update_settings ( self , user_id : str , ** new_settings ) -> dict : \"\"\"Update specific settings for a user.\"\"\" profile = self . get_user ( user_id ) if profile is None : raise ValueError ( f \"User ' { user_id } ' not found\" ) profile . setdefault ( \"settings\" , {}) . update ( new_settings ) self . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = { user_id : profile } ) . raise_for_status () print ( f \"Updated settings for ' { user_id } ': { new_settings } \" ) return profile def delete_user ( self , user_id : str ) -> None : \"\"\" DeltaDatabase does not have a native DELETE endpoint. Store a tombstone marker to indicate the user was deleted. \"\"\" tombstone = { \"id\" : user_id , \"deleted\" : True , \"deleted_at\" : datetime . now ( timezone . utc ) . isoformat ()} self . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = { user_id : tombstone } ) . raise_for_status () print ( f \"Tombstoned user ' { user_id } '\" ) if __name__ == \"__main__\" : client = UserProfileClient () # Create users client . create_user ( \"user_001\" , \"Alice Smith\" , \"alice@example.com\" , theme = \"dark\" , notifications = True , language = \"en\" ) client . create_user ( \"user_002\" , \"Bob Jones\" , \"bob@example.com\" , theme = \"light\" , notifications = False , language = \"fr\" ) # Retrieve a user alice = client . get_user ( \"user_001\" ) print ( f \" \\n Alice's profile: { alice } \" ) # Update settings client . update_settings ( \"user_001\" , theme = \"light\" , language = \"de\" ) # Verify update alice_updated = client . get_user ( \"user_001\" ) print ( f \"Alice's new theme: { alice_updated [ 'settings' ][ 'theme' ] } \" ) # Non-existent user nobody = client . get_user ( \"user_999\" ) print ( f \"user_999 exists: { nobody is not None } \" ) Expected output: Created user 'user_001' ( alice @example . com ) Created user 'user_002' ( bob @example . com ) Alice 's profile: {' id ': ' user_001 ', ' name ': ' Alice Smith ', ' email ': ' alice @example . com ', ...} Updated settings for ' user_001 ': {' theme ': ' light ', ' language ': ' de '} Alice' s new theme : light user_999 exists : False curl Walkthrough \u00b6 BASE = \"http://127.0.0.1:8080\" TOKEN = $( curl -sf -X POST \" $BASE /api/login\" \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"demo\"}' | jq -r .token ) # Create a user curl -sf -X PUT \" $BASE /entity/userdb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"user_001\": { \"id\": \"user_001\", \"name\": \"Alice Smith\", \"email\": \"alice@example.com\", \"created_at\": \"2026-01-01T00:00:00Z\", \"settings\": {\"theme\": \"dark\", \"notifications\": true} } }' # Retrieve the user curl -sf \" $BASE /entity/userdb?key=user_001\" \\ -H \"Authorization: Bearer $TOKEN \" | jq . # Update the theme (fetch + modify + put) PROFILE = $( curl -sf \" $BASE /entity/userdb?key=user_001\" \\ -H \"Authorization: Bearer $TOKEN \" ) UPDATED = $( echo \" $PROFILE \" | jq '.settings.theme = \"light\"' ) curl -sf -X PUT \" $BASE /entity/userdb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d \"{\\\"user_001\\\": $UPDATED }\" Batch User Import \u00b6 Write multiple users in a single PUT request to reduce round-trips: def bulk_import_users ( client : UserProfileClient , users : list [ dict ]) -> None : \"\"\"Import multiple users in a single API call.\"\"\" payload = {} for user in users : payload [ user [ \"id\" ]] = { \"id\" : user [ \"id\" ], \"name\" : user [ \"name\" ], \"email\" : user [ \"email\" ], \"created_at\" : datetime . now ( timezone . utc ) . isoformat (), \"settings\" : { \"theme\" : \"light\" , \"notifications\" : True }, } resp = client . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = payload ) resp . raise_for_status () print ( f \"Imported { len ( users ) } users in one request\" ) # Import 100 users at once users = [ { \"id\" : f \"user_ { i : 04d } \" , \"name\" : f \"User { i } \" , \"email\" : f \"user { i } @example.com\" } for i in range ( 1 , 101 ) ] bulk_import_users ( client , users ) Multi-Database Pattern: Separating Credentials \u00b6 For security, store credentials and profile data in separate databases: # Store credentials separately cred_payload = { \"user_001\" : { \"user_id\" : \"user_001\" , \"password_hash\" : \"$2b$12$...\" , # bcrypt hash \u2014 never plaintext \"mfa_enabled\" : True , } } client . session . put ( f \" { BASE_URL } /entity/credentials\" , json = cred_payload ) . raise_for_status () # Store public profile in a different database profile_payload = { \"user_001\" : { \"id\" : \"user_001\" , \"name\" : \"Alice Smith\" , \"email\" : \"alice@example.com\" , } } client . session . put ( f \" { BASE_URL } /entity/userdb\" , json = profile_payload ) . raise_for_status () Both databases are encrypted independently and can be accessed with different tokens.","title":"User Profiles"},{"location":"usage/examples/user-profiles/#example-user-profiles","text":"Store and manage user accounts, profile data, and per-user settings. Each user is stored as a separate entity with a unique user ID as the key. Use case: User registration system, profile service, preferences store. Database: userdb Entity key: user ID (e.g., user_42 , alice@example.com ) Entity value: {\"id\": \"...\", \"name\": \"...\", \"email\": \"...\", \"settings\": {...}}","title":"Example: User Profiles"},{"location":"usage/examples/user-profiles/#schema-setup","text":"TOKEN = $( curl -s -X POST http://127.0.0.1:8080/api/login \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"admin\"}' | jq -r .token ) curl -s -X PUT http://127.0.0.1:8080/schema/user.v1 \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"user.v1\", \"type\": \"object\", \"properties\": { \"id\": {\"type\": \"string\"}, \"name\": {\"type\": \"string\"}, \"email\": {\"type\": \"string\", \"format\": \"email\"}, \"created_at\": {\"type\": \"string\", \"format\": \"date-time\"}, \"settings\": { \"type\": \"object\", \"properties\": { \"theme\": {\"type\": \"string\", \"enum\": [\"light\", \"dark\"]}, \"notifications\": {\"type\": \"boolean\"}, \"language\": {\"type\": \"string\"} } } }, \"required\": [\"id\", \"email\"] }'","title":"Schema Setup"},{"location":"usage/examples/user-profiles/#python-client","text":"\"\"\" user_profiles.py \u2014 User profile CRUD using DeltaDatabase Install: pip install requests \"\"\" import requests from datetime import datetime , timezone BASE_URL = \"http://127.0.0.1:8080\" DATABASE = \"userdb\" class UserProfileClient : def __init__ ( self , client_id : str = \"user-service\" ): self . session = requests . Session () resp = self . session . post ( f \" { BASE_URL } /api/login\" , json = { \"client_id\" : client_id } ) resp . raise_for_status () self . session . headers [ \"Authorization\" ] = f \"Bearer { resp . json ()[ 'token' ] } \" def create_user ( self , user_id : str , name : str , email : str , ** settings ) -> dict : \"\"\"Create a new user profile.\"\"\" profile = { \"id\" : user_id , \"name\" : name , \"email\" : email , \"created_at\" : datetime . now ( timezone . utc ) . isoformat (), \"settings\" : settings or { \"theme\" : \"light\" , \"notifications\" : True }, } resp = self . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = { user_id : profile }, ) resp . raise_for_status () print ( f \"Created user ' { user_id } ' ( { email } )\" ) return profile def get_user ( self , user_id : str ) -> dict | None : \"\"\"Retrieve a user profile. Returns None if not found.\"\"\" resp = self . session . get ( f \" { BASE_URL } /entity/ { DATABASE } \" , params = { \"key\" : user_id } ) if resp . status_code == 404 : return None resp . raise_for_status () return resp . json () def update_settings ( self , user_id : str , ** new_settings ) -> dict : \"\"\"Update specific settings for a user.\"\"\" profile = self . get_user ( user_id ) if profile is None : raise ValueError ( f \"User ' { user_id } ' not found\" ) profile . setdefault ( \"settings\" , {}) . update ( new_settings ) self . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = { user_id : profile } ) . raise_for_status () print ( f \"Updated settings for ' { user_id } ': { new_settings } \" ) return profile def delete_user ( self , user_id : str ) -> None : \"\"\" DeltaDatabase does not have a native DELETE endpoint. Store a tombstone marker to indicate the user was deleted. \"\"\" tombstone = { \"id\" : user_id , \"deleted\" : True , \"deleted_at\" : datetime . now ( timezone . utc ) . isoformat ()} self . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = { user_id : tombstone } ) . raise_for_status () print ( f \"Tombstoned user ' { user_id } '\" ) if __name__ == \"__main__\" : client = UserProfileClient () # Create users client . create_user ( \"user_001\" , \"Alice Smith\" , \"alice@example.com\" , theme = \"dark\" , notifications = True , language = \"en\" ) client . create_user ( \"user_002\" , \"Bob Jones\" , \"bob@example.com\" , theme = \"light\" , notifications = False , language = \"fr\" ) # Retrieve a user alice = client . get_user ( \"user_001\" ) print ( f \" \\n Alice's profile: { alice } \" ) # Update settings client . update_settings ( \"user_001\" , theme = \"light\" , language = \"de\" ) # Verify update alice_updated = client . get_user ( \"user_001\" ) print ( f \"Alice's new theme: { alice_updated [ 'settings' ][ 'theme' ] } \" ) # Non-existent user nobody = client . get_user ( \"user_999\" ) print ( f \"user_999 exists: { nobody is not None } \" ) Expected output: Created user 'user_001' ( alice @example . com ) Created user 'user_002' ( bob @example . com ) Alice 's profile: {' id ': ' user_001 ', ' name ': ' Alice Smith ', ' email ': ' alice @example . com ', ...} Updated settings for ' user_001 ': {' theme ': ' light ', ' language ': ' de '} Alice' s new theme : light user_999 exists : False","title":"Python Client"},{"location":"usage/examples/user-profiles/#curl-walkthrough","text":"BASE = \"http://127.0.0.1:8080\" TOKEN = $( curl -sf -X POST \" $BASE /api/login\" \\ -H 'Content-Type: application/json' \\ -d '{\"client_id\":\"demo\"}' | jq -r .token ) # Create a user curl -sf -X PUT \" $BASE /entity/userdb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d '{ \"user_001\": { \"id\": \"user_001\", \"name\": \"Alice Smith\", \"email\": \"alice@example.com\", \"created_at\": \"2026-01-01T00:00:00Z\", \"settings\": {\"theme\": \"dark\", \"notifications\": true} } }' # Retrieve the user curl -sf \" $BASE /entity/userdb?key=user_001\" \\ -H \"Authorization: Bearer $TOKEN \" | jq . # Update the theme (fetch + modify + put) PROFILE = $( curl -sf \" $BASE /entity/userdb?key=user_001\" \\ -H \"Authorization: Bearer $TOKEN \" ) UPDATED = $( echo \" $PROFILE \" | jq '.settings.theme = \"light\"' ) curl -sf -X PUT \" $BASE /entity/userdb\" \\ -H \"Authorization: Bearer $TOKEN \" \\ -H 'Content-Type: application/json' \\ -d \"{\\\"user_001\\\": $UPDATED }\"","title":"curl Walkthrough"},{"location":"usage/examples/user-profiles/#batch-user-import","text":"Write multiple users in a single PUT request to reduce round-trips: def bulk_import_users ( client : UserProfileClient , users : list [ dict ]) -> None : \"\"\"Import multiple users in a single API call.\"\"\" payload = {} for user in users : payload [ user [ \"id\" ]] = { \"id\" : user [ \"id\" ], \"name\" : user [ \"name\" ], \"email\" : user [ \"email\" ], \"created_at\" : datetime . now ( timezone . utc ) . isoformat (), \"settings\" : { \"theme\" : \"light\" , \"notifications\" : True }, } resp = client . session . put ( f \" { BASE_URL } /entity/ { DATABASE } \" , json = payload ) resp . raise_for_status () print ( f \"Imported { len ( users ) } users in one request\" ) # Import 100 users at once users = [ { \"id\" : f \"user_ { i : 04d } \" , \"name\" : f \"User { i } \" , \"email\" : f \"user { i } @example.com\" } for i in range ( 1 , 101 ) ] bulk_import_users ( client , users )","title":"Batch User Import"},{"location":"usage/examples/user-profiles/#multi-database-pattern-separating-credentials","text":"For security, store credentials and profile data in separate databases: # Store credentials separately cred_payload = { \"user_001\" : { \"user_id\" : \"user_001\" , \"password_hash\" : \"$2b$12$...\" , # bcrypt hash \u2014 never plaintext \"mfa_enabled\" : True , } } client . session . put ( f \" { BASE_URL } /entity/credentials\" , json = cred_payload ) . raise_for_status () # Store public profile in a different database profile_payload = { \"user_001\" : { \"id\" : \"user_001\" , \"name\" : \"Alice Smith\" , \"email\" : \"alice@example.com\" , } } client . session . put ( f \" { BASE_URL } /entity/userdb\" , json = profile_payload ) . raise_for_status () Both databases are encrypted independently and can be accessed with different tokens.","title":"Multi-Database Pattern: Separating Credentials"}]}